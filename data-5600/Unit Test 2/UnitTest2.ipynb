{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a8290b-c236-43ee-8146-c577dc9138e1",
   "metadata": {},
   "source": [
    "# Unit Test 2\n",
    "\n",
    "Topics covered:\n",
    "\n",
    "* Logistic Regression\n",
    "* Resampling Methods\n",
    "* Subset Selection\n",
    "* Shrinkage Methods\n",
    "\n",
    "## Background\n",
    "The study of Near-Earth Objects (NEOs) is critical to ensuring future planetary security from impacts by asteroids. Predicting potential impacts may seem as if it is a straightforward task but the number of variables involved in the process leads to quite a bit of uncertainty. Because of this, the Center for NEO Studies (https://cneos.jpl.nasa.gov/about/cneos.html) and NASA's Jet Propulsion Laboratory has been logging data about asteroids and whether they meet the classification of hazardous or not. The data is provided on Canvas.\n",
    "\n",
    "### Dataset\n",
    "`nasa.csv`\n",
    "\n",
    "## Task\n",
    "Your goal is to construct a model that effectively predicts whether an asteroid is hazardous or not. Ideally, you will find a relatively simple (i.e. interpretable) model, such that we don't need to collect every variable below to make a prediction (hint: subset selection and/or shrinkage would be useful for this). The fewer variables we have to collect, the more asteroids we'll be able to observe. I would also like you to utilize PCA to select some number of principal components and try a logistic regression with those as predictor variables.\n",
    "\n",
    "I'm looking for a well-constructed logistic regression, whose assumptions have been checked, with strong cross-validated accuracy and an interpretation of the coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aab28f-2467-4071-b638-95dd02e8fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "import pandas as pd\n",
    "df = pd.read_csv('nasa.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2a6d9-c2c1-43c8-9d79-029516f5b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdaf73-a893-4575-801c-ef1334fb1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA continued\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7476750-7c00-4f0d-b852-1a01f526c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48164687-70db-4dc4-94bb-9a12b85f313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset Selection\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "sfs = SequentialFeatureSelector(lr, n_features_to_select=10, direction='forward')\n",
    "sfs.fit(df.drop(columns=['Hazardous']), df['Hazardous'])\n",
    "selected_features = df.columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc43e9-b8f1-4423-88a0-e54e0771b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "principal_components = pca.fit_transform(df.drop(columns=['Hazardous']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312fba5-eb05-4380-b7a3-3c737e131c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[selected_features], df['Hazardous'], test_size=0.2, random_state=42)\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba28a6a-d963-467c-a749-e4fff3521657",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(lr, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1133bd-af34-4994-8b12-7c8c3721f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpretation and Reporting\n",
    "coeffs = pd.DataFrame(lr.coef_, columns=selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc94ac-3436-44d8-ade5-7aa5377acff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load and inspect data\n",
    "df = pd.read_csv('nasa.csv')\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: EDA\n",
    "print(df.describe())\n",
    "print(df.info())\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Feature Engineering\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Step 4: Subset Selection\n",
    "lr = LogisticRegression()\n",
    "sfs = SequentialFeatureSelector(lr, n_features_to_select=10, direction='forward')\n",
    "sfs.fit(df.drop(columns=['Hazardous']), df['Hazardous'])\n",
    "selected_features = df.columns[sfs.get_support()]\n",
    "\n",
    "# Step 5: PCA\n",
    "pca = PCA(n_components=10)\n",
    "principal_components = pca.fit_transform(df.drop(columns=['Hazardous']))\n",
    "\n",
    "# Step 6: Logistic Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[selected_features], df['Hazardous'], test_size=0.2, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Model Evaluation\n",
    "cv_scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "print(f'Cross-validated accuracy: {cv_scores.mean()}')\n",
    "\n",
    "# Step 8: Interpretation\n",
    "coeffs = pd.DataFrame(lr.coef_, columns=selected_features)\n",
    "print(coeffs)\n",
    "\n",
    "# Step 9: Reporting\n",
    "# Summarize findings in a well-constructed report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
