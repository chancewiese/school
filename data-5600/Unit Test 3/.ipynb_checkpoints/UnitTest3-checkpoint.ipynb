{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f4f07b-dfec-49b8-8154-2d2dfc02a28b",
   "metadata": {},
   "source": [
    "# Unit Test 3\n",
    "\n",
    "Topics Covered:\n",
    "* Generalized Linear Models\n",
    "* K-Nearest Neighbors\n",
    "* CART\n",
    "* Random Forests\n",
    "* Boosting\n",
    "* Support Vector Machines\n",
    "\n",
    "## Background\n",
    "Story telling is a key component of interpersonal communication and the study of narrative ability in children can provide critical insights into their language development. Narrative sample analysis is a process in which an individual produces a narrative and then a Speech-Language Pathologist (or similar practitioner) analyzes the quality. One tool for measuring this quality is the Monitoring Indicators of Scholarly Language (MISL). It provides an objective measure of the macrostructure story elements (e.g. Characters, Setting, Initiating Event) as well as the microstructure or grammatical elements. \n",
    "\n",
    "The process of scoring the macrostructure can be very time consuming though, which leads to less effective ongoing monitoring. This dataset provides the first publicly accessible data for attempting to automate scoring of the macrostructure via Machine Learning.\n",
    "\n",
    "## Dataset:\n",
    "`AutomatedNarrativeAnalysisMISLData.csv`\n",
    "\n",
    "## Task\n",
    "\n",
    "Your goal is to predict the Initiating Event (`IE`) label. The `IE` is scored as either 0, 1, 2, or 3 but for our purposes it is acceptable to predict this as either a continuous or categorical output. Note that if you predict it as continuous, it is necessary to constrain the prediction in some way, therefore, categorical may be easier.\n",
    "\n",
    "For predictor variables, you have two choices: either the raw text or the text features (or both, technically). The text features are every column **except** `Char`, `Sett`, `IE`, `Plan`, `Act`, and `Con`. Those 6 variables are the output scores but again we'll just be focusing on `IE` for now. Also, exclude the `ID` column.\n",
    "\n",
    "Using cross-validation, explore the many different classification algorithms we discussed to find the model with the highest performance (I'll leave it to you to define performance).\n",
    "\n",
    "**Bonus**: The column `vecOfNarratives` contains the raw text. If you would like, feel free to use Tf-Idf method for creating columns out of raw text that we discussed in the SVM lecture. It's in the notebook titled `BBC_Text_preprocessing.ipynb`.\n",
    "\n",
    "*This is still very much an open task so any major improvements would likely be publication worthy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca466ac9-c2d1-4e81-9495-57b28f08070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd907b01-ae23-4552-b904-63d1fb3cacb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in dataframe\n",
    "df = pd.read_csv('AutomatedNarrativeAnalysisMISLData.csv')\n",
    "\n",
    "# Clean data\n",
    "df = df.drop(columns=['ID', 'vecOfNarratives', 'Char', 'Sett', 'Plan', 'Act', 'Con']) # Drop columns\n",
    "df = df.dropna() # Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fab6629-82e9-488f-9262-f6d4f2558d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into features and target variable\n",
    "X = df.drop(columns=['IE'])\n",
    "y = df['IE']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379e2b12-297e-4e15-a2ee-ce7bb821fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model evaluation function\n",
    "def evaluate_model(model, X_train, y_train):\n",
    "    # 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    print(f\"\\tCross-validated accuracy scores: {cv_scores}\")\n",
    "    print(f\"\\tMean accuracy: {mean_cv_score}\")\n",
    "    print(f\"\\tStandard deviation: {np.std(cv_scores)}\\n\")\n",
    "    \n",
    "    # Train the model on training set and return it along with mean cross-validation score\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, mean_cv_score\n",
    "\n",
    "# Define function to find the best model\n",
    "def find_best_model(models, X_train, y_train, X_test, y_test):\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_name = \"\"\n",
    "    best_cv_score = 0\n",
    "    for name, model in models.items():\n",
    "        print(f\"Evaluating {name}:\")\n",
    "        trained_model, mean_cv_score = evaluate_model(model, X_train, y_train)\n",
    "        y_pred = trained_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f\"Performance of {name} on the test set:\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        if accuracy > best_score or (accuracy == best_score and mean_cv_score > best_cv_score):\n",
    "            best_score = accuracy\n",
    "            best_cv_score = mean_cv_score\n",
    "            best_model = trained_model\n",
    "            best_name = name\n",
    "    print(f\"The best model is {best_name} with an accuracy of {best_score} and a cross-validated mean accuracy of {best_cv_score}\")\n",
    "    return best_model\n",
    "\n",
    "# Define function find the final best model after parameter tuning\n",
    "def find_best_model_final(scores):\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_f1_score = 0\n",
    "    best_name = \"\"\n",
    "    \n",
    "    # Compare models based on accuracy and F1 score\n",
    "    for model_name, metrics in scores.items():\n",
    "        print(f\"{model_name} - Accuracy: {metrics['accuracy']}, F1 Score: {metrics['f1_score']}\")\n",
    "        if metrics['accuracy'] > best_score or \\\n",
    "           (metrics['accuracy'] == best_score and metrics['f1_score'] > best_f1_score):\n",
    "            best_score = metrics['accuracy']\n",
    "            best_f1_score = metrics['f1_score']\n",
    "            best_model = model_name\n",
    "    \n",
    "    print(f\"\\nThe best model is {best_model} with an accuracy of {best_score} and an F1 score of {best_f1_score}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58c570f-4be3-488a-899b-ecba4a236120",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression:\n",
      "\tCross-validated accuracy scores: [0.56716418 0.5        0.48484848 0.40909091 0.5       ]\n",
      "\tMean accuracy: 0.4922207146087743\n",
      "\tStandard deviation: 0.05040331689500523\n",
      "\n",
      "Performance of Logistic Regression on the test set:\n",
      "Accuracy: 0.4457831325301205\n",
      "F1 Score: 0.42730567502827266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.41      0.47        17\n",
      "           1       0.19      0.17      0.18        23\n",
      "           2       0.54      0.69      0.61        36\n",
      "           3       0.33      0.14      0.20         7\n",
      "\n",
      "    accuracy                           0.45        83\n",
      "   macro avg       0.40      0.36      0.36        83\n",
      "weighted avg       0.43      0.45      0.43        83\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating K-Nearest Neighbors:\n",
      "\tCross-validated accuracy scores: [0.52238806 0.46969697 0.48484848 0.5        0.42424242]\n",
      "\tMean accuracy: 0.48023518769787427\n",
      "\tStandard deviation: 0.03296979991478287\n",
      "\n",
      "Performance of K-Nearest Neighbors on the test set:\n",
      "Accuracy: 0.46987951807228917\n",
      "F1 Score: 0.4500887064742486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.41      0.56        17\n",
      "           1       0.33      0.17      0.23        23\n",
      "           2       0.45      0.69      0.55        36\n",
      "           3       0.38      0.43      0.40         7\n",
      "\n",
      "    accuracy                           0.47        83\n",
      "   macro avg       0.51      0.43      0.43        83\n",
      "weighted avg       0.50      0.47      0.45        83\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating Decision Tree:\n",
      "\tCross-validated accuracy scores: [0.53731343 0.42424242 0.31818182 0.5        0.40909091]\n",
      "\tMean accuracy: 0.4377657168701945\n",
      "\tStandard deviation: 0.0762735689748958\n",
      "\n",
      "Performance of Decision Tree on the test set:\n",
      "Accuracy: 0.4939759036144578\n",
      "F1 Score: 0.4918302618470193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.59        17\n",
      "           1       0.44      0.35      0.39        23\n",
      "           2       0.54      0.53      0.54        36\n",
      "           3       0.30      0.43      0.35         7\n",
      "\n",
      "    accuracy                           0.49        83\n",
      "   macro avg       0.46      0.49      0.47        83\n",
      "weighted avg       0.50      0.49      0.49        83\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating Random Forest:\n",
      "\tCross-validated accuracy scores: [0.64179104 0.48484848 0.54545455 0.48484848 0.60606061]\n",
      "\tMean accuracy: 0.5526006331976481\n",
      "\tStandard deviation: 0.06331614643664202\n",
      "\n",
      "Performance of Random Forest on the test set:\n",
      "Accuracy: 0.4939759036144578\n",
      "F1 Score: 0.4697729492910215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60        17\n",
      "           1       0.29      0.17      0.22        23\n",
      "           2       0.50      0.72      0.59        36\n",
      "           3       0.50      0.29      0.36         7\n",
      "\n",
      "    accuracy                           0.49        83\n",
      "   macro avg       0.49      0.43      0.44        83\n",
      "weighted avg       0.48      0.49      0.47        83\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating Support Vector Machine:\n",
      "\tCross-validated accuracy scores: [0.64179104 0.45454545 0.46969697 0.51515152 0.57575758]\n",
      "\tMean accuracy: 0.5313885119855268\n",
      "\tStandard deviation: 0.06947182882212444\n",
      "\n",
      "Performance of Support Vector Machine on the test set:\n",
      "Accuracy: 0.5301204819277109\n",
      "F1 Score: 0.4883527435660328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        17\n",
      "           1       0.23      0.13      0.17        23\n",
      "           2       0.53      0.83      0.65        36\n",
      "           3       1.00      0.14      0.25         7\n",
      "\n",
      "    accuracy                           0.53        83\n",
      "   macro avg       0.65      0.42      0.44        83\n",
      "weighted avg       0.55      0.53      0.49        83\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating Gradient Boosting:\n",
      "\tCross-validated accuracy scores: [0.62686567 0.5        0.51515152 0.51515152 0.57575758]\n",
      "\tMean accuracy: 0.5465852555404794\n",
      "\tStandard deviation: 0.047837883690025264\n",
      "\n",
      "Performance of Gradient Boosting on the test set:\n",
      "Accuracy: 0.5060240963855421\n",
      "F1 Score: 0.48939347132118216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53        17\n",
      "           1       0.31      0.22      0.26        23\n",
      "           2       0.56      0.69      0.62        36\n",
      "           3       0.60      0.43      0.50         7\n",
      "\n",
      "    accuracy                           0.51        83\n",
      "   macro avg       0.50      0.47      0.48        83\n",
      "weighted avg       0.49      0.51      0.49        83\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "The best model is Support Vector Machine with an accuracy of 0.5301204819277109 and a cross-validated mean accuracy of 0.5313885119855268\n"
     ]
    }
   ],
   "source": [
    "# List of models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()}\n",
    "\n",
    "# Find and evaluate the best model\n",
    "best_model = find_best_model(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0632c23-924a-46c3-9aa4-67c7d76400c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best SVM cross-validated accuracy: 0.5313885119855268\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# GridSearchCV object for SVM\n",
    "svm_grid_search = GridSearchCV(SVC(), svm_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search for SVM\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "best_svm = svm_grid_search.best_estimator_\n",
    "print(f\"Best SVM parameters: {svm_grid_search.best_params_}\")\n",
    "print(f\"Best SVM cross-validated accuracy: {svm_grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38fe9b4f-397e-474b-b8f1-93d3677f603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest parameters: {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Random Forest cross-validated accuracy: 0.5799638172772501\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# GridSearchCV object for Random Forest\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search for Random Forest\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "print(f\"Best Random Forest parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Best Random Forest cross-validated accuracy: {rf_grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f070c388-fec2-4820-be7b-2cdb276030d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}\n",
      "Best Gradient Boosting cross-validated accuracy: 0.5437358661239258\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [0.8, 1.0]}\n",
    "\n",
    "# GridSearchCV object for Gradient Boosting\n",
    "gb_grid_search = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search for Gradient Boosting\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "best_gb = gb_grid_search.best_estimator_\n",
    "print(f\"Best Gradient Boosting parameters: {gb_grid_search.best_params_}\")\n",
    "print(f\"Best Gradient Boosting cross-validated accuracy: {gb_grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0294bea9-93e5-48de-98e2-cddff848ab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the best SVM on the test set:\n",
      "Accuracy: 0.5301204819277109\n",
      "F1 Score: 0.4883527435660328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        17\n",
      "           1       0.23      0.13      0.17        23\n",
      "           2       0.53      0.83      0.65        36\n",
      "           3       1.00      0.14      0.25         7\n",
      "\n",
      "    accuracy                           0.53        83\n",
      "   macro avg       0.65      0.42      0.44        83\n",
      "weighted avg       0.55      0.53      0.49        83\n",
      "\n",
      "Performance of the best Random Forest on the test set:\n",
      "Accuracy: 0.5301204819277109\n",
      "F1 Score: 0.5086007862039954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60        17\n",
      "           1       0.39      0.30      0.34        23\n",
      "           2       0.54      0.75      0.63        36\n",
      "           3       0.50      0.14      0.22         7\n",
      "\n",
      "    accuracy                           0.53        83\n",
      "   macro avg       0.53      0.43      0.45        83\n",
      "weighted avg       0.53      0.53      0.51        83\n",
      "\n",
      "Performance of the best Gradient Boosting on the test set:\n",
      "Accuracy: 0.5180722891566265\n",
      "F1 Score: 0.5083523587784533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53        17\n",
      "           1       0.33      0.26      0.29        23\n",
      "           2       0.57      0.67      0.62        36\n",
      "           3       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           0.52        83\n",
      "   macro avg       0.53      0.51      0.51        83\n",
      "weighted avg       0.50      0.52      0.51        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary to hold the scores\n",
    "scores = {}\n",
    "\n",
    "# Evaluate and store scores for the best SVM\n",
    "print(\"Performance of the best SVM on the test set:\")\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "print(f\"Accuracy: {accuracy_svm}\")\n",
    "print(f\"F1 Score: {f1_svm}\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "scores['SVM'] = {'accuracy': accuracy_svm, 'f1_score': f1_svm}\n",
    "\n",
    "# Evaluate and store scores for the best Random Forest\n",
    "print(\"Performance of the best Random Forest on the test set:\")\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"F1 Score: {f1_rf}\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "scores['Random Forest'] = {'accuracy': accuracy_rf, 'f1_score': f1_rf}\n",
    "\n",
    "# Evaluate and store scores for the best Gradient Boosting\n",
    "print(\"Performance of the best Gradient Boosting on the test set:\")\n",
    "y_pred_gb = best_gb.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "f1_gb = f1_score(y_test, y_pred_gb, average='weighted')\n",
    "print(f\"Accuracy: {accuracy_gb}\")\n",
    "print(f\"F1 Score: {f1_gb}\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "scores['Gradient Boosting'] = {'accuracy': accuracy_gb, 'f1_score': f1_gb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc7176f-cfa9-4337-a6f4-86f246f1ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy: 0.5301204819277109, F1 Score: 0.4883527435660328\n",
      "Random Forest - Accuracy: 0.5301204819277109, F1 Score: 0.5086007862039954\n",
      "Gradient Boosting - Accuracy: 0.5180722891566265, F1 Score: 0.5083523587784533\n",
      "\n",
      "The best model is Random Forest with an accuracy of 0.5301204819277109 and an F1 score of 0.5086007862039954\n"
     ]
    }
   ],
   "source": [
    "# Find and print the best model\n",
    "best_model_final = find_best_model_final(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6b4e9-bf3f-47d0-a205-9a7dbc123332",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "\n",
    "#### Model Evaluation\n",
    "Six different classification models were evaluated using 5-fold cross-validation on the training set.\n",
    "* Logistic Regression\n",
    "* K-Nearest Neighbors\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Support Vector Machine\n",
    "* Gradient Boosting\n",
    "\n",
    "##### The scores for each model:\n",
    "\n",
    "| Model                  | Cross-Validated Accuracy | Test Set Accuracy | F1 Score on Test Set |\n",
    "|------------------------|--------------------------|-------------------|----------------------|\n",
    "| Logistic Regression    | 0.492                    | 0.4458            | 0.4273               |\n",
    "| K-Nearest Neighbors    | 0.480                    | 0.4699            | 0.4501               |\n",
    "| Decision Tree          | 0.435                    | 0.4699            | 0.4645               |\n",
    "| Random Forest          | 0.559                    | 0.5181            | 0.4794               |\n",
    "| Support Vector Machine | 0.531                    | 0.5301            | 0.4884               |\n",
    "| Gradient Boosting      | 0.547                    | 0.5060            | 0.4894               |\n",
    "\n",
    "Based on the cross-validated accuracy, the best-performing model was the Support Vector Machine (SVM).\n",
    "\n",
    "#### Hyperparameter Tuning\n",
    "Hyperparameter tuning was performed for the Gradient Boosting, SVM, and Random Forest models, as they had similar performance scores.\n",
    "\n",
    "* **Support Vector Machine (SVM):** GridSearchCV was used to find the best parameters. The optimal parameters were C=1, gamma=0.01, and kernel='rbf'. This tuning resulted in a cross-validated accuracy of 0.531.\n",
    "* **Random Forest:** GridSearchCV identified the best parameters as {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}. The cross-validated accuracy improved to 0.580.\n",
    "* **Gradient Boosting:** GridSearchCV revealed the best parameters as {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}. The cross-validated accuracy was 0.544.\n",
    "\n",
    "#### Final Model Performance\n",
    "Below are the performance scores of the best SVM model on the test set:\n",
    "* Accuracy: 0.530\n",
    "* F1 Score: 0.488\n",
    "\n",
    "#### Classification Report\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| 0     | 0.83      | 0.59   | 0.69     | 17      |\n",
    "| 1     | 0.23      | 0.13   | 0.17     | 23      |\n",
    "| 2     | 0.53      | 0.83   | 0.65     | 36      |\n",
    "| 3     | 1.00      | 0.14   | 0.25     | 7       |\n",
    "\n",
    "#### Overall Scores\n",
    "\n",
    "|             | Precision | Recall | F1-Score | Support |\n",
    "|-------------|-----------|--------|----------|---------|\n",
    "| **Accuracy**| -         | -      | **0.53** | 83      |\n",
    "| **Macro Avg** | 0.65    | 0.42   | 0.44     | 83      |\n",
    "| **Weighted Avg** | 0.55 | 0.53   | 0.49     | 83      |\n",
    "\n",
    "#### Conclusion\n",
    "The tuned SVM model gave the best performance above all the models, having an accuracy of 0.530 and an F1 score of 0.488 on the test set. The model performed very well for some classes, but had a harder time with others. This shows there were possible areas of improvement. Further exploration of additional features or more advanced models could help the findings. Perhaps using the raw text could prove to be more valuable with more robust models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
