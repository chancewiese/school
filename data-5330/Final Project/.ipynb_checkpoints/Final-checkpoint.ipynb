{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6ca219-3d5c-4eb0-8720-672d64e636a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "# import pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7816fe97-38ff-450a-a3f5-4aa96c82673c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Convert to integer\n",
    "def int_convert(value):\n",
    "    if pd.notna(value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Handle Null Values\n",
    "def handle_na(value):\n",
    "    if pd.notna(value):\n",
    "        return value\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Determine winner_ou\n",
    "def get_winner_ou(total_score, over_under_line):\n",
    "    if total_score > over_under_line:\n",
    "        return 'over'\n",
    "    elif total_score < over_under_line:\n",
    "        return 'under'\n",
    "    else:\n",
    "        return 'push'\n",
    "\n",
    "# Determine winner_line\n",
    "def get_winner_line(score_home, score_away, spread_favorite, team_favorite_id, team_home):\n",
    "    score_diff = score_home - score_away\n",
    "    \n",
    "    # Special handling for pick games (spread is 0)\n",
    "    if spread_favorite == 0:\n",
    "        if score_diff > 0:\n",
    "            return 'home'\n",
    "        elif score_diff < 0:\n",
    "            return 'away'\n",
    "        else:\n",
    "            return 'push'\n",
    "    \n",
    "    if team_favorite_id == team_home:\n",
    "        adjusted_spread = spread_favorite\n",
    "    else:\n",
    "        adjusted_spread = -spread_favorite\n",
    "        \n",
    "    if score_diff > adjusted_spread:\n",
    "        return 'home'\n",
    "    elif score_diff < adjusted_spread:\n",
    "        return 'away'\n",
    "    else:\n",
    "        return 'push'\n",
    "\n",
    "# Calculate commission based on bet amount\n",
    "def calculate_commission(bet_amount):\n",
    "    \"\"\"\n",
    "    Calculate commission based on Iron Will's graduated schedule:\n",
    "    - 10% on first $1,000\n",
    "    - 8% on next $4,000\n",
    "    - 6% on remaining amount\n",
    "    \"\"\"\n",
    "    commission = 0\n",
    "    \n",
    "    # First $1,000\n",
    "    if bet_amount <= 1000:\n",
    "        commission = bet_amount * 0.10\n",
    "    else:\n",
    "        commission = 1000 * 0.10\n",
    "        remaining = bet_amount - 1000\n",
    "        \n",
    "        # Next $4,000\n",
    "        if remaining <= 4000:\n",
    "            commission += remaining * 0.08\n",
    "        else:\n",
    "            commission += 4000 * 0.08\n",
    "            remaining = remaining - 4000\n",
    "            \n",
    "            # Anything over $5,000\n",
    "            commission += remaining * 0.06\n",
    "            \n",
    "    return round(commission, 2)\n",
    "\n",
    "# Bet result\n",
    "def determine_bet_result(bet_on, winner_line, winner_ou, team_id_home, team_id_away):\n",
    "    \"\"\"\n",
    "    Determine if bet was a win, loss, or push based on:\n",
    "    - What was bet on (team or over/under)\n",
    "    - Game outcome (winner_line or winner_ou)\n",
    "    \"\"\"\n",
    "\n",
    "    bet_on_lower = bet_on.lower()\n",
    "    \n",
    "    if bet_on_lower == 'over':\n",
    "        if winner_ou == 'over':\n",
    "            return 'win'\n",
    "        elif winner_ou == 'under':\n",
    "            return 'loss'\n",
    "        else:\n",
    "            return 'push'\n",
    "    elif bet_on_lower == 'under':\n",
    "        if winner_ou == 'under':\n",
    "            return 'win'\n",
    "        elif winner_ou == 'over':\n",
    "            return 'loss'\n",
    "        else:\n",
    "            return 'push'\n",
    "    elif bet_on_lower == 'push':\n",
    "        if winner_line == 'push':\n",
    "            return 'win'\n",
    "        else:\n",
    "            return 'loss'\n",
    "    else:  # Team bet\n",
    "        cursor.execute(\"SELECT DISTINCT team_id FROM team_history WHERE name = %s;\", (bet_on,))\n",
    "        bet_team_id = cursor.fetchone()\n",
    "        if bet_team_id:\n",
    "            bet_team_id = bet_team_id[0]\n",
    "            \n",
    "            # Home or away team\n",
    "            if bet_team_id == team_id_home:\n",
    "                if winner_line == 'home':\n",
    "                    return 'win'\n",
    "                elif winner_line == 'away':\n",
    "                    return 'loss'\n",
    "                else:\n",
    "                    return 'push'\n",
    "            else:\n",
    "                if winner_line == 'away':\n",
    "                    return 'win'\n",
    "                elif winner_line == 'home':\n",
    "                    return 'loss'\n",
    "                else:\n",
    "                    return 'push'\n",
    "        else:\n",
    "            print(f\"Warning: Could not find team ID for bet on {bet_on}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3192b747-c8a0-476a-8a71-5859e05a4477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establish connections\n",
    "conn = psycopg2.connect(\n",
    "    database=\"iwdm\", \n",
    "    user='dw_chancewiese',\n",
    "    password='Spikeball2020',\n",
    "    host='database-1.czsooswggscz.us-east-2.rds.amazonaws.com',\n",
    "    port='5432'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# pymssql_conn = pymssql.connect(\n",
    "#     server='stairwaytoheaven.usu.edu',\n",
    "#     user='5330user',\n",
    "#     password='pipelinesnow',\n",
    "#     database='ironwill'\n",
    "# )\n",
    "# pymssql_cursor = pymssql_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485d2f39-d13e-4602-8a9e-e808a848c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop all tables in the correct order, considering foreign key dependencies\n",
    "# try:\n",
    "#     cursor.execute('''\n",
    "#     DROP TABLE IF EXISTS bets;\n",
    "#     ''')\n",
    "#     conn.commit()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n",
    "\n",
    "# cursor.execute('''\n",
    "# CREATE TABLE IF NOT EXISTS bets (\n",
    "#     bet_id INTEGER PRIMARY KEY,\n",
    "#     customer_id INTEGER NOT NULL,\n",
    "#     game_id VARCHAR(50) NOT NULL,\n",
    "#     bet_amount INTEGER NOT NULL,\n",
    "#     bet_on VARCHAR(50) NOT NULL,\n",
    "#     result VARCHAR(10),\n",
    "#     commission_amount DECIMAL(10,2),\n",
    "#     FOREIGN KEY (customer_id) \n",
    "#         REFERENCES customers (customer_id),\n",
    "#     FOREIGN KEY (game_id) \n",
    "#         REFERENCES games (game_id)\n",
    "#     );''')\n",
    "# conn.commit()\n",
    "# print(\"Created bets table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60927470-6198-4929-b7f9-1cc19ac3303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all tables in the correct order, considering foreign key dependencies\n",
    "try:\n",
    "    cursor.execute('''\n",
    "    DROP TABLE IF EXISTS bets;\n",
    "    DROP TABLE IF EXISTS games;\n",
    "    DROP TABLE IF EXISTS stadiums;\n",
    "    DROP TABLE IF EXISTS weather_stations;\n",
    "    DROP TABLE IF EXISTS teams;\n",
    "    DROP TABLE IF EXISTS team_history;\n",
    "    DROP TABLE IF EXISTS current_teams;\n",
    "    DROP TABLE IF EXISTS customers;\n",
    "    ''')\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71776ef-598e-4565-b31d-a763e01353e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customers table\n",
      "Created current teams table\n",
      "Created team history table\n",
      "Created weather stations table\n",
      "Created stadiums table\n",
      "Created games table\n",
      "Created bets table\n"
     ]
    }
   ],
   "source": [
    "# Create Tables\n",
    "# Customers\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS customers (\n",
    "    customer_id INTEGER PRIMARY KEY,\n",
    "    first_name VARCHAR(50) NOT NULL,\n",
    "    last_name VARCHAR(50) NOT NULL,\n",
    "    age INTEGER NOT NULL,\n",
    "    customer_type VARCHAR(10) NOT NULL,\n",
    "    customer_since INTEGER NOT NULL,\n",
    "    income INTEGER NOT NULL,\n",
    "    household_size INTEGER NOT NULL,\n",
    "    mode_color VARCHAR(10) NOT NULL\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created customers table\")\n",
    "\n",
    "# Current Teams\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS current_teams (\n",
    "    team_id VARCHAR(5) PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    name_short VARCHAR(50) NOT NULL,\n",
    "    team_id_pfr VARCHAR(5) NOT NULL,\n",
    "    conference VARCHAR(5),\n",
    "    division VARCHAR(20)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created current teams table\")\n",
    "\n",
    "# Team History\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS team_history (\n",
    "    team_history_id SERIAL PRIMARY KEY,\n",
    "    team_id VARCHAR(5) NOT NULL,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    name_short VARCHAR(50) NOT NULL,\n",
    "    team_id_pfr VARCHAR(5) NOT NULL,\n",
    "    conference VARCHAR(5),\n",
    "    division VARCHAR(20),\n",
    "    FOREIGN KEY (team_id) REFERENCES current_teams (team_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created team history table\")\n",
    "\n",
    "# Weather Stations\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS weather_stations (\n",
    "    weather_station_id CHAR(11) PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    state CHAR(2),\n",
    "    country CHAR(2),\n",
    "    latitude DECIMAL(8,5) NOT NULL,\n",
    "    longitude DECIMAL(8,5) NOT NULL,\n",
    "    elevation DECIMAL(5,1) NOT NULL\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created weather stations table\")\n",
    "\n",
    "# Stadiums\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS stadiums (\n",
    "    stadium_id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    stadium_open SMALLINT,\n",
    "    stadium_close INTEGER,\n",
    "    stadium_type VARCHAR(20),\n",
    "    street_address VARCHAR(100),\n",
    "    city VARCHAR(50),\n",
    "    state CHAR(2),\n",
    "    postal_code VARCHAR(10),\n",
    "    country CHAR(2),\n",
    "    weather_station_id CHAR(11),\n",
    "    stadium_weather_station_code INTEGER,\n",
    "    stadium_weather_type VARCHAR(20),\n",
    "    surface VARCHAR(50),\n",
    "    FOREIGN KEY (weather_station_id) \n",
    "        REFERENCES weather_stations (weather_station_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created stadiums table\")\n",
    "\n",
    "# Games\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS games (\n",
    "    game_id VARCHAR(50) PRIMARY KEY,\n",
    "    schedule_date DATE NOT NULL,\n",
    "    schedule_season SMALLINT NOT NULL,\n",
    "    schedule_week SMALLINT NOT NULL,\n",
    "    schedule_playoff BOOLEAN NOT NULL,\n",
    "    playoff_type VARCHAR(20),\n",
    "    team_id_home VARCHAR(5) NOT NULL,\n",
    "    team_id_away VARCHAR(5) NOT NULL,\n",
    "    score_home SMALLINT,\n",
    "    score_away SMALLINT,\n",
    "    team_id_favorite VARCHAR(5),\n",
    "    spread_favorite DECIMAL(4,1),\n",
    "    over_under_line DECIMAL(4,1),\n",
    "    stadium_id INTEGER,\n",
    "    stadium_neutral BOOLEAN NOT NULL,\n",
    "    weather_temperature SMALLINT,\n",
    "    weather_wind_mph SMALLINT,\n",
    "    weather_humidity SMALLINT,\n",
    "    weather_detail VARCHAR(100),\n",
    "    winner_ou VARCHAR(10),\n",
    "    winner_line VARCHAR(10),\n",
    "    FOREIGN KEY (team_id_home) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_away) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_favorite) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (stadium_id) \n",
    "        REFERENCES stadiums (stadium_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created games table\")\n",
    "\n",
    "# Bets\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS bets (\n",
    "    bet_id INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER NOT NULL,\n",
    "    game_id VARCHAR(50) NOT NULL,\n",
    "    bet_amount INTEGER NOT NULL,\n",
    "    bet_on VARCHAR(50) NOT NULL,\n",
    "    result VARCHAR(10),\n",
    "    commission_amount DECIMAL(10,2),\n",
    "    FOREIGN KEY (customer_id) \n",
    "        REFERENCES customers (customer_id),\n",
    "    FOREIGN KEY (game_id) \n",
    "        REFERENCES games (game_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created bets table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc9ea31-1b36-47d2-82b6-7a4b1d33ec10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\2151444998.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_weather_stations = pd.read_sql(\"SELECT weather_station_id FROM weather_stations;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted station USW00094823: PITTSBURGH ASOS\n",
      "Inserted station US1MOJC0028: KANSAS CITY 5.1 SE\n",
      "Inserted station USC00410337: ARLINGTON SIX FLAGS\n",
      "Inserted station USW00013881: CHARLOTTE DOUGLAS AIRPORT\n",
      "Inserted station US1NYER0093: BUFFALO 1.5 W\n",
      "Inserted station USC00238791: WEBSTER GROVES\n",
      "Inserted station USW00023234: SAN FRANCISCO INTERNATIONAL AIRPORT\n",
      "Inserted station US1WAKG0038: SEATTLE 3.5 NW\n",
      "Inserted station USW00003871: CINCINNATI WEATHER SERVICE OFFICE CITY\n",
      "Inserted station USW00014820: CLEVELAND HOPKINS INTERNATIONAL AIRPORT\n",
      "Inserted station USW00023062: DENVER STAPLETON\n",
      "Inserted station USW00093837: JACKSONVILLE NAS\n",
      "Inserted station USC00186350: NATIONAL ARBORETUM DC\n",
      "Inserted station USC00190860: BROCKTON\n",
      "Inserted station USW00014734: NEWARK LIBERTY INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012839: MIAMI INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012842: TAMPA INTERNATIONAL AIRPORT\n",
      "Inserted station USW00014898: GREEN BAY AUSTIN STRAUBEL INTERNATIONAL AIRPORT\n",
      "Inserted station USW00013739: PHILADELPHIA INTERNATIONAL AIRPORT\n",
      "Inserted station USW00023174: LOS ANGELES INTERNATIONAL AIRPORT\n",
      "Inserted station USW00013897: NASHVILLE INTERNATIONAL AIRPORT\n",
      "Inserted station US1INMR0076: INDIANAPOLIS 6.8 NNE\n",
      "Inserted station USW00093721: BALTIMORE WASHINGTON INTERNATIONAL AIRPORT\n",
      "Inserted station USW00014922: MINNEAPOLIS ST PAUL INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012918: HOUSTON WILLIAM P HOBBY AIRPORT\n",
      "Inserted station USW00023230: OAKLAND METROPOLITAN INTERNATIONAL AIRPORT\n",
      "Inserted station USW00093107: SAN DIEGO MIRAMAR NAS\n",
      "Inserted station USC00111550: CHICAGO NORTHERLY ISLAND\n",
      "Inserted station US1AZMR0451: TEMPE 3.6 NNW\n",
      "Number of records: 29\n",
      "                                                                name state  \\\n",
      "weather_station_id                                                          \n",
      "USW00094823                                         PITTSBURGH ASOS    PA   \n",
      "US1MOJC0028                                      KANSAS CITY 5.1 SE    MO   \n",
      "USC00410337                                     ARLINGTON SIX FLAGS    TX   \n",
      "USW00013881                               CHARLOTTE DOUGLAS AIRPORT    NC   \n",
      "US1NYER0093                                           BUFFALO 1.5 W    NY   \n",
      "USC00238791                                          WEBSTER GROVES    MO   \n",
      "USW00023234                     SAN FRANCISCO INTERNATIONAL AIRPORT    CA   \n",
      "US1WAKG0038                                          SEATTLE 3.5 NW    WA   \n",
      "USW00003871                  CINCINNATI WEATHER SERVICE OFFICE CITY    OH   \n",
      "USW00014820                 CLEVELAND HOPKINS INTERNATIONAL AIRPORT    OH   \n",
      "USW00023062                                        DENVER STAPLETON    CO   \n",
      "USW00093837                                        JACKSONVILLE NAS    FL   \n",
      "USC00186350                                   NATIONAL ARBORETUM DC    MD   \n",
      "USC00190860                                                BROCKTON    MA   \n",
      "USW00014734                    NEWARK LIBERTY INTERNATIONAL AIRPORT    NJ   \n",
      "USW00012839                             MIAMI INTERNATIONAL AIRPORT    FL   \n",
      "USW00012842                             TAMPA INTERNATIONAL AIRPORT    FL   \n",
      "USW00014898         GREEN BAY AUSTIN STRAUBEL INTERNATIONAL AIRPORT    WI   \n",
      "USW00013739                      PHILADELPHIA INTERNATIONAL AIRPORT    PA   \n",
      "USW00023174                       LOS ANGELES INTERNATIONAL AIRPORT    CA   \n",
      "USW00013897                         NASHVILLE INTERNATIONAL AIRPORT    TN   \n",
      "US1INMR0076                                    INDIANAPOLIS 6.8 NNE    IN   \n",
      "USW00093721              BALTIMORE WASHINGTON INTERNATIONAL AIRPORT    MD   \n",
      "USW00014922               MINNEAPOLIS ST PAUL INTERNATIONAL AIRPORT    MN   \n",
      "USW00012918                         HOUSTON WILLIAM P HOBBY AIRPORT    TX   \n",
      "USW00023230              OAKLAND METROPOLITAN INTERNATIONAL AIRPORT    CA   \n",
      "USW00093107                                   SAN DIEGO MIRAMAR NAS    CA   \n",
      "USC00111550                                CHICAGO NORTHERLY ISLAND    IL   \n",
      "US1AZMR0451                                           TEMPE 3.6 NNW    AZ   \n",
      "\n",
      "                   country  latitude  longitude  elevation  \n",
      "weather_station_id                                          \n",
      "USW00094823             US  40.48460  -80.21440      366.7  \n",
      "US1MOJC0028             US  39.06920  -94.48710      264.9  \n",
      "USC00410337             US  32.75720  -97.07360      163.4  \n",
      "USW00013881             US  35.22360  -80.95520      221.9  \n",
      "US1NYER0093             US  42.88900  -78.89010      178.0  \n",
      "USC00238791             US  38.56667  -90.36667      189.0  \n",
      "USW00023234             US  37.61970 -122.36470        2.4  \n",
      "US1WAKG0038             US  47.65230 -122.40950       93.0  \n",
      "USW00003871             US  39.10000  -84.51667      193.9  \n",
      "USW00014820             US  41.40570  -81.85200      238.0  \n",
      "USW00023062             US  39.76330 -104.86940     1611.2  \n",
      "USW00093837             US  30.23333  -81.66667        6.1  \n",
      "USC00186350             US  38.91330  -76.97000       15.2  \n",
      "USC00190860             US  42.04790  -71.00500       24.4  \n",
      "USW00014734             US  40.68250  -74.16940        2.1  \n",
      "USW00012839             US  25.79050  -80.31630        8.8  \n",
      "USW00012842             US  27.96194  -82.54030        5.8  \n",
      "USW00014898             US  44.47940  -88.13660      209.4  \n",
      "USW00013739             US  39.87327  -75.22678        3.0  \n",
      "USW00023174             US  33.93800 -118.38880       29.6  \n",
      "USW00013897             US  36.11889  -86.68917      182.9  \n",
      "US1INMR0076             US  39.87210  -86.12010      227.1  \n",
      "USW00093721             US  39.17330  -76.68400       47.5  \n",
      "USW00014922             US  44.88310  -93.22890      265.8  \n",
      "USW00012918             US  29.63806  -95.28194       13.4  \n",
      "USW00023230             US  37.72139 -122.22083        1.8  \n",
      "USW00093107             US  32.86667 -117.13333      145.4  \n",
      "USC00111550             US  41.85580  -87.60940      177.7  \n",
      "US1AZMR0451             US  33.45520 -111.93160      375.2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\2151444998.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM weather_stations\", conn, index_col='weather_station_id')\n"
     ]
    }
   ],
   "source": [
    "# Ingest Weather Stations\n",
    "\n",
    "stadiums_df = pd.read_csv('nfl_stadiums.csv')\n",
    "weather_stations_df = stadiums_df[['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION']]\n",
    "df = weather_stations_df.dropna()\n",
    "\n",
    "# Get current stations and convert to list\n",
    "current_weather_stations = pd.read_sql(\"SELECT weather_station_id FROM weather_stations;\", conn)\n",
    "cws = current_weather_stations['weather_station_id'].tolist()\n",
    "\n",
    "for x in df.index:\n",
    "    weather_station_id = df['STATION'].loc[x]\n",
    "    \n",
    "    # Only proceed if station is new\n",
    "    if weather_station_id not in cws:\n",
    "        cws.append(weather_station_id) # Make sure a station isn't inserted twice\n",
    "        name = df['NAME'].loc[x]\n",
    "        latitude = df['LATITUDE'].loc[x]\n",
    "        longitude = df['LONGITUDE'].loc[x]\n",
    "        elevation = df['ELEVATION'].loc[x]\n",
    "\n",
    "        # Get state and country codes\n",
    "        name, state_country = name.split(', ')\n",
    "        state, country = state_country.split(' ')\n",
    "\n",
    "        cursor.execute('''\n",
    "            INSERT INTO weather_stations (weather_station_id, name, state, country, latitude, longitude, elevation)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (weather_station_id, name, state, country, latitude, longitude, elevation))\n",
    "        print(f\"Inserted station {weather_station_id}: {name}\")\n",
    "        \n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "df = pd.read_sql(\"SELECT * FROM weather_stations\", conn, index_col='weather_station_id')\n",
    "print(f\"Number of records: {len(cws)}\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5dce61e-ad0c-4ee2-8a4a-7a9f071bb76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3946041491.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_stadiums = pd.read_sql(\"SELECT name FROM stadiums;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted stadium: Acrisure Stadium\n",
      "Inserted stadium: Alamo Dome\n",
      "Inserted stadium: Allegiant Stadium\n",
      "Inserted stadium: Allianz Arena\n",
      "Inserted stadium: Alltel Stadium\n",
      "Inserted stadium: Alumni Stadium\n",
      "Inserted stadium: Anaheim Stadium\n",
      "Inserted stadium: Arrowhead Stadium\n",
      "Inserted stadium: AT&T Stadium\n",
      "Inserted stadium: Atlanta-Fulton County Stadium\n",
      "Inserted stadium: Balboa Stadium\n",
      "Inserted stadium: Bank of America Stadium\n",
      "Inserted stadium: Bills Stadium\n",
      "Inserted stadium: Busch Memorial Stadium\n",
      "Inserted stadium: Caesars Superdome\n",
      "Inserted stadium: Candlestick Park\n",
      "Inserted stadium: CenturyLink Field\n",
      "Inserted stadium: Cinergy Field\n",
      "Inserted stadium: Cleveland Municipal Stadium\n",
      "Inserted stadium: Cotton Bowl\n",
      "Inserted stadium: Cowboys Stadium\n",
      "Inserted stadium: Dolphin Stadium\n",
      "Inserted stadium: Edward Jones Dome\n",
      "Inserted stadium: Empower Field at Mile High\n",
      "Inserted stadium: Estadio Azteca\n",
      "Inserted stadium: EverBank Field\n",
      "Inserted stadium: FedEx Field\n",
      "Inserted stadium: Fenway Park\n",
      "Inserted stadium: FirstEnergy Stadium\n",
      "Inserted stadium: Ford Field\n",
      "Inserted stadium: Foxboro Stadium\n",
      "Inserted stadium: Franklin Field\n",
      "Inserted stadium: GEHA Field at Arrowhead Stadium\n",
      "Inserted stadium: Georgia Dome\n",
      "Inserted stadium: Giants Stadium\n",
      "Inserted stadium: Gillette Stadium\n",
      "Inserted stadium: Hard Rock Stadium\n",
      "Inserted stadium: Harvard Stadium\n",
      "Inserted stadium: Heinz Field\n",
      "Inserted stadium: Highmark Stadium\n",
      "Inserted stadium: Houlihan's Stadium\n",
      "Inserted stadium: Houston Astrodome\n",
      "Inserted stadium: Hubert H. Humphrey Metrodome\n",
      "Inserted stadium: Husky Stadium\n",
      "Inserted stadium: Jack Murphy Stadium\n",
      "Inserted stadium: Joe Robbie Stadium\n",
      "Inserted stadium: Kansas City Municipal Stadium\n",
      "Inserted stadium: Kezar Stadium\n",
      "Inserted stadium: Lambeau Field\n",
      "Inserted stadium: Legion Field\n",
      "Inserted stadium: Levi's Stadium\n",
      "Inserted stadium: Liberty Bowl Memorial Stadium\n",
      "Inserted stadium: Lincoln Financial Field\n",
      "Inserted stadium: Los Angeles Memorial Coliseum\n",
      "Inserted stadium: Louisiana Superdome\n",
      "Inserted stadium: LP Stadium\n",
      "Inserted stadium: Lucas Oil Stadium\n",
      "Inserted stadium: Lumen Field\n",
      "Inserted stadium: M&T Bank Stadium\n",
      "Inserted stadium: Mall of America Field\n",
      "Inserted stadium: Memorial Stadium (Baltimore)\n",
      "Inserted stadium: Memorial Stadium (Champaign)\n",
      "Inserted stadium: Memorial Stadium (Clemson)\n",
      "Inserted stadium: Mercedes-Benz Stadium\n",
      "Inserted stadium: Mercedes-Benz Superdome\n",
      "Inserted stadium: MetLife Stadium\n",
      "Inserted stadium: Metropolitan Stadium\n",
      "Inserted stadium: Mile High Stadium\n",
      "Inserted stadium: New Era Field\n",
      "Inserted stadium: Nippert Stadium\n",
      "Inserted stadium: Nissan Stadium\n",
      "Inserted stadium: NRG Stadium\n",
      "Inserted stadium: Oakland Coliseum\n",
      "Inserted stadium: Orange Bowl\n",
      "Inserted stadium: Paul Brown Stadium\n",
      "Inserted stadium: Paycor Stadium\n",
      "Inserted stadium: Pitt Stadium\n",
      "Inserted stadium: Pontiac Silverdome\n",
      "Inserted stadium: Pro Player Stadium\n",
      "Inserted stadium: Qualcomm Stadium\n",
      "Inserted stadium: Ralph Wilson Stadium\n",
      "Inserted stadium: Raymond James Stadium\n",
      "Inserted stadium: RCA Dome\n",
      "Inserted stadium: Reliant Stadium\n",
      "Inserted stadium: RFK Memorial Stadium\n",
      "Inserted stadium: Rice Stadium\n",
      "Inserted stadium: Rogers Centre\n",
      "Inserted stadium: Rose Bowl\n",
      "Inserted stadium: Seattle Kingdome\n",
      "Inserted stadium: Shea Stadium\n",
      "Inserted stadium: SoFi Stadium\n",
      "Inserted stadium: Soldier Field\n",
      "Inserted stadium: Sports Authority Field at Mile High\n",
      "Inserted stadium: Stanford Stadium\n",
      "Inserted stadium: State Farm Stadium\n",
      "Inserted stadium: StubHub Center\n",
      "Inserted stadium: Sun Devil Stadium\n",
      "Inserted stadium: Sun Life Stadium\n",
      "Inserted stadium: Tampa Stadium\n",
      "Inserted stadium: TCF Bank Stadium\n",
      "Inserted stadium: Texas Stadium\n",
      "Inserted stadium: Three Rivers Stadium\n",
      "Inserted stadium: TIAA Bank Field\n",
      "Inserted stadium: Tiger Stadium\n",
      "Inserted stadium: Tiger Stadium (LSU)\n",
      "Inserted stadium: Tottenham Hotspur Stadium\n",
      "Inserted stadium: Tottenham Stadium\n",
      "Inserted stadium: Tulane Stadium\n",
      "Inserted stadium: Twickenham Stadium\n",
      "Inserted stadium: U.S. Bank Stadium\n",
      "Inserted stadium: University of Phoenix Stadium\n",
      "Inserted stadium: Vanderbilt Stadium\n",
      "Inserted stadium: Veterans Stadium\n",
      "Inserted stadium: War Memorial Stadium\n",
      "Inserted stadium: Wembley Stadium\n",
      "Inserted stadium: Wrigley Field\n",
      "Inserted stadium: Yale Bowl\n",
      "Inserted stadium: Yankee Stadium\n",
      "Number of records: 118\n",
      "                             name  stadium_open  stadium_close stadium_type  \\\n",
      "stadium_id                                                                   \n",
      "1               Acrisure Stadium        2001.0            NaN      outdoor   \n",
      "2                     Alamo Dome           NaN            NaN       indoor   \n",
      "3              Allegiant Stadium        2020.0            NaN       indoor   \n",
      "4                  Allianz Arena           NaN            NaN      outdoor   \n",
      "5                 Alltel Stadium           NaN            NaN         None   \n",
      "...                          ...           ...            ...          ...   \n",
      "114         War Memorial Stadium        1960.0         1972.0      outdoor   \n",
      "115              Wembley Stadium        2007.0            NaN      outdoor   \n",
      "116                Wrigley Field        1920.0         1970.0      outdoor   \n",
      "117                    Yale Bowl           NaN            NaN      outdoor   \n",
      "118               Yankee Stadium           NaN            NaN      outdoor   \n",
      "\n",
      "                      street_address          city state postal_code country  \\\n",
      "stadium_id                                                                     \n",
      "1                 100 Art Rooney Ave    Pittsburgh    PA       15212      US   \n",
      "2                     100 Montana St   San Antonio    TX       78203      US   \n",
      "3                               None      Paradise    NV        None      US   \n",
      "4                               None        Munich  None        None      DE   \n",
      "5                               None  Jacksonville    FL        None      US   \n",
      "...                              ...           ...   ...         ...     ...   \n",
      "114                 285 Dodge Street       Buffalo    NY       14208      US   \n",
      "115                          Wembley        London  None     HA9 0WS      UK   \n",
      "116         1060 West Addison Street       Chicago    IL       60613      US   \n",
      "117                    276 Derby Ave     New Haven    CT       06516      US   \n",
      "118                             None         Bronx    NY        None      US   \n",
      "\n",
      "           weather_station_id  stadium_weather_station_code  \\\n",
      "stadium_id                                                    \n",
      "1                 USW00094823                       15212.0   \n",
      "2                        None                       78203.0   \n",
      "3                        None                           NaN   \n",
      "4                        None                           NaN   \n",
      "5                        None                           NaN   \n",
      "...                       ...                           ...   \n",
      "114                      None                       14208.0   \n",
      "115                      None                           NaN   \n",
      "116                      None                       60613.0   \n",
      "117                      None                        6516.0   \n",
      "118                      None                           NaN   \n",
      "\n",
      "           stadium_weather_type surface  \n",
      "stadium_id                               \n",
      "1                          cold   Grass  \n",
      "2                          dome    Turf  \n",
      "3                          dome   Grass  \n",
      "4                      moderate   Grass  \n",
      "5                          None    None  \n",
      "...                         ...     ...  \n",
      "114                        cold    None  \n",
      "115                    moderate    None  \n",
      "116                        cold    None  \n",
      "117                        cold   Grass  \n",
      "118                        cold    None  \n",
      "\n",
      "[118 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3946041491.py:108: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM stadiums\", conn, index_col='stadium_id')\n"
     ]
    }
   ],
   "source": [
    "# Ingest Stadiums\n",
    "\n",
    "df = pd.read_csv('nfl_stadiums.csv')\n",
    "\n",
    "# Get current stadiums and convert to list\n",
    "current_stadiums = pd.read_sql(\"SELECT name FROM stadiums;\", conn)\n",
    "cs = current_stadiums['name'].tolist()\n",
    "\n",
    "for x in df.index:\n",
    "    name = df['stadium_name'].loc[x]\n",
    "    \n",
    "    # Only proceed if stadium is new\n",
    "    if name not in cs:\n",
    "        cs.append(name)  # Make sure a stadium isn't inserted twice\n",
    "        location = df['stadium_location'].loc[x]\n",
    "        stadium_open = df['stadium_open'].loc[x]\n",
    "        stadium_close = df['stadium_close'].loc[x]\n",
    "        stadium_type = df['stadium_type'].loc[x]\n",
    "        address = df['stadium_address'].loc[x]\n",
    "        stadium_weather_station_code = df['stadium_weather_station_code'].loc[x]\n",
    "        weather_station_id = df['STATION'].loc[x]\n",
    "        stadium_weather_type = df['stadium_weather_type'].loc[x]\n",
    "        surface = df['stadium_surface'].loc[x]\n",
    "        street_address = city = state = postal_code = country = None\n",
    "\n",
    "        ### cleaning\n",
    "        ## address --> street_address, city, state, zip, country\n",
    "        # Get city/state/country from location\n",
    "        if pd.notna(location):\n",
    "            if 'UK' in location:\n",
    "                city, country = location.split(', ')\n",
    "            elif 'MX' in str(stadium_weather_station_code):\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'MX'\n",
    "            elif 'Canada' in location:\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'CA'\n",
    "            elif 'Germany' in location:\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'DE'\n",
    "            elif ',' in location:  # US locations\n",
    "                city, state = location.split(', ')\n",
    "                country = 'US'\n",
    "        # Parse address if it exists\n",
    "        if pd.notna(address):\n",
    "            if country == 'UK':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                postal_code = parts[1].replace('London', '').strip()\n",
    "            elif country == 'MX': # no clue how to handle this one\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "            elif country == 'CA':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                state = parts[2].split(' ')[0]\n",
    "                postal_code = parts[2].split(' ')[1] + ' ' + parts[2].split(' ')[2]\n",
    "            elif country == 'US':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                postal_code = parts[-1].split(' ')[-1]\n",
    "        \n",
    "        \n",
    "        ## stadium_open\n",
    "        stadium_open = int_convert(stadium_open)\n",
    "        \n",
    "        \n",
    "        ## stadium_close\n",
    "        stadium_close = int_convert(stadium_close)\n",
    "        \n",
    "        \n",
    "        ## stadium_weather_station_code\n",
    "        stadium_weather_station_code = int_convert(stadium_weather_station_code)\n",
    "                \n",
    "                \n",
    "        ## surface\n",
    "        if pd.notna(surface):  # Check if surface exists before lowercase\n",
    "            if 'grass' in surface.lower():\n",
    "                surface = 'Grass'\n",
    "            elif 'turf' in surface.lower():\n",
    "                surface = 'Turf'\n",
    "        else:\n",
    "            surface = None\n",
    "            \n",
    "        \n",
    "        ## weather_station_id\n",
    "        weather_station_id = handle_na(weather_station_id)\n",
    "        \n",
    "        \n",
    "        ## stadium_type\n",
    "        stadium_type = handle_na(stadium_type)\n",
    "            \n",
    "            \n",
    "        ## stadium_weather_type\n",
    "        stadium_weather_type = handle_na(stadium_weather_type)\n",
    "          \n",
    "            \n",
    "        ### Ingest\n",
    "        cursor.execute('''\n",
    "            INSERT INTO stadiums (name, stadium_open, stadium_close, stadium_type, street_address, city, state, postal_code, country, weather_station_id, stadium_weather_station_code, stadium_weather_type, surface)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (name, stadium_open, stadium_close, stadium_type, street_address, city, state, postal_code, country, weather_station_id, stadium_weather_station_code, stadium_weather_type, surface))\n",
    "        print(f\"Inserted stadium: {name}\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "df = pd.read_sql(\"SELECT * FROM stadiums\", conn, index_col='stadium_id')\n",
    "print(f\"Number of records: {len(cs)}\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4372267-0032-4676-9ee4-606689ce5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted pre-2002 record for team: Arizona Cardinals\n",
      "Inserted pre-2002 record for team: Atlanta Falcons\n",
      "Inserted pre-2002 record for team: Baltimore Colts\n",
      "Inserted pre-2002 record for team: Baltimore Ravens\n",
      "Inserted pre-2002 record for team: Boston Patriots\n",
      "Inserted pre-2002 record for team: Buffalo Bills\n",
      "Inserted pre-2002 record for team: Carolina Panthers\n",
      "Inserted pre-2002 record for team: Chicago Bears\n",
      "Inserted pre-2002 record for team: Cincinnati Bengals\n",
      "Inserted pre-2002 record for team: Cleveland Browns\n",
      "Inserted pre-2002 record for team: Dallas Cowboys\n",
      "Inserted pre-2002 record for team: Denver Broncos\n",
      "Inserted pre-2002 record for team: Detroit Lions\n",
      "Inserted pre-2002 record for team: Green Bay Packers\n",
      "Inserted pre-2002 record for team: Houston Oilers\n",
      "Inserted pre-2002 record for team: Houston Texans\n",
      "Inserted pre-2002 record for team: Jacksonville Jaguars\n",
      "Inserted pre-2002 record for team: Kansas City Chiefs\n",
      "Inserted pre-2002 record for team: Las Vegas Raiders\n",
      "Inserted pre-2002 record for team: Los Angeles Chargers\n",
      "Inserted pre-2002 record for team: Los Angeles Rams\n",
      "Inserted pre-2002 record for team: Miami Dolphins\n",
      "Inserted pre-2002 record for team: Minnesota Vikings\n",
      "Inserted pre-2002 record for team: New Orleans Saints\n",
      "Inserted pre-2002 record for team: New York Giants\n",
      "Inserted pre-2002 record for team: New York Jets\n",
      "Inserted pre-2002 record for team: Philadelphia Eagles\n",
      "Inserted pre-2002 record for team: Pittsburgh Steelers\n",
      "Inserted pre-2002 record for team: San Francisco 49ers\n",
      "Inserted pre-2002 record for team: Seattle Seahawks\n",
      "Inserted pre-2002 record for team: Tampa Bay Buccaneers\n",
      "Inserted pre-2002 record for team: Washington Commanders\n",
      "Updated record for team: Atlanta Falcons\n",
      "Updated record for team: Baltimore Colts\n",
      "Updated record for team: Baltimore Ravens\n",
      "Updated record for team: Carolina Panthers\n",
      "Updated record for team: Chicago Bears\n",
      "Updated record for team: Cincinnati Bengals\n",
      "Updated record for team: Cleveland Browns\n",
      "Updated record for team: Detroit Lions\n",
      "Updated record for team: Green Bay Packers\n",
      "Updated record for team: Houston Oilers\n",
      "Updated record for team: Houston Texans\n",
      "Updated record for team: Indianapolis Colts\n",
      "Updated record for team: Jacksonville Jaguars\n",
      "Updated record for team: Las Vegas Raiders\n",
      "Updated record for team: Los Angeles Raiders\n",
      "Updated record for team: Minnesota Vikings\n",
      "Updated record for team: New England Patriots\n",
      "Updated record for team: New Orleans Saints\n",
      "Updated record for team: Oakland Raiders\n",
      "Updated record for team: Phoenix Cardinals\n",
      "Updated record for team: Pittsburgh Steelers\n",
      "Updated record for team: San Diego Chargers\n",
      "Updated record for team: Seattle Seahawks\n",
      "Updated record for team: St. Louis Cardinals\n",
      "Updated record for team: St. Louis Rams\n",
      "Updated record for team: Tampa Bay Buccaneers\n",
      "Updated record for team: Tennessee Oilers\n",
      "Updated record for team: Tennessee Titans\n",
      "Updated record for team: Washington Football Team\n",
      "Updated record for team: Washington Redskins\n",
      "\n",
      "Current Teams table:\n",
      "Number of current teams: 32\n",
      "    team_id                  name  name_short team_id_pfr conference   division\n",
      "0      BUF         Buffalo Bills       Bills         BUF        AFC   AFC East\n",
      "1      DAL        Dallas Cowboys     Cowboys         DAL        NFC   NFC East\n",
      "2      DEN        Denver Broncos     Broncos         DEN        AFC   AFC West\n",
      "3       KC    Kansas City Chiefs      Chiefs         KAN        AFC   AFC West\n",
      "4      MIA        Miami Dolphins    Dolphins         MIA        AFC   AFC East\n",
      "5      NYG       New York Giants      Giants         NYG        NFC   NFC East\n",
      "6      NYJ         New York Jets        Jets         NYJ        NFC   AFC East\n",
      "7      PHI   Philadelphia Eagles      Eagles         PHI        NFC   NFC East\n",
      "8       SF   San Francisco 49ers       49ers         SFO        NFC   NFC West\n",
      "9      ATL       Atlanta Falcons     Falcons         ATL        NFC  NFC South\n",
      "10     BAL      Baltimore Ravens      Ravens         RAV        AFC  AFC North\n",
      "11     CAR     Carolina Panthers    Panthers         CAR        NFC  NFC South\n",
      "12     CHI         Chicago Bears       Bears         CHI        NFC  NFC North\n",
      "13     CIN    Cincinnati Bengals     Bengals         CIN        AFC  AFC North\n",
      "14     CLE      Cleveland Browns      Browns         CLE        AFC  AFC North\n",
      "15     DET         Detroit Lions       Lions         DET        NFC  NFC North\n",
      "16      GB     Green Bay Packers     Packers         GNB        NFC  NFC North\n",
      "17     HOU        Houston Texans      Texans         HTX        AFC  AFC South\n",
      "18     IND    Indianapolis Colts       Colts         CLT        AFC  AFC South\n",
      "19     JAX  Jacksonville Jaguars     Jaguars         JAX        AFC  AFC South\n",
      "20     MIN     Minnesota Vikings     Vikings         MIN        NFC  NFC North\n",
      "21      NE  New England Patriots    Patriots         NWE        AFC   AFC East\n",
      "22      NO    New Orleans Saints      Saints         NOR        NFC  NFC South\n",
      "23     LVR       Oakland Raiders     Raiders         RAI        AFC   AFC West\n",
      "24     PIT   Pittsburgh Steelers    Steelers         PIT        AFC  AFC North\n",
      "25     LAC    San Diego Chargers    Chargers         SDG        AFC   AFC West\n",
      "26     SEA      Seattle Seahawks    Seahawks         SEA        NFC   NFC West\n",
      "27     ARI   St. Louis Cardinals   Cardinals         ARI        NFC       None\n",
      "28     LAR        St. Louis Rams        Rams         RAM        NFC       None\n",
      "29      TB  Tampa Bay Buccaneers  Buccaneers         TAM        NFC  NFC South\n",
      "30     TEN      Tennessee Titans      Titans         OTI        AFC  AFC South\n",
      "31     WAS   Washington Redskins  Washington         WAS        NFC   NFC East\n",
      "\n",
      "Team History table:\n",
      "Number of history records: 62\n",
      "     team_history_id team_id                      name  name_short team_id_pfr  \\\n",
      "0                 1     ARI         Arizona Cardinals   Cardinals         CRD   \n",
      "1                 2     ATL           Atlanta Falcons     Falcons         ATL   \n",
      "2                 3     IND           Baltimore Colts       Colts         CLT   \n",
      "3                 4     BAL          Baltimore Ravens      Ravens         RAV   \n",
      "4                 5      NE           Boston Patriots    Patriots         NWE   \n",
      "..              ...     ...                       ...         ...         ...   \n",
      "57               58      TB      Tampa Bay Buccaneers  Buccaneers         TAM   \n",
      "58               59     TEN          Tennessee Oilers      Oilers         OTI   \n",
      "59               60     TEN          Tennessee Titans      Titans         OTI   \n",
      "60               61     WAS  Washington Football Team  Washington         WAS   \n",
      "61               62     WAS       Washington Redskins  Washington         WAS   \n",
      "\n",
      "   conference     division  \n",
      "0         NFC     NFC West  \n",
      "1         NFC     NFC West  \n",
      "2         AFC     AFC East  \n",
      "3         AFC  AFC Central  \n",
      "4         AFC         None  \n",
      "..        ...          ...  \n",
      "57        NFC    NFC South  \n",
      "58        AFC         None  \n",
      "59        AFC    AFC South  \n",
      "60        NFC     NFC East  \n",
      "61        NFC     NFC East  \n",
      "\n",
      "[62 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\257198371.py:91: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  teams_df = pd.read_sql(\"SELECT * FROM current_teams\", conn)\n",
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\257198371.py:95: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  history_df = pd.read_sql(\"SELECT * FROM team_history\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Ingest Teams\n",
    "df = pd.read_csv('nfl_teams.csv')\n",
    "\n",
    "# First pass: Insert pre-2002 data\n",
    "for x in df.index:\n",
    "    team_id = df['team_id'].loc[x]\n",
    "    name = df['team_name'].loc[x]\n",
    "    name_short = df['team_name_short'].loc[x]\n",
    "    team_id_pfr = df['team_id_pfr'].loc[x]\n",
    "    conference = df['team_conference_pre2002'].loc[x]\n",
    "    division = df['team_division_pre2002'].loc[x]\n",
    "\n",
    "    # Clean data\n",
    "    team_id = handle_na(team_id)\n",
    "    name = handle_na(name)\n",
    "    name_short = handle_na(name_short)\n",
    "    team_id_pfr = handle_na(team_id_pfr)\n",
    "    conference = handle_na(conference)\n",
    "    division = handle_na(division)\n",
    "    \n",
    "    # Check if team_id exists\n",
    "    cursor.execute('SELECT team_id FROM current_teams WHERE team_id = %s', (team_id,))\n",
    "    exists = cursor.fetchone()\n",
    "    \n",
    "    if not exists:\n",
    "        # Insert into current_teams only if it doesn't exist\n",
    "        cursor.execute('''\n",
    "            INSERT INTO current_teams (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "        \n",
    "        # Insert into team_history\n",
    "        cursor.execute('''\n",
    "            INSERT INTO team_history \n",
    "            (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "        \n",
    "        print(f\"Inserted pre-2002 record for team: {name}\")\n",
    "    \n",
    "# Second pass: Check for changes and update if needed\n",
    "for x in df.index:\n",
    "    team_id = df['team_id'].loc[x]\n",
    "    name = df['team_name'].loc[x]\n",
    "    name_short = df['team_name_short'].loc[x]\n",
    "    team_id_pfr = df['team_id_pfr'].loc[x]\n",
    "    conference = df['team_conference'].loc[x]\n",
    "    division = df['team_division'].loc[x]\n",
    "\n",
    "    # Clean data\n",
    "    team_id = handle_na(team_id)\n",
    "    name = handle_na(name)\n",
    "    name_short = handle_na(name_short)\n",
    "    team_id_pfr = handle_na(team_id_pfr)\n",
    "    conference = handle_na(conference)\n",
    "    division = handle_na(division)\n",
    "\n",
    "    # Get current values\n",
    "    cursor.execute('''\n",
    "        SELECT name, name_short, team_id_pfr, conference, division \n",
    "        FROM current_teams \n",
    "        WHERE team_id = %s;\n",
    "    ''', (team_id,))  # Fixed tuple syntax\n",
    "    \n",
    "    current = cursor.fetchone()\n",
    "    if current:\n",
    "        current_values = list(current)\n",
    "        new_values = [name, name_short, team_id_pfr, conference, division]\n",
    "        \n",
    "        # Check if any values have changed\n",
    "        if current_values != new_values:            \n",
    "            cursor.execute('''\n",
    "                INSERT INTO team_history \n",
    "                (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s);\n",
    "            ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "            \n",
    "            # Update current_teams\n",
    "            cursor.execute('''\n",
    "                UPDATE current_teams \n",
    "                SET name = %s, name_short = %s, team_id_pfr = %s, conference = %s, division = %s\n",
    "                WHERE team_id = %s;\n",
    "            ''', (name, name_short, team_id_pfr, conference, division, team_id))\n",
    "            \n",
    "            print(f\"Updated record for team: {name}\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nCurrent Teams table:\")\n",
    "teams_df = pd.read_sql(\"SELECT * FROM current_teams\", conn)\n",
    "print(f\"Number of current teams: {len(teams_df)}\\n\", teams_df)\n",
    "\n",
    "print(\"\\nTeam History table:\")\n",
    "history_df = pd.read_sql(\"SELECT * FROM team_history\", conn)\n",
    "print(f\"Number of history records: {len(history_df)}\\n\", history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffcdf7fa-3858-450b-a112-c1d21ff3cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1053402355.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_customers = pd.read_sql('SELECT customer_id FROM customers;', conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 customers (5.0%) | Last 100 customers: 0:04 | Total time: 0:04\n",
      "Processed 200 customers (10.0%) | Last 100 customers: 0:04 | Total time: 0:09\n",
      "Processed 300 customers (15.0%) | Last 100 customers: 0:04 | Total time: 0:14\n",
      "Processed 400 customers (20.0%) | Last 100 customers: 0:04 | Total time: 0:19\n",
      "Processed 500 customers (25.0%) | Last 100 customers: 0:05 | Total time: 0:24\n",
      "Processed 600 customers (30.0%) | Last 100 customers: 0:05 | Total time: 0:30\n",
      "Processed 700 customers (35.0%) | Last 100 customers: 0:04 | Total time: 0:35\n",
      "Processed 800 customers (40.0%) | Last 100 customers: 0:04 | Total time: 0:39\n",
      "Processed 900 customers (45.0%) | Last 100 customers: 0:04 | Total time: 0:44\n",
      "Processed 1000 customers (50.0%) | Last 100 customers: 0:04 | Total time: 0:48\n",
      "Processed 1100 customers (55.0%) | Last 100 customers: 0:04 | Total time: 0:53\n",
      "Processed 1200 customers (60.0%) | Last 100 customers: 0:05 | Total time: 0:58\n",
      "Processed 1300 customers (65.0%) | Last 100 customers: 0:05 | Total time: 1:04\n",
      "Processed 1400 customers (70.0%) | Last 100 customers: 0:04 | Total time: 1:09\n",
      "Processed 1500 customers (75.0%) | Last 100 customers: 0:04 | Total time: 1:13\n",
      "Processed 1600 customers (80.0%) | Last 100 customers: 0:04 | Total time: 1:18\n",
      "Processed 1700 customers (85.0%) | Last 100 customers: 0:04 | Total time: 1:22\n",
      "Processed 1800 customers (90.0%) | Last 100 customers: 0:04 | Total time: 1:27\n",
      "Processed 1900 customers (95.0%) | Last 100 customers: 0:04 | Total time: 1:32\n",
      "\n",
      "Total processing time: 1:32\n",
      "\n",
      "Customers table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1053402355.py:76: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customers_df = pd.read_sql(\"SELECT * FROM customers\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers: 2000\n",
      "      customer_id first_name last_name  age customer_type  customer_since  \\\n",
      "0               1   Coraline    Flores   23        online            2022   \n",
      "1               2    Presley     Ortiz   41        online            2021   \n",
      "2               3       Reid    Knight   40        online            2023   \n",
      "3               4   Clarissa  Chandler   43         local            2023   \n",
      "4               5      Isaac    Vaughn   23         phone            2023   \n",
      "...           ...        ...       ...  ...           ...             ...   \n",
      "1995         1996     Maxine      Pope   36         local            2020   \n",
      "1996         1997    Camilla     Wolfe   46         local            2020   \n",
      "1997         1998     Karina    Knight   36         local            2020   \n",
      "1998         1999  Sebastian   Winters   55         local            2020   \n",
      "1999         2000   Hadassah      Wade   29         local            2021   \n",
      "\n",
      "      income  household_size mode_color  \n",
      "0     116000               1        red  \n",
      "1     111000               1       blue  \n",
      "2      55000               1      green  \n",
      "3      32000               2     orange  \n",
      "4      46000               1       blue  \n",
      "...      ...             ...        ...  \n",
      "1995   29000               2       blue  \n",
      "1996   62000               2     purple  \n",
      "1997   64000               1     orange  \n",
      "1998   93000               1     purple  \n",
      "1999  150000               4      black  \n",
      "\n",
      "[2000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Customers\n",
    "\n",
    "# df = pd.read_sql(\"SELECT * FROM customer_table;\", pymssql_conn)\n",
    "df = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# Get current customers and convert to list\n",
    "current_customers = pd.read_sql('SELECT customer_id FROM customers;', conn)\n",
    "cc = current_customers['customer_id'].tolist()\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each customer\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    customer_id = int_convert(df['customer_id'].loc[x])\n",
    "    \n",
    "    # Only proceed if customer is new\n",
    "    if customer_id not in cc:\n",
    "        cc.append(customer_id)\n",
    "        \n",
    "        customer_name = df['customer_name'].loc[x]\n",
    "        age = int_convert(df['customer_age'].loc[x])\n",
    "        customer_type = handle_na(df['customer_type'].loc[x])\n",
    "        customer_since = int_convert(df['customer_since'].loc[x])\n",
    "        income = int_convert(df['customer_income'].loc[x])\n",
    "        household_size = int_convert(df['household_size'].loc[x])\n",
    "        mode_color = handle_na(df['mode_color'].loc[x])\n",
    "        \n",
    "        # Name\n",
    "        name_parts = customer_name.split(' ')\n",
    "        if len(name_parts) == 2:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = name_parts[1]\n",
    "        else:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = ' '.join(name_parts[1:])\n",
    "        \n",
    "        # Insert into customers table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO customers \n",
    "            (customer_id, first_name, last_name, age, customer_type, \n",
    "             customer_since, income, household_size, mode_color)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (customer_id, first_name, last_name, age, customer_type, \n",
    "              customer_since, income, household_size, mode_color))\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:  # Print progress every 100 records\n",
    "            current_time = time.time()\n",
    "            elapsed_since_last = current_time - last_check\n",
    "            total_elapsed = current_time - start_time\n",
    "    \n",
    "            last_check_min = int(elapsed_since_last // 60)\n",
    "            last_check_sec = int(elapsed_since_last % 60)\n",
    "            total_min = int(total_elapsed // 60)\n",
    "            total_sec = int(total_elapsed % 60)\n",
    "    \n",
    "            percent_complete = (counter / len(df)) * 100\n",
    "            \n",
    "            print(f\"Processed {counter} customers ({percent_complete:.1f}%) | Last 100 customers: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d}\")\n",
    "            last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nCustomers table:\")\n",
    "customers_df = pd.read_sql(\"SELECT * FROM customers\", conn)\n",
    "print(f\"Number of customers: {len(cc)}\")\n",
    "print(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a6bd5dc-67eb-4e4d-9144-90fa887c4efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3754371467.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_games = pd.read_sql(\"SELECT game_id FROM games;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 games (4.1%) | Last 100 games: 0:18 | Total time: 0:18\n",
      "Processed 200 games (8.1%) | Last 100 games: 0:18 | Total time: 0:37\n",
      "Processed 300 games (12.2%) | Last 100 games: 0:19 | Total time: 0:56\n",
      "Processed 400 games (16.3%) | Last 100 games: 0:18 | Total time: 1:14\n",
      "Processed 500 games (20.3%) | Last 100 games: 0:19 | Total time: 1:34\n",
      "Processed 600 games (24.4%) | Last 100 games: 0:18 | Total time: 1:53\n",
      "Processed 700 games (28.5%) | Last 100 games: 0:18 | Total time: 2:12\n",
      "Processed 800 games (32.5%) | Last 100 games: 0:20 | Total time: 2:32\n",
      "Processed 900 games (36.6%) | Last 100 games: 0:18 | Total time: 2:50\n",
      "Processed 1000 games (40.7%) | Last 100 games: 0:20 | Total time: 3:11\n",
      "Added new stadium: Dignity Health Sports Park with ID: 119\n",
      "Processed 1100 games (44.8%) | Last 100 games: 0:19 | Total time: 3:31\n",
      "Processed 1200 games (48.8%) | Last 100 games: 0:19 | Total time: 3:50\n",
      "Processed 1300 games (52.9%) | Last 100 games: 0:19 | Total time: 4:10\n",
      "Processed 1400 games (57.0%) | Last 100 games: 0:19 | Total time: 4:30\n",
      "Processed 1500 games (61.0%) | Last 100 games: 0:19 | Total time: 4:49\n",
      "Processed 1600 games (65.1%) | Last 100 games: 0:20 | Total time: 5:10\n",
      "Processed 1700 games (69.2%) | Last 100 games: 0:19 | Total time: 5:30\n",
      "Processed 1800 games (73.2%) | Last 100 games: 0:20 | Total time: 5:50\n",
      "Processed 1900 games (77.3%) | Last 100 games: 0:20 | Total time: 6:10\n",
      "Processed 2000 games (81.4%) | Last 100 games: 0:19 | Total time: 6:30\n",
      "Processed 2100 games (85.4%) | Last 100 games: 0:18 | Total time: 6:48\n",
      "Processed 2200 games (89.5%) | Last 100 games: 0:18 | Total time: 7:07\n",
      "Processed 2300 games (93.6%) | Last 100 games: 0:18 | Total time: 7:25\n",
      "Added new stadium: Frankfurt Stadium with ID: 120\n",
      "Processed 2400 games (97.6%) | Last 100 games: 0:18 | Total time: 7:44\n",
      "\n",
      "Total processing time: 7:55\n",
      "\n",
      "Games table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3754371467.py:155: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  games_df = pd.read_sql(\"SELECT * FROM games;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games: 2458\n",
      "             game_id schedule_date  schedule_season  schedule_week  \\\n",
      "0      201501-NE-PIT    2015-09-10             2015              1   \n",
      "1      201501-ARI-NO    2015-09-13             2015              1   \n",
      "2     201501-BUF-IND    2015-09-13             2015              1   \n",
      "3      201501-CHI-GB    2015-09-13             2015              1   \n",
      "4     201501-DAL-NYG    2015-09-13             2015              1   \n",
      "...              ...           ...              ...            ...   \n",
      "2453   202320-BUF-KC    2024-01-21             2023             20   \n",
      "2454   202320-DET-TB    2024-01-21             2023             20   \n",
      "2455   202321-BAL-KC    2024-01-28             2023             21   \n",
      "2456   202321-SF-DET    2024-01-28             2023             21   \n",
      "2457    202322-KC-SF    2024-02-11             2023             22   \n",
      "\n",
      "      schedule_playoff playoff_type team_id_home team_id_away  score_home  \\\n",
      "0                False         None           NE          PIT          28   \n",
      "1                False         None          ARI           NO          31   \n",
      "2                False         None          BUF          IND          27   \n",
      "3                False         None          CHI           GB          23   \n",
      "4                False         None          DAL          NYG          27   \n",
      "...                ...          ...          ...          ...         ...   \n",
      "2453              True     Division          BUF           KC          24   \n",
      "2454              True     Division          DET           TB          31   \n",
      "2455              True   Conference          BAL           KC          10   \n",
      "2456              True   Conference           SF          DET          34   \n",
      "2457              True    Superbowl           KC           SF          25   \n",
      "\n",
      "      score_away  ... spread_favorite  over_under_line  stadium_id  \\\n",
      "0             21  ...            -7.0             51.0          36   \n",
      "1             19  ...            -2.5             48.5         111   \n",
      "2             14  ...            -1.0             44.5          81   \n",
      "3             31  ...            -6.5             48.5          92   \n",
      "4             26  ...            -7.0             52.5          21   \n",
      "...          ...  ...             ...              ...         ...   \n",
      "2453          27  ...            -2.5             46.0          40   \n",
      "2454          23  ...            -6.0             49.5          30   \n",
      "2455          17  ...            -4.5             44.0          59   \n",
      "2456          31  ...            -7.5             53.5          51   \n",
      "2457          22  ...            -2.0             47.0           3   \n",
      "\n",
      "      stadium_neutral  weather_temperature  weather_wind_mph  \\\n",
      "0               False                 64.0               9.0   \n",
      "1               False                 72.0               0.0   \n",
      "2               False                 53.0               7.0   \n",
      "3               False                 68.0               4.0   \n",
      "4               False                 72.0               0.0   \n",
      "...               ...                  ...               ...   \n",
      "2453            False                 25.0              11.0   \n",
      "2454            False                 72.0               0.0   \n",
      "2455            False                 47.0               7.0   \n",
      "2456            False                 69.0               5.0   \n",
      "2457             True                 72.0               0.0   \n",
      "\n",
      "      weather_humidity  weather_detail winner_ou winner_line  \n",
      "0                  NaN            rain     under        home  \n",
      "1                  NaN          indoor      over        home  \n",
      "2                  NaN            None     under        home  \n",
      "3                  NaN            None      over        away  \n",
      "4                  NaN          indoor      over        home  \n",
      "...                ...             ...       ...         ...  \n",
      "2453              67.0            None      over        away  \n",
      "2454               NaN          indoor      over        home  \n",
      "2455              83.0            None     under        away  \n",
      "2456              55.0            None      over        home  \n",
      "2457               NaN          indoor      push        home  \n",
      "\n",
      "[2458 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Games\n",
    "\n",
    "# Read games data\n",
    "df = pd.read_csv('spread_scores-2.csv')\n",
    "\n",
    "# Filter for games from 2015 onwards\n",
    "df = df[df['schedule_season'] >= 2015]\n",
    "\n",
    "# Get current games and convert to list\n",
    "current_games = pd.read_sql(\"SELECT game_id FROM games;\", conn)\n",
    "cg = current_games['game_id'].tolist()\n",
    "\n",
    "TEAM_ID_CORRECTIONS = {\n",
    "    'LV': 'LVR',\n",
    "    }\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each game\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    # Construct game_id \n",
    "    season = str(df['schedule_season'].loc[x])\n",
    "    \n",
    "    weeknum = df['schedule_week'].loc[x]\n",
    "    if weeknum == \"Wildcard\":\n",
    "        playoff_type = \"Wildcard\"\n",
    "        weeknum = \"19\"\n",
    "    elif weeknum == \"Division\":\n",
    "        playoff_type = \"Division\"\n",
    "        weeknum = \"20\"\n",
    "    elif weeknum == \"Conference\":\n",
    "        playoff_type = \"Conference\"\n",
    "        weeknum = \"21\"\n",
    "    elif weeknum == \"Superbowl\":\n",
    "        playoff_type = \"Superbowl\"\n",
    "        weeknum = \"22\"\n",
    "    else:\n",
    "        playoff_type = None\n",
    "        weeknum = str(weeknum)\n",
    "        \n",
    "    if len(weeknum) < 2: \n",
    "        weeknum = \"0\" + weeknum\n",
    "\n",
    "    weekstring = weeknum\n",
    "    weeknum = int_convert(weeknum)\n",
    "    \n",
    "    cursor.execute(f\"SELECT DISTINCT team_id FROM team_history WHERE name = '{df['team_home'].loc[x]}';\")\n",
    "    home_id = cursor.fetchone()[0]\n",
    "    home_id = TEAM_ID_CORRECTIONS.get(home_id, home_id)\n",
    "    \n",
    "    cursor.execute(f\"SELECT DISTINCT team_id FROM team_history WHERE name = '{df['team_away'].loc[x]}';\")\n",
    "    away_id = cursor.fetchone()[0]\n",
    "    away_id = TEAM_ID_CORRECTIONS.get(away_id, away_id)\n",
    "    \n",
    "    game_id = f\"{season}{weekstring}-{home_id}-{away_id}\"\n",
    "    \n",
    "    # Only proceed if game is new\n",
    "    if game_id not in cg:\n",
    "        cg.append(game_id)\n",
    "        \n",
    "        # Get required data\n",
    "        schedule_date = datetime.strptime(df['schedule_date'].loc[x], '%m/%d/%Y')\n",
    "        schedule_season = int_convert(df['schedule_season'].loc[x])\n",
    "        schedule_week = weeknum\n",
    "        schedule_playoff = bool(df['schedule_playoff'].loc[x])\n",
    "        score_home = int_convert(df['score_home'].loc[x])\n",
    "        score_away = int_convert(df['score_away'].loc[x])\n",
    "        team_favorite_id = df['team_favorite_id'].loc[x]\n",
    "        spread_favorite = df['spread_favorite'].loc[x]\n",
    "        over_under_line = df['over_under_line'].loc[x]\n",
    "        stadium_name = df['stadium'].loc[x]\n",
    "        stadium_neutral = bool(df['stadium_neutral'].loc[x])\n",
    "        weather_temperature = int_convert(df['weather_temperature'].loc[x])\n",
    "        weather_wind_mph = int_convert(df['weather_wind_mph'].loc[x])\n",
    "        weather_humidity = int_convert(df['weather_humidity'].loc[x])\n",
    "        weather_detail = handle_na(df['weather_detail'].loc[x])        \n",
    "\n",
    "\n",
    "        # Try to find existing stadium\n",
    "        stadium_id = None\n",
    "        cursor.execute(\"SELECT stadium_id FROM stadiums WHERE name = %s;\", (stadium_name,))\n",
    "        stadium_result = cursor.fetchone()\n",
    "\n",
    "        if stadium_result:\n",
    "            stadium_id = stadium_result[0]\n",
    "        else:\n",
    "            # Insert new stadium with minimal info and get its ID\n",
    "            cursor.execute('''INSERT INTO stadiums (name) VALUES (%s);''', (stadium_name,))\n",
    "            conn.commit()\n",
    "            cursor.execute(\"SELECT stadium_id FROM stadiums WHERE name = %s;\", (stadium_name,))\n",
    "            stadium_id = cursor.fetchone()[0]\n",
    "            print(f\"Added new stadium: {stadium_name} with ID: {stadium_id}\")\n",
    "        \n",
    "        # Handle PICK\n",
    "        if team_favorite_id == 'PICK':\n",
    "            team_favorite_id = home_id  # Use home team and set spread to 0 float\n",
    "            spread_favorite = 0.0\n",
    "        else:\n",
    "            team_favorite_id = TEAM_ID_CORRECTIONS.get(team_favorite_id, team_favorite_id)\n",
    "        \n",
    "        # Calculate winner_ou and winner_line\n",
    "        total_score = score_home + score_away\n",
    "        winner_ou = get_winner_ou(total_score, over_under_line)\n",
    "        winner_line = get_winner_line(score_home, score_away, spread_favorite, team_favorite_id, home_id)\n",
    "\n",
    "        # Insert into games table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO games (\n",
    "                game_id, schedule_date, schedule_season, schedule_week, \n",
    "                schedule_playoff, playoff_type, team_id_home, team_id_away, \n",
    "                score_home, score_away, team_id_favorite, spread_favorite,\n",
    "                over_under_line, stadium_id, stadium_neutral, \n",
    "                weather_temperature, weather_wind_mph, weather_humidity,\n",
    "                weather_detail, winner_ou, winner_line) \n",
    "            VALUES (\n",
    "                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (game_id, schedule_date, schedule_season, schedule_week,\n",
    "              schedule_playoff, playoff_type, home_id, away_id,\n",
    "              score_home, score_away, team_favorite_id, spread_favorite,\n",
    "              over_under_line, stadium_id, stadium_neutral,\n",
    "              weather_temperature, weather_wind_mph, weather_humidity,\n",
    "              weather_detail, winner_ou, winner_line))\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:  # Print progress every 100 records\n",
    "            current_time = time.time()\n",
    "            elapsed_since_last = current_time - last_check\n",
    "            total_elapsed = current_time - start_time\n",
    "    \n",
    "            last_check_min = int(elapsed_since_last // 60)\n",
    "            last_check_sec = int(elapsed_since_last % 60)\n",
    "            total_min = int(total_elapsed // 60)\n",
    "            total_sec = int(total_elapsed % 60)\n",
    "    \n",
    "            percent_complete = (counter / len(df)) * 100\n",
    "            \n",
    "            print(f\"Processed {counter} games ({percent_complete:.1f}%) | Last 100 games: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d}\")\n",
    "            last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nGames table:\")\n",
    "games_df = pd.read_sql(\"SELECT * FROM games;\", conn)\n",
    "print(f\"Number of games: {len(cg)}\")\n",
    "print(games_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "271b9f85-0c0a-4f8b-a641-0d1305806292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\2729435184.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_bets = pd.read_sql(\"SELECT bet_id FROM bets;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 bets (0.8%) | Last 1000 bets: 2:13 | Total time: 2:13\n",
      "Processed 2000 bets (1.6%) | Last 1000 bets: 2:09 | Total time: 4:22\n",
      "Processed 3000 bets (2.4%) | Last 1000 bets: 2:20 | Total time: 6:43\n",
      "Processed 4000 bets (3.2%) | Last 1000 bets: 2:12 | Total time: 8:56\n",
      "Processed 5000 bets (4.0%) | Last 1000 bets: 2:24 | Total time: 11:21\n",
      "Processed 6000 bets (4.8%) | Last 1000 bets: 2:24 | Total time: 13:45\n",
      "Processed 7000 bets (5.6%) | Last 1000 bets: 2:20 | Total time: 16:06\n",
      "Processed 8000 bets (6.3%) | Last 1000 bets: 2:16 | Total time: 18:23\n",
      "Processed 9000 bets (7.1%) | Last 1000 bets: 2:15 | Total time: 20:38\n",
      "Processed 10000 bets (7.9%) | Last 1000 bets: 2:18 | Total time: 22:56\n",
      "Processed 11000 bets (8.7%) | Last 1000 bets: 2:13 | Total time: 25:10\n",
      "Processed 12000 bets (9.5%) | Last 1000 bets: 2:09 | Total time: 27:20\n",
      "Processed 13000 bets (10.3%) | Last 1000 bets: 2:20 | Total time: 29:40\n",
      "Processed 14000 bets (11.1%) | Last 1000 bets: 2:15 | Total time: 31:55\n",
      "Processed 15000 bets (11.9%) | Last 1000 bets: 2:13 | Total time: 34:09\n",
      "Processed 16000 bets (12.7%) | Last 1000 bets: 2:08 | Total time: 36:18\n",
      "Processed 17000 bets (13.5%) | Last 1000 bets: 2:10 | Total time: 38:29\n",
      "Processed 18000 bets (14.3%) | Last 1000 bets: 2:07 | Total time: 40:36\n",
      "Processed 19000 bets (15.1%) | Last 1000 bets: 2:10 | Total time: 42:47\n",
      "Processed 20000 bets (15.9%) | Last 1000 bets: 2:23 | Total time: 45:10\n",
      "Processed 21000 bets (16.7%) | Last 1000 bets: 2:20 | Total time: 47:31\n",
      "Processed 22000 bets (17.5%) | Last 1000 bets: 2:18 | Total time: 49:50\n",
      "Processed 23000 bets (18.2%) | Last 1000 bets: 2:12 | Total time: 52:02\n",
      "Processed 24000 bets (19.0%) | Last 1000 bets: 2:15 | Total time: 54:18\n",
      "Processed 25000 bets (19.8%) | Last 1000 bets: 2:22 | Total time: 56:40\n",
      "Processed 26000 bets (20.6%) | Last 1000 bets: 2:09 | Total time: 58:49\n",
      "Processed 27000 bets (21.4%) | Last 1000 bets: 2:19 | Total time: 61:08\n",
      "Processed 28000 bets (22.2%) | Last 1000 bets: 2:19 | Total time: 63:28\n",
      "Processed 29000 bets (23.0%) | Last 1000 bets: 2:13 | Total time: 65:41\n",
      "Processed 30000 bets (23.8%) | Last 1000 bets: 2:07 | Total time: 67:48\n",
      "Processed 31000 bets (24.6%) | Last 1000 bets: 2:06 | Total time: 69:55\n",
      "Processed 32000 bets (25.4%) | Last 1000 bets: 2:13 | Total time: 72:09\n",
      "Processed 33000 bets (26.2%) | Last 1000 bets: 2:19 | Total time: 74:29\n",
      "Processed 34000 bets (27.0%) | Last 1000 bets: 2:17 | Total time: 76:46\n",
      "Processed 35000 bets (27.8%) | Last 1000 bets: 2:17 | Total time: 79:04\n",
      "Processed 36000 bets (28.6%) | Last 1000 bets: 2:08 | Total time: 81:12\n",
      "Processed 37000 bets (29.4%) | Last 1000 bets: 2:17 | Total time: 83:30\n",
      "Processed 38000 bets (30.1%) | Last 1000 bets: 2:13 | Total time: 85:44\n",
      "Processed 39000 bets (30.9%) | Last 1000 bets: 2:08 | Total time: 87:52\n",
      "Processed 40000 bets (31.7%) | Last 1000 bets: 2:09 | Total time: 90:02\n",
      "Processed 41000 bets (32.5%) | Last 1000 bets: 2:16 | Total time: 92:18\n",
      "Processed 42000 bets (33.3%) | Last 1000 bets: 2:08 | Total time: 94:27\n",
      "Processed 43000 bets (34.1%) | Last 1000 bets: 2:09 | Total time: 96:36\n",
      "Processed 44000 bets (34.9%) | Last 1000 bets: 2:10 | Total time: 98:47\n",
      "Processed 45000 bets (35.7%) | Last 1000 bets: 2:08 | Total time: 100:55\n",
      "Processed 46000 bets (36.5%) | Last 1000 bets: 2:14 | Total time: 103:10\n",
      "Processed 47000 bets (37.3%) | Last 1000 bets: 2:14 | Total time: 105:25\n",
      "Processed 48000 bets (38.1%) | Last 1000 bets: 2:22 | Total time: 107:47\n",
      "Processed 49000 bets (38.9%) | Last 1000 bets: 2:16 | Total time: 110:03\n",
      "Processed 50000 bets (39.7%) | Last 1000 bets: 2:11 | Total time: 112:14\n",
      "Processed 51000 bets (40.5%) | Last 1000 bets: 2:10 | Total time: 114:25\n",
      "Processed 52000 bets (41.3%) | Last 1000 bets: 2:14 | Total time: 116:39\n",
      "Processed 53000 bets (42.0%) | Last 1000 bets: 2:24 | Total time: 119:03\n",
      "Processed 54000 bets (42.8%) | Last 1000 bets: 2:19 | Total time: 121:23\n",
      "Processed 55000 bets (43.6%) | Last 1000 bets: 2:18 | Total time: 123:41\n",
      "Processed 56000 bets (44.4%) | Last 1000 bets: 2:20 | Total time: 126:02\n",
      "Processed 57000 bets (45.2%) | Last 1000 bets: 2:26 | Total time: 128:28\n",
      "Processed 58000 bets (46.0%) | Last 1000 bets: 2:19 | Total time: 130:47\n",
      "Processed 59000 bets (46.8%) | Last 1000 bets: 2:17 | Total time: 133:05\n",
      "Processed 60000 bets (47.6%) | Last 1000 bets: 2:19 | Total time: 135:24\n",
      "Processed 61000 bets (48.4%) | Last 1000 bets: 2:21 | Total time: 137:46\n",
      "Processed 62000 bets (49.2%) | Last 1000 bets: 2:08 | Total time: 139:54\n",
      "Processed 63000 bets (50.0%) | Last 1000 bets: 2:10 | Total time: 142:04\n",
      "Processed 64000 bets (50.8%) | Last 1000 bets: 2:18 | Total time: 144:23\n",
      "Processed 65000 bets (51.6%) | Last 1000 bets: 2:18 | Total time: 146:42\n",
      "Processed 66000 bets (52.4%) | Last 1000 bets: 2:15 | Total time: 148:57\n",
      "Processed 67000 bets (53.2%) | Last 1000 bets: 2:18 | Total time: 151:16\n",
      "Processed 68000 bets (53.9%) | Last 1000 bets: 2:10 | Total time: 153:27\n",
      "Processed 69000 bets (54.7%) | Last 1000 bets: 2:20 | Total time: 155:47\n",
      "Processed 70000 bets (55.5%) | Last 1000 bets: 2:16 | Total time: 158:04\n",
      "Processed 71000 bets (56.3%) | Last 1000 bets: 2:16 | Total time: 160:20\n",
      "Processed 72000 bets (57.1%) | Last 1000 bets: 2:18 | Total time: 162:38\n",
      "Processed 73000 bets (57.9%) | Last 1000 bets: 2:19 | Total time: 164:58\n",
      "Processed 74000 bets (58.7%) | Last 1000 bets: 2:18 | Total time: 167:17\n",
      "Processed 75000 bets (59.5%) | Last 1000 bets: 2:19 | Total time: 169:36\n",
      "Processed 76000 bets (60.3%) | Last 1000 bets: 2:16 | Total time: 171:52\n",
      "Processed 77000 bets (61.1%) | Last 1000 bets: 2:08 | Total time: 174:00\n",
      "Processed 78000 bets (61.9%) | Last 1000 bets: 2:07 | Total time: 176:08\n",
      "Processed 79000 bets (62.7%) | Last 1000 bets: 2:09 | Total time: 178:17\n",
      "Processed 80000 bets (63.5%) | Last 1000 bets: 2:14 | Total time: 180:32\n",
      "Processed 81000 bets (64.3%) | Last 1000 bets: 2:16 | Total time: 182:49\n",
      "Processed 82000 bets (65.1%) | Last 1000 bets: 2:07 | Total time: 184:56\n",
      "Processed 83000 bets (65.8%) | Last 1000 bets: 2:10 | Total time: 187:07\n",
      "Processed 84000 bets (66.6%) | Last 1000 bets: 2:07 | Total time: 189:14\n",
      "Processed 85000 bets (67.4%) | Last 1000 bets: 2:12 | Total time: 191:27\n",
      "Processed 86000 bets (68.2%) | Last 1000 bets: 2:11 | Total time: 193:38\n",
      "Processed 87000 bets (69.0%) | Last 1000 bets: 2:19 | Total time: 195:58\n",
      "Processed 88000 bets (69.8%) | Last 1000 bets: 2:20 | Total time: 198:19\n",
      "Processed 89000 bets (70.6%) | Last 1000 bets: 2:13 | Total time: 200:32\n",
      "Processed 90000 bets (71.4%) | Last 1000 bets: 2:07 | Total time: 202:40\n",
      "Processed 91000 bets (72.2%) | Last 1000 bets: 2:17 | Total time: 204:57\n",
      "Processed 92000 bets (73.0%) | Last 1000 bets: 2:18 | Total time: 207:15\n",
      "Processed 93000 bets (73.8%) | Last 1000 bets: 2:19 | Total time: 209:35\n",
      "Processed 94000 bets (74.6%) | Last 1000 bets: 2:11 | Total time: 211:46\n",
      "Processed 95000 bets (75.4%) | Last 1000 bets: 2:09 | Total time: 213:56\n",
      "Processed 96000 bets (76.2%) | Last 1000 bets: 2:27 | Total time: 216:24\n",
      "Processed 97000 bets (77.0%) | Last 1000 bets: 2:19 | Total time: 218:43\n",
      "Processed 98000 bets (77.7%) | Last 1000 bets: 2:19 | Total time: 221:03\n",
      "Processed 99000 bets (78.5%) | Last 1000 bets: 2:18 | Total time: 223:22\n",
      "Processed 100000 bets (79.3%) | Last 1000 bets: 2:18 | Total time: 225:40\n",
      "Processed 101000 bets (80.1%) | Last 1000 bets: 2:19 | Total time: 227:59\n",
      "Processed 102000 bets (80.9%) | Last 1000 bets: 2:19 | Total time: 230:19\n",
      "Processed 103000 bets (81.7%) | Last 1000 bets: 2:12 | Total time: 232:31\n",
      "Processed 104000 bets (82.5%) | Last 1000 bets: 2:23 | Total time: 234:54\n",
      "Processed 105000 bets (83.3%) | Last 1000 bets: 2:18 | Total time: 237:12\n",
      "Processed 106000 bets (84.1%) | Last 1000 bets: 2:19 | Total time: 239:32\n",
      "Processed 107000 bets (84.9%) | Last 1000 bets: 2:19 | Total time: 241:52\n",
      "Processed 108000 bets (85.7%) | Last 1000 bets: 2:09 | Total time: 244:01\n",
      "Processed 109000 bets (86.5%) | Last 1000 bets: 2:11 | Total time: 246:13\n",
      "Processed 110000 bets (87.3%) | Last 1000 bets: 2:13 | Total time: 248:27\n",
      "Processed 111000 bets (88.1%) | Last 1000 bets: 2:19 | Total time: 250:46\n",
      "Processed 112000 bets (88.9%) | Last 1000 bets: 2:19 | Total time: 253:06\n",
      "Processed 113000 bets (89.6%) | Last 1000 bets: 2:18 | Total time: 255:25\n",
      "Processed 114000 bets (90.4%) | Last 1000 bets: 2:18 | Total time: 257:43\n",
      "Processed 115000 bets (91.2%) | Last 1000 bets: 2:19 | Total time: 260:03\n",
      "Processed 116000 bets (92.0%) | Last 1000 bets: 2:11 | Total time: 262:14\n",
      "Processed 117000 bets (92.8%) | Last 1000 bets: 2:09 | Total time: 264:23\n",
      "Processed 118000 bets (93.6%) | Last 1000 bets: 2:13 | Total time: 266:37\n",
      "Processed 119000 bets (94.4%) | Last 1000 bets: 2:20 | Total time: 268:57\n",
      "Processed 120000 bets (95.2%) | Last 1000 bets: 2:18 | Total time: 271:16\n",
      "Processed 121000 bets (96.0%) | Last 1000 bets: 2:20 | Total time: 273:36\n",
      "Processed 122000 bets (96.8%) | Last 1000 bets: 2:14 | Total time: 275:51\n",
      "Processed 123000 bets (97.6%) | Last 1000 bets: 2:08 | Total time: 278:00\n",
      "Processed 124000 bets (98.4%) | Last 1000 bets: 2:16 | Total time: 280:16\n",
      "Processed 125000 bets (99.2%) | Last 1000 bets: 2:13 | Total time: 282:29\n",
      "Processed 126000 bets (100.0%) | Last 1000 bets: 2:09 | Total time: 284:38\n",
      "\n",
      "Total processing time: 284:44\n",
      "\n",
      "Bets table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\2729435184.py:91: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  bets_df = pd.read_sql(\"SELECT * FROM bets;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bets: 126047\n",
      "        bet_id  customer_id        game_id  bet_amount               bet_on  \\\n",
      "0            1            1  202301-KC-DET        8500        Detroit Lions   \n",
      "1            2            7  202301-KC-DET         350                under   \n",
      "2            3            8  202301-KC-DET       10000   Kansas City Chiefs   \n",
      "3            4           23  202301-KC-DET         200                under   \n",
      "4            5           24  202301-KC-DET         400                 over   \n",
      "...        ...          ...            ...         ...                  ...   \n",
      "126042  126043         1988   202322-KC-SF        2500  San Francisco 49ers   \n",
      "126043  126044         1989   202322-KC-SF         100  San Francisco 49ers   \n",
      "126044  126045         1991   202322-KC-SF        1700   Kansas City Chiefs   \n",
      "126045  126046         1995   202322-KC-SF         225                 push   \n",
      "126046  126047         1999   202322-KC-SF        1800   Kansas City Chiefs   \n",
      "\n",
      "       result  commission_amount  \n",
      "0        loss              630.0  \n",
      "1         win               35.0  \n",
      "2         win              720.0  \n",
      "3         win               20.0  \n",
      "4        loss               40.0  \n",
      "...       ...                ...  \n",
      "126042   loss              220.0  \n",
      "126043   loss               10.0  \n",
      "126044    win              156.0  \n",
      "126045   loss               22.5  \n",
      "126046    win              164.0  \n",
      "\n",
      "[126047 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Bets\n",
    "\n",
    "# Read betting data\n",
    "# df = pd.read_sql(\"SELECT * FROM betlog;\", pymssql_conn)\n",
    "df = pd.read_csv('betting_data.csv')\n",
    "\n",
    "# Get current bets and convert to list\n",
    "current_bets = pd.read_sql(\"SELECT bet_id FROM bets;\", conn)\n",
    "cb = current_bets['bet_id'].tolist()\n",
    "GAME_ID_CORRECTIONS = {\n",
    "    'LV': 'LVR',\n",
    "    'JAC': 'JAX'\n",
    "    }\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each bet\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    # if counter >= 3000:\n",
    "    #     break\n",
    "        \n",
    "    bet_id = int_convert(df['bet_id'].loc[x])\n",
    "    \n",
    "    # Only proceed if bet is new\n",
    "    if bet_id not in cb:\n",
    "        cb.append(bet_id)\n",
    "        \n",
    "        customer_id = int_convert(df['customer_id'].loc[x])\n",
    "\n",
    "        # Fix game ids\n",
    "        game_id = df['game_id'].loc[x]\n",
    "        game_id_parts = game_id.split('-')\n",
    "        if len(game_id_parts) == 3:\n",
    "            season_week, team1, team2 = game_id_parts\n",
    "            team1 = GAME_ID_CORRECTIONS.get(team1, team1)\n",
    "            team2 = GAME_ID_CORRECTIONS.get(team2, team2)\n",
    "            game_id = f\"{season_week}-{team1}-{team2}\"\n",
    "\n",
    "        \n",
    "        bet_amount = int_convert(df['bet_amount'].loc[x])\n",
    "        bet_on = df['bet_on'].loc[x]\n",
    "        \n",
    "        # Get game details to determine bet result\n",
    "        cursor.execute(\"SELECT winner_line, winner_ou, team_id_home, team_id_away FROM games WHERE game_id = %s;\", (game_id,))\n",
    "        game_details = cursor.fetchone()\n",
    "        \n",
    "        if game_details:\n",
    "            winner_line, winner_ou, team_id_home, team_id_away = game_details\n",
    "            \n",
    "            # Get result and commission\n",
    "            result = determine_bet_result(bet_on, winner_line, winner_ou, team_id_home, team_id_away)                \n",
    "            commission_amount = calculate_commission(bet_amount)\n",
    "            \n",
    "            # Insert into bets table\n",
    "            cursor.execute('''\n",
    "                INSERT INTO bets (bet_id, customer_id, game_id, bet_amount, bet_on, result, commission_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "            ''', (bet_id, customer_id, game_id, bet_amount, bet_on, result, commission_amount))\n",
    "        else:\n",
    "            print(f\"Warning: Could not find game details for game_id {game_id}\")\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:  # Print progress every 1000 records\n",
    "        current_time = time.time()\n",
    "        elapsed_since_last = current_time - last_check\n",
    "        total_elapsed = current_time - start_time\n",
    "\n",
    "        last_check_min = int(elapsed_since_last // 60)\n",
    "        last_check_sec = int(elapsed_since_last % 60)\n",
    "        total_min = int(total_elapsed // 60)\n",
    "        total_sec = int(total_elapsed % 60)\n",
    "\n",
    "        percent_complete = (counter / len(df)) * 100\n",
    "        \n",
    "        print(f\"Processed {counter} bets ({percent_complete:.1f}%) | Last 1000 bets: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d}\")\n",
    "        last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nBets table:\")\n",
    "bets_df = pd.read_sql(\"SELECT * FROM bets;\", conn)\n",
    "print(f\"Number of bets: {len(cb)}\")\n",
    "print(bets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ed2099-1e87-4a53-a4c8-dfd9886c82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\661526783.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported customers to iwdm_customers.csv\n",
      "Number of records: 2000\n",
      "Successfully exported bets to iwdm_bets.csv\n",
      "Number of records: 126047\n",
      "Successfully exported games to iwdm_games.csv\n",
      "Number of records: 2458\n",
      "Successfully exported team_history to iwdm_team_history.csv\n",
      "Number of records: 62\n",
      "Successfully exported current_teams to iwdm_current_teams.csv\n",
      "Number of records: 32\n",
      "Successfully exported stadiums to iwdm_stadiums.csv\n",
      "Number of records: 120\n",
      "Successfully exported weather_stations to iwdm_weather_stations.csv\n",
      "Number of records: 29\n"
     ]
    }
   ],
   "source": [
    "# # Create csvs of finals\n",
    "# tables = ['customers', 'bets', 'games', 'team_history', 'current_teams', 'stadiums', 'weather_stations']\n",
    "# for table in tables:\n",
    "#     query = f\"SELECT * FROM {table};\"\n",
    "#     df = pd.read_sql(query, conn)\n",
    "\n",
    "#     filename = f'iwdm_{table}.csv'\n",
    "#     df.to_csv(filename, index=False)\n",
    "#     print(f\"Successfully exported {table} to {filename}\")\n",
    "#     print(f\"Number of records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72365cf2-5df5-4b66-b274-d5d9600bddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1487148845.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1487148845.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1487148845.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1487148845.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows from customers:\n",
      "    customer_id first_name last_name  age customer_type  customer_since  \\\n",
      "0            1   Coraline    Flores   23        online            2022   \n",
      "1            2    Presley     Ortiz   41        online            2021   \n",
      "2            3       Reid    Knight   40        online            2023   \n",
      "3            4   Clarissa  Chandler   43         local            2023   \n",
      "4            5      Isaac    Vaughn   23         phone            2023   \n",
      "\n",
      "   income  household_size mode_color  \n",
      "0  116000               1        red  \n",
      "1  111000               1       blue  \n",
      "2   55000               1      green  \n",
      "3   32000               2     orange  \n",
      "4   46000               1       blue  \n",
      "\n",
      "First 5 rows from bets:\n",
      "    bet_id  customer_id        game_id  bet_amount              bet_on result  \\\n",
      "0       1            1  202301-KC-DET        8500       Detroit Lions   loss   \n",
      "1       2            7  202301-KC-DET         350               under    win   \n",
      "2       3            8  202301-KC-DET       10000  Kansas City Chiefs    win   \n",
      "3       4           23  202301-KC-DET         200               under    win   \n",
      "4       5           24  202301-KC-DET         400                over   loss   \n",
      "\n",
      "   commission_amount  \n",
      "0              630.0  \n",
      "1               35.0  \n",
      "2              720.0  \n",
      "3               20.0  \n",
      "4               40.0  \n",
      "\n",
      "First 5 rows from games:\n",
      "           game_id schedule_date  schedule_season  schedule_week  \\\n",
      "0   201501-NE-PIT    2015-09-10             2015              1   \n",
      "1   201501-ARI-NO    2015-09-13             2015              1   \n",
      "2  201501-BUF-IND    2015-09-13             2015              1   \n",
      "3   201501-CHI-GB    2015-09-13             2015              1   \n",
      "4  201501-DAL-NYG    2015-09-13             2015              1   \n",
      "\n",
      "   schedule_playoff playoff_type team_id_home team_id_away  score_home  \\\n",
      "0             False         None           NE          PIT          28   \n",
      "1             False         None          ARI           NO          31   \n",
      "2             False         None          BUF          IND          27   \n",
      "3             False         None          CHI           GB          23   \n",
      "4             False         None          DAL          NYG          27   \n",
      "\n",
      "   score_away  ... spread_favorite  over_under_line  stadium_id  \\\n",
      "0          21  ...            -7.0             51.0          36   \n",
      "1          19  ...            -2.5             48.5         111   \n",
      "2          14  ...            -1.0             44.5          81   \n",
      "3          31  ...            -6.5             48.5          92   \n",
      "4          26  ...            -7.0             52.5          21   \n",
      "\n",
      "   stadium_neutral  weather_temperature  weather_wind_mph  weather_humidity  \\\n",
      "0            False                   64                 9              None   \n",
      "1            False                   72                 0              None   \n",
      "2            False                   53                 7              None   \n",
      "3            False                   68                 4              None   \n",
      "4            False                   72                 0              None   \n",
      "\n",
      "  weather_detail winner_ou winner_line  \n",
      "0           rain     under        home  \n",
      "1         indoor      over        home  \n",
      "2           None     under        home  \n",
      "3           None      over        away  \n",
      "4         indoor      over        home  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "First 5 rows from team_history:\n",
      "    team_history_id team_id               name name_short team_id_pfr  \\\n",
      "0                1     ARI  Arizona Cardinals  Cardinals         CRD   \n",
      "1                2     ATL    Atlanta Falcons    Falcons         ATL   \n",
      "2                3     IND    Baltimore Colts      Colts         CLT   \n",
      "3                4     BAL   Baltimore Ravens     Ravens         RAV   \n",
      "4                5      NE    Boston Patriots   Patriots         NWE   \n",
      "\n",
      "  conference     division  \n",
      "0        NFC     NFC West  \n",
      "1        NFC     NFC West  \n",
      "2        AFC     AFC East  \n",
      "3        AFC  AFC Central  \n",
      "4        AFC         None  \n",
      "\n",
      "First 5 rows from current_teams:\n",
      "   team_id                name name_short team_id_pfr conference  division\n",
      "0     BUF       Buffalo Bills      Bills         BUF        AFC  AFC East\n",
      "1     DAL      Dallas Cowboys    Cowboys         DAL        NFC  NFC East\n",
      "2     DEN      Denver Broncos    Broncos         DEN        AFC  AFC West\n",
      "3      KC  Kansas City Chiefs     Chiefs         KAN        AFC  AFC West\n",
      "4     MIA      Miami Dolphins   Dolphins         MIA        AFC  AFC East\n",
      "\n",
      "First 5 rows from stadiums:\n",
      "    stadium_id               name  stadium_open stadium_close stadium_type  \\\n",
      "0           1   Acrisure Stadium        2001.0          None      outdoor   \n",
      "1           2         Alamo Dome           NaN          None       indoor   \n",
      "2           3  Allegiant Stadium        2020.0          None       indoor   \n",
      "3           4      Allianz Arena           NaN          None      outdoor   \n",
      "4           5     Alltel Stadium           NaN          None         None   \n",
      "\n",
      "       street_address          city state postal_code country  \\\n",
      "0  100 Art Rooney Ave    Pittsburgh    PA       15212      US   \n",
      "1      100 Montana St   San Antonio    TX       78203      US   \n",
      "2                None      Paradise    NV        None      US   \n",
      "3                None        Munich  None        None      DE   \n",
      "4                None  Jacksonville    FL        None      US   \n",
      "\n",
      "  weather_station_id  stadium_weather_station_code stadium_weather_type  \\\n",
      "0        USW00094823                       15212.0                 cold   \n",
      "1               None                       78203.0                 dome   \n",
      "2               None                           NaN                 dome   \n",
      "3               None                           NaN             moderate   \n",
      "4               None                           NaN                 None   \n",
      "\n",
      "  surface  \n",
      "0   Grass  \n",
      "1    Turf  \n",
      "2   Grass  \n",
      "3   Grass  \n",
      "4    None  \n",
      "\n",
      "First 5 rows from weather_stations:\n",
      "   weather_station_id                       name state country  latitude  \\\n",
      "0        USW00094823            PITTSBURGH ASOS    PA      US   40.4846   \n",
      "1        US1MOJC0028         KANSAS CITY 5.1 SE    MO      US   39.0692   \n",
      "2        USC00410337        ARLINGTON SIX FLAGS    TX      US   32.7572   \n",
      "3        USW00013881  CHARLOTTE DOUGLAS AIRPORT    NC      US   35.2236   \n",
      "4        US1NYER0093              BUFFALO 1.5 W    NY      US   42.8890   \n",
      "\n",
      "   longitude  elevation  \n",
      "0   -80.2144      366.7  \n",
      "1   -94.4871      264.9  \n",
      "2   -97.0736      163.4  \n",
      "3   -80.9552      221.9  \n",
      "4   -78.8901      178.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1487148845.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1487148845.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1487148845.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Test Queries\n",
    "\n",
    "# 1\n",
    "tables = ['customers', 'bets', 'games', 'team_history', 'current_teams', 'stadiums', 'weather_stations']\n",
    "for table in tables:\n",
    "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(f\"\\nFirst 5 rows from {table}:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d63d3c53-9633-4aa0-9192-f89465cf2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\696354768.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of high-commission customers:\n",
      "    customers_over_20k  total_customers  percentage\n",
      "0                 236             2000        11.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\696354768.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 commission payers:\n",
      "    first_name last_name  total_commission\n",
      "0        Gary   McClain          160114.5\n",
      "1     Matthew     Booth          147968.5\n",
      "2      Vaughn     Ortiz          126964.0\n",
      "3      Bailey    Sparks          123294.0\n",
      "4       Alexa   Mendoza          122644.0\n",
      "5      Violet    Tanner          110888.0\n",
      "6       Nadia     Frank          107458.0\n",
      "7     Harmoni   Burnett           98722.5\n",
      "8       Simon     Cohen           98533.5\n",
      "9       Lucas    Wagner           96160.5\n",
      "10      Clark    Jordan           93224.5\n",
      "11      April    Martin           93212.5\n",
      "12       Kate     Noble           89231.0\n",
      "13       Lara   Hoffman           89225.0\n",
      "14    Winston     Short           86980.0\n",
      "15     Chanel      Pope           86525.5\n",
      "16     Austin    Flores           86287.5\n",
      "17     Warren   Barnett           85294.0\n",
      "18    Adeline    Conner           85096.5\n",
      "19   Emmaline    Hodges           84723.0\n"
     ]
    }
   ],
   "source": [
    "# 2a\n",
    "query = \"\"\"\n",
    "WITH commission_totals AS (\n",
    "    SELECT \n",
    "        c.customer_id, \n",
    "        SUM(commission_amount) as total_commission\n",
    "    FROM customers c\n",
    "    JOIN bets b ON c.customer_id = b.customer_id\n",
    "    GROUP BY c.customer_id\n",
    "    HAVING SUM(commission_amount) > 20000\n",
    ")\n",
    "SELECT \n",
    "    COUNT(*) as customers_over_20k,\n",
    "    (SELECT COUNT(*) FROM customers) as total_customers,\n",
    "    ROUND(CAST(COUNT(*) AS DECIMAL) / (SELECT COUNT(*) FROM customers) * 100, 2) as percentage\n",
    "FROM commission_totals;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Summary of high-commission customers:\\n\", df)\n",
    "\n",
    "# 2b\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    c.first_name,\n",
    "    c.last_name,\n",
    "    ROUND(CAST(SUM(commission_amount) AS DECIMAL), 2) as total_commission\n",
    "FROM customers c\n",
    "JOIN bets b ON c.customer_id = b.customer_id\n",
    "GROUP BY c.customer_id, first_name, last_name\n",
    "HAVING SUM(commission_amount) > 20000\n",
    "ORDER BY total_commission DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"\\nTop 20 commission payers:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3bb6b2-2d33-4125-8e0b-da764595dc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1276876316.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 luckiest bettors:\n",
      "   first_name last_name  total_bets  wins  win_percentage  total_winnings\n",
      "0      Alice     Booth           8     7           87.50           49500\n",
      "1  Alexander   Sherman           7     6           85.71            4225\n",
      "2       John       Lee          13    11           84.62           14900\n",
      "3     Amelia    Knight          13    11           84.62            1025\n",
      "4       Ryan   Edwards           6     5           83.33           38900\n",
      "5     Joshua      Ross          12    10           83.33            1050\n",
      "6      Rylee    Romero          12    10           83.33             850\n",
      "7  Anastasia    Powell           6     5           83.33             625\n",
      "8     Ensley   Simpson          11     9           81.82            2400\n",
      "9     Elijah    Rivera          11     9           81.82            1025\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "query = \"\"\"\n",
    "WITH bet_stats AS (\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        COUNT(*) as total_bets,\n",
    "        COUNT(CASE WHEN b.result = 'win' THEN 1 END) as wins,\n",
    "        SUM(CASE \n",
    "            WHEN b.result = 'win' THEN b.bet_amount\n",
    "            WHEN b.result = 'loss' THEN -b.bet_amount\n",
    "            ELSE 0 END) as total_winnings\n",
    "    FROM customers c\n",
    "    JOIN bets b ON c.customer_id = b.customer_id\n",
    "    GROUP BY c.customer_id, c.first_name, c.last_name\n",
    "    HAVING COUNT(*) >= 6\n",
    ")\n",
    "SELECT \n",
    "    first_name,\n",
    "    last_name,\n",
    "    total_bets,\n",
    "    wins,\n",
    "    ROUND((CAST(wins AS DECIMAL) / total_bets * 100), 2) as win_percentage,\n",
    "    total_winnings\n",
    "FROM bet_stats\n",
    "ORDER BY win_percentage DESC, total_winnings DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Top 10 luckiest bettors:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "162ea3a7-3c56-4f0f-86d7-d717988fc35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 costliest customers for the sports book:\n",
      "    first_name last_name  total_bets  wins  net_lost_for_company\n",
      "0     Matthew     Booth         250   133            -1219308.5\n",
      "1        Kate     Noble         148    88            -1183781.0\n",
      "2      Bailey    Sparks         180    91             -861214.0\n",
      "3        Owen  Garrison          77    48             -810180.0\n",
      "4        Ryan      Lane          81    50             -791732.0\n",
      "5      Chanel      Pope         145    82             -788369.0\n",
      "6      Vaughn     Ortiz         232   121             -780439.5\n",
      "7     Adeline    Conner         194   105             -755861.5\n",
      "8       Nadia     Frank         167    78             -717210.0\n",
      "9        Lara   Hoffman         119    61             -713930.0\n",
      "10    Winston     Short         206   111             -710257.0\n",
      "11      Clark    Jordan         163    85             -690068.0\n",
      "12   Mckenzie   Flowers         190   120             -675614.0\n",
      "13     Lennox      Bean         122    66             -660191.0\n",
      "14        Lia     Drake         117    66             -631199.0\n",
      "15    Kenneth   Roberts         121    64             -623472.0\n",
      "16   Emmaline    Hodges         162    86             -564867.5\n",
      "17      Avery    Holmes         135    67             -543755.0\n",
      "18    Charles     Quinn         102    56             -531971.0\n",
      "19      April    Martin         177    87             -527186.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\2370925212.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    first_name,\n",
    "    last_name,\n",
    "    COUNT(*) as total_bets,\n",
    "    COUNT(CASE WHEN result = 'win' THEN 1 END) as wins,\n",
    "    SUM(CASE \n",
    "        WHEN result = 'win' THEN -(bet_amount + bet_amount)\n",
    "        WHEN result = 'loss' THEN bet_amount + commission_amount\n",
    "        WHEN result = 'push' THEN commission_amount END) as net_lost_for_company\n",
    "FROM customers c\n",
    "JOIN bets b ON c.customer_id = b.customer_id\n",
    "GROUP BY c.customer_id, first_name, last_name\n",
    "ORDER BY net_lost_for_company\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"20 costliest customers for the sports book:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f510e79c-3ffe-42fb-8bd6-154032d43117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\4147440282.py:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly house performance for 2023 season:\n",
      "     schedule_week  total_games  winners  losers  winner_percentage  \\\n",
      "0               1           16        6      10              37.50   \n",
      "1               2           16        7       8              43.75   \n",
      "2               3           16        7       9              43.75   \n",
      "3               4           16        8       8              50.00   \n",
      "4               5           14        6       7              42.86   \n",
      "5               6           15        7       8              46.67   \n",
      "6               7           13        5       7              38.46   \n",
      "7               8           16        8       8              50.00   \n",
      "8               9           14        2      11              14.29   \n",
      "9              10           14        3      10              21.43   \n",
      "10             11           14        3      10              21.43   \n",
      "11             12           16        8       8              50.00   \n",
      "12             13           13        7       6              53.85   \n",
      "13             14           15        5      10              33.33   \n",
      "14             15           16        6       9              37.50   \n",
      "15             16           16        6      10              37.50   \n",
      "16             17           16        5      11              31.25   \n",
      "17             18           16        7       9              43.75   \n",
      "\n",
      "    loser_percentage  \n",
      "0              62.50  \n",
      "1              50.00  \n",
      "2              56.25  \n",
      "3              50.00  \n",
      "4              50.00  \n",
      "5              53.33  \n",
      "6              53.85  \n",
      "7              50.00  \n",
      "8              78.57  \n",
      "9              71.43  \n",
      "10             71.43  \n",
      "11             50.00  \n",
      "12             46.15  \n",
      "13             66.67  \n",
      "14             56.25  \n",
      "15             62.50  \n",
      "16             68.75  \n",
      "17             56.25  \n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "query = \"\"\"\n",
    "WITH weekly_games AS (\n",
    "    SELECT \n",
    "        schedule_week,\n",
    "        COUNT(*) as total_games,\n",
    "        COUNT(CASE WHEN \n",
    "            (winner_line = 'home' AND spread_favorite > 0) OR \n",
    "            (winner_line = 'away' AND spread_favorite < 0) THEN 1 END) as winners,\n",
    "        COUNT(CASE WHEN \n",
    "            (winner_line = 'away' AND spread_favorite > 0) OR\n",
    "            (winner_line = 'home' AND spread_favorite < 0) THEN 1 END) as losers\n",
    "    FROM games\n",
    "    WHERE schedule_season = 2023 AND schedule_playoff = false\n",
    "    GROUP BY schedule_week\n",
    ")\n",
    "SELECT \n",
    "    schedule_week,\n",
    "    total_games,\n",
    "    winners,\n",
    "    losers,\n",
    "    ROUND((CAST(winners AS DECIMAL) / total_games * 100), 2) as winner_percentage,\n",
    "    ROUND((CAST(losers AS DECIMAL) / total_games * 100), 2) as loser_percentage\n",
    "FROM weekly_games\n",
    "ORDER BY schedule_week;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Weekly house performance for 2023 season:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f93ec73d-782a-497b-b1b4-14c1a43f182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3622777610.py:58: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-team betting analysis for 2023 season:\n",
      "                team_name  wins  losses  beat_spread  bets_for  bets_against\n",
      "0        Atlanta Falcons     7      10            8      3020          5299\n",
      "1       Baltimore Ravens    14       5           15      3465          5648\n",
      "2          Buffalo Bills    12       7           14      3368          5437\n",
      "3      Carolina Panthers     2      15            0      2956          5311\n",
      "4          Chicago Bears     7      10            6      3003          5224\n",
      "5     Cincinnati Bengals     9       8            9      2906          5143\n",
      "6       Cleveland Browns    11       7            9      3223          5660\n",
      "7         Dallas Cowboys    12       6           13      3195          5497\n",
      "8         Denver Broncos     8       9           10      3001          5081\n",
      "9          Detroit Lions    14       6           14      3533          6240\n",
      "10     Green Bay Packers    10       9            9      3346          6301\n",
      "11        Houston Texans    11       8           10      3430          5707\n",
      "12    Indianapolis Colts     9       8            8      3034          4921\n",
      "13  Jacksonville Jaguars     9       8            9      2996          5146\n",
      "14    Kansas City Chiefs    15       6           16      3834          6735\n",
      "15        Miami Dolphins    11       7           11      3130          5560\n",
      "16     Minnesota Vikings     7      10            7      3018          5263\n",
      "17  New England Patriots     4      13            2      3004          4884\n",
      "18    New Orleans Saints     9       8            9      3029          5330\n",
      "19       New York Giants     6      11            4      2872          5385\n",
      "20         New York Jets     7      10            6      2964          4930\n",
      "21       Oakland Raiders     8       9            6         0          6590\n",
      "22   Philadelphia Eagles    11       7           14      3214          5735\n",
      "23   Pittsburgh Steelers    10       8           11      3196          5575\n",
      "24    San Diego Chargers     5      12            7         0          6644\n",
      "25   San Francisco 49ers    14       6           17      3696          6430\n",
      "26      Seattle Seahawks     9       8            8      3010          5334\n",
      "27   St. Louis Cardinals     4      13            1         0          6885\n",
      "28        St. Louis Rams    10       8            9         0          7366\n",
      "29  Tampa Bay Buccaneers    10       9            9      3272          6043\n",
      "30      Tennessee Titans     6      11            5      2950          5105\n",
      "31   Washington Redskins     4      13            2         0          6877\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "query = \"\"\"\n",
    "WITH team_games AS (\n",
    "    SELECT \n",
    "        name as team_name,\n",
    "        game_id,\n",
    "        CASE \n",
    "            WHEN team_id_home = team_id THEN 'home'\n",
    "            ELSE 'away' END as home_or_away,\n",
    "        score_home,\n",
    "        score_away,\n",
    "        winner_line,\n",
    "        spread_favorite,\n",
    "        team_id_favorite\n",
    "    FROM current_teams t\n",
    "    JOIN games g ON t.team_id = g.team_id_home OR t.team_id = g.team_id_away\n",
    "    WHERE schedule_season = 2023\n",
    "),\n",
    "team_records AS (\n",
    "    SELECT \n",
    "        team_name,\n",
    "        COUNT(*) AS games_played,\n",
    "        COUNT(CASE WHEN \n",
    "        \t(home_or_away = 'home' AND score_home > score_away) OR\n",
    "        \t(home_or_away = 'away' AND score_away > score_home) THEN 1 END) as wins,\n",
    "        COUNT(CASE WHEN \n",
    "        \t(home_or_away = 'home' AND score_home < score_away) OR\n",
    "        \t(home_or_away = 'away' AND score_away < score_home) THEN 1 END) as losses,\n",
    "        COUNT(CASE WHEN home_or_away = winner_line THEN 1 END) as beat_spread\n",
    "    FROM team_games\n",
    "    GROUP BY team_name\n",
    "),\n",
    "betting_counts AS (\n",
    "    SELECT \n",
    "        name AS team_name,\n",
    "        COUNT(CASE WHEN bet_on = ct.name THEN 1 END) AS bets_for,\n",
    "        COUNT(CASE WHEN bet_on != ct.name AND\n",
    "        \tbet_on NOT IN ('over', 'under') AND\n",
    "        \tteam_id_home = team_id OR\n",
    "        \tteam_id_away = team_id THEN 1 END) as bets_against\n",
    "    FROM current_teams ct\n",
    "    LEFT JOIN games g ON ct.team_id = g.team_id_home OR ct.team_id = g.team_id_away\n",
    "    LEFT JOIN bets b ON g.game_id = b.game_id\n",
    "    WHERE schedule_season = 2023\n",
    "    GROUP BY team_id, name\n",
    ")\n",
    "SELECT \n",
    "    r.team_name,\n",
    "    wins,\n",
    "    losses,\n",
    "    beat_spread,\n",
    "    COALESCE(bets_for, 0) as bets_for,\n",
    "    COALESCE(bets_against, 0) as bets_against\n",
    "FROM team_records r\n",
    "LEFT JOIN betting_counts b ON r.team_name = b.team_name\n",
    "ORDER BY r.team_name;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Per-team betting analysis for 2023 season:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2411348a-c3d9-4f99-b951-2a39be0ffdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3458429226.py:38: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Correlation Matrix:\n",
      "                      age    income  household_size  type_local  type_online  \\\n",
      "age             1.000000 -0.003367       -0.003167    0.003520     0.012831   \n",
      "income         -0.003367  1.000000       -0.010054    0.020711    -0.011735   \n",
      "household_size -0.003167 -0.010054        1.000000   -0.017376     0.012117   \n",
      "type_local      0.003520  0.020711       -0.017376    1.000000    -0.772538   \n",
      "type_online     0.012831 -0.011735        0.012117   -0.772538     1.000000   \n",
      "type_phone     -0.023397 -0.015428        0.009761   -0.456359    -0.212437   \n",
      "years_customer  0.020605  0.005408       -0.009284    0.056665    -0.027774   \n",
      "name_length     0.006064 -0.045654       -0.047149    0.001623    -0.020042   \n",
      "win_rate        0.028639  0.031775       -0.020192   -0.016064     0.070460   \n",
      "\n",
      "                type_phone  years_customer  name_length  win_rate  \n",
      "age              -0.023397        0.020605     0.006064  0.028639  \n",
      "income           -0.015428        0.005408    -0.045654  0.031775  \n",
      "household_size    0.009761       -0.009284    -0.047149 -0.020192  \n",
      "type_local       -0.456359        0.056665     0.001623 -0.016064  \n",
      "type_online      -0.212437       -0.027774    -0.020042  0.070460  \n",
      "type_phone        1.000000       -0.048285     0.025588 -0.074016  \n",
      "years_customer   -0.048285        1.000000     0.007465  0.220128  \n",
      "name_length       0.025588        0.007465     1.000000 -0.018828  \n",
      "win_rate         -0.074016        0.220128    -0.018828  1.000000  \n",
      "\n",
      "First Model Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         customer_value   R-squared:                       0.073\n",
      "Model:                            OLS   Adj. R-squared:                  0.071\n",
      "Method:                 Least Squares   F-statistic:                     39.44\n",
      "Date:                Wed, 04 Dec 2024   Prob (F-statistic):           7.96e-32\n",
      "Time:                        16:35:12   Log-Likelihood:                -25724.\n",
      "No. Observations:                2000   AIC:                         5.146e+04\n",
      "Df Residuals:                    1995   BIC:                         5.149e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const           2.409e+04   1.09e+04      2.211      0.027    2718.764    4.55e+04\n",
      "age              -43.8045    224.593     -0.195      0.845    -484.266     396.657\n",
      "income            -0.5064      0.043    -11.853      0.000      -0.590      -0.423\n",
      "household_size -5332.8185   1388.301     -3.841      0.000   -8055.490   -2610.147\n",
      "type_local      8671.6310   4311.842      2.011      0.044     215.447    1.71e+04\n",
      "==============================================================================\n",
      "Omnibus:                     1920.106   Durbin-Watson:                   1.946\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            94634.500\n",
      "Skew:                          -4.547   Prob(JB):                         0.00\n",
      "Kurtosis:                      35.449   Cond. No.                     5.92e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.92e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Second Model Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         customer_value   R-squared:                       0.036\n",
      "Model:                            OLS   Adj. R-squared:                  0.034\n",
      "Method:                 Least Squares   F-statistic:                     18.40\n",
      "Date:                Wed, 04 Dec 2024   Prob (F-statistic):           7.34e-15\n",
      "Time:                        16:35:12   Log-Likelihood:                -25764.\n",
      "No. Observations:                2000   AIC:                         5.154e+04\n",
      "Df Residuals:                    1995   BIC:                         5.157e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const           4.045e+04   1.04e+04      3.894      0.000    2.01e+04    6.08e+04\n",
      "win_rate       -1.339e+05   1.91e+04     -7.005      0.000   -1.71e+05   -9.64e+04\n",
      "years_customer -1434.1780   1191.443     -1.204      0.229   -3770.781     902.425\n",
      "type_local      7407.4048   4406.679      1.681      0.093   -1234.771     1.6e+04\n",
      "household_size -5395.2805   1416.488     -3.809      0.000   -8173.232   -2617.329\n",
      "==============================================================================\n",
      "Omnibus:                     1948.880   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            92035.959\n",
      "Skew:                          -4.685   Prob(JB):                         0.00\n",
      "Kurtosis:                      34.885   Cond. No.                         42.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Regression Analysis Summary:\n",
      "--------------------------\n",
      "1. Correlation Analysis:\n",
      "    - High collinearity detected between customer types (type_local, type_online, type_phone)\n",
      "    - No other concerning correlations found among independent variables\n",
      "    - Removed type_online and type_phone due to collinearity with type_local\n",
      "\n",
      "2. First Model:\n",
      "    - Variables: age, income, household_size, type_local\n",
      "    - Adjusted R-squared: 0.0714\n",
      "    - Key findings:\n",
      "        * Age not significant (p=0.8454)\n",
      "        * All other variables significant at p<0.05\n",
      "        * Negative relationship with income and household_size\n",
      "        * Positive relationship with type_local\n",
      "\n",
      "3. Second Model:\n",
      "    - Variables: win_rate, years_customer, type_local, household_size\n",
      "    - Adjusted R-squared: 0.0337\n",
      "    - Key findings:\n",
      "        * Win rate and household_size significant at p<0.05\n",
      "        * Years_customer (p=0.229) and type_local (p=0.093) not significant\n",
      "        * Negative relationships with all variables except type_local\n",
      "        * Household size remains consistently significant across models\n",
      "\n",
      "4. Model Comparison:\n",
      "    - First model Adj R-squared: 0.0714\n",
      "    - Second model Adj R-squared: 0.0337\n",
      "    - First model shows better explanatory power\n",
      "    - Both models identify significant predictors of customer value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Analysis\n",
    "\n",
    "# Query to calculate customer value and create features\n",
    "query = \"\"\"\n",
    "WITH bet_values AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        SUM(bet_amount) AS total_bet,\n",
    "        SUM(commission_amount) as total_commission,\n",
    "        COUNT(*) as num_bets,\n",
    "        COUNT(CASE WHEN result = 'win' THEN 1 END) as num_wins,\n",
    "        SUM(CASE \n",
    "            WHEN result = 'win' THEN -(bet_amount * 2)\n",
    "            WHEN result = 'loss' THEN bet_amount\n",
    "            ELSE 0 END) AS bet_outcomes\n",
    "    FROM bets\n",
    "    GROUP BY customer_id\n",
    ")\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    age,\n",
    "    income,\n",
    "    household_size, \n",
    "    customer_type,\n",
    "    customer_since,\n",
    "    mode_color,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    num_bets,\n",
    "    num_wins,\n",
    "    CASE WHEN customer_type = 'local' THEN 1 ELSE 0 END as type_local,\n",
    "    CASE WHEN customer_type = 'online' THEN 1 ELSE 0 END as type_online,\n",
    "    CASE WHEN customer_type = 'phone' THEN 1 ELSE 0 END as type_phone,\n",
    "    total_commission + bet_outcomes as customer_value\n",
    "FROM customers c\n",
    "LEFT JOIN bet_values bv ON c.customer_id = bv.customer_id;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Feature engineering\n",
    "df['name_length'] = df['first_name'].str.len() + df['last_name'].str.len()\n",
    "df['years_customer'] = 2024 - df['customer_since']\n",
    "df['win_rate'] = df['num_wins'] / df['num_bets']\n",
    "\n",
    "# A: Initial correlation matrix with all variables\n",
    "initial_predictors = ['age', 'income', 'household_size', 'type_local', 'type_online', 'type_phone', 'years_customer', 'name_length', 'win_rate']\n",
    "corr_matrix = df[initial_predictors].corr()\n",
    "print(\"\\nInitial Correlation Matrix:\\n\", corr_matrix)\n",
    "\n",
    "# B: First regression\n",
    "first_predictors = ['age', 'income', 'household_size', 'type_local']\n",
    "X = df[first_predictors]\n",
    "y = df['customer_value']\n",
    "X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X).fit()\n",
    "print(\"\\nFirst Model Results:\")\n",
    "print(model1.summary())\n",
    "\n",
    "# C: Second regression\n",
    "second_predictors = ['win_rate', 'years_customer', 'type_local', 'household_size']\n",
    "X2 = df[second_predictors]\n",
    "y = df['customer_value']\n",
    "X2 = sm.add_constant(X2)\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "print(\"\\nSecond Model Results:\")\n",
    "print(model2.summary())\n",
    "\n",
    "print(f\"\"\"\n",
    "Regression Analysis Summary:\n",
    "--------------------------\n",
    "1. Correlation Analysis:\n",
    "    - High collinearity detected between customer types (type_local, type_online, type_phone)\n",
    "    - No other concerning correlations found among independent variables\n",
    "    - Removed type_online and type_phone due to collinearity with type_local\n",
    "\n",
    "2. First Model:\n",
    "    - Variables: age, income, household_size, type_local\n",
    "    - Adjusted R-squared: {model1.rsquared_adj:.4f}\n",
    "    - Key findings:\n",
    "        * Age not significant (p={model1.pvalues['age']:.4f})\n",
    "        * All other variables significant at p<0.05\n",
    "        * Negative relationship with income and household_size\n",
    "        * Positive relationship with type_local\n",
    "\n",
    "3. Second Model:\n",
    "    - Variables: win_rate, years_customer, type_local, household_size\n",
    "    - Adjusted R-squared: {model2.rsquared_adj:.4f}\n",
    "    - Key findings:\n",
    "        * Win rate and household_size significant at p<0.05\n",
    "        * Years_customer (p=0.229) and type_local (p=0.093) not significant\n",
    "        * Negative relationships with all variables except type_local\n",
    "        * Household size remains consistently significant across models\n",
    "\n",
    "4. Model Comparison:\n",
    "    - First model Adj R-squared: {model1.rsquared_adj:.4f}\n",
    "    - Second model Adj R-squared: {model2.rsquared_adj:.4f}\n",
    "    - First model shows better explanatory power\n",
    "    - Both models identify significant predictors of customer value\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3f46860-7a6c-471a-8073-690cfe5cf1d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# pymssql_cursor.close() \n",
    "# pymssql_conn.close()\n",
    "\n",
    "# Might need to fix teams/team history connection to games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058000c-6380-4ac4-b088-6a4bd6bd7d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Establish connections\n",
    "# conn = psycopg2.connect(\n",
    "#     database=\"iwdm\", \n",
    "#     user='dw_chancewiese',\n",
    "#     password='Spikeball2020',\n",
    "#     host='database-1.czsooswggscz.us-east-2.rds.amazonaws.com',\n",
    "#     port='5432'\n",
    "# )\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # pymssql_conn = pymssql.connect(\n",
    "# #     server='stairwaytoheaven.usu.edu',\n",
    "# #     user='5330user',\n",
    "# #     password='pipelinesnow',\n",
    "# #     database='ironwill'\n",
    "# # )\n",
    "# # pymssql_cursor = pymssql_conn.cursor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
