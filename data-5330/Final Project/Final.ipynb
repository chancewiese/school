{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6ca219-3d5c-4eb0-8720-672d64e636a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "import pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7816fe97-38ff-450a-a3f5-4aa96c82673c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Convert to integer\n",
    "def int_convert(value):\n",
    "    if pd.notna(value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Handle Null Values\n",
    "def handle_na(value):\n",
    "    if pd.notna(value):\n",
    "        return value\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Determine winner_ou\n",
    "def get_winner_ou(total_score, over_under_line):\n",
    "    if total_score > over_under_line:\n",
    "        return 'over'\n",
    "    elif total_score < over_under_line:\n",
    "        return 'under'\n",
    "    else:\n",
    "        return 'push'\n",
    "\n",
    "# Determine winner_line\n",
    "def get_winner_line(score_home, score_away, spread_favorite, team_favorite_id, team_home):\n",
    "    score_diff = score_home - score_away\n",
    "    \n",
    "    if team_favorite_id == team_home: # Home team is favorite (includes PICK games)\n",
    "        if score_diff > -spread_favorite:\n",
    "            return 'home'\n",
    "        elif score_diff < -spread_favorite:\n",
    "            return 'away'\n",
    "        else:\n",
    "            return 'push'\n",
    "    else: # Away team is favorite\n",
    "        if score_diff > spread_favorite:\n",
    "            return 'home'\n",
    "        elif score_diff < spread_favorite:\n",
    "            return 'away'\n",
    "        else:\n",
    "            return 'push'\n",
    "\n",
    "# Calculate commission based on bet amount\n",
    "def calculate_commission(bet_amount):\n",
    "    \"\"\"\n",
    "    - 10% on first $1,000\n",
    "    - 8% on next $4,000\n",
    "    - 6% on remaining amount\n",
    "    \"\"\"\n",
    "    commission = 0\n",
    "    \n",
    "    # First $1,000\n",
    "    if bet_amount <= 1000:\n",
    "        commission = bet_amount * 0.10\n",
    "    else:\n",
    "        commission = 1000 * 0.10\n",
    "        remaining = bet_amount - 1000\n",
    "        \n",
    "        # Next $4,000\n",
    "        if remaining <= 4000:\n",
    "            commission += remaining * 0.08\n",
    "        else:\n",
    "            commission += 4000 * 0.08\n",
    "            remaining = remaining - 4000\n",
    "            \n",
    "            # Anything over $5,000\n",
    "            commission += remaining * 0.06\n",
    "            \n",
    "    return round(commission, 2)\n",
    "\n",
    "# Bet result\n",
    "def determine_bet_result(bet_on, winner_line, winner_ou, team_home):    \n",
    "    if bet_on == 'over':\n",
    "        if winner_ou == 'over':\n",
    "            return 'win'\n",
    "        elif winner_ou == 'under':\n",
    "            return 'loss'\n",
    "        else:\n",
    "            return 'push'\n",
    "    elif bet_on == 'under':\n",
    "        if winner_ou == 'under':\n",
    "            return 'win'\n",
    "        elif winner_ou == 'over':\n",
    "            return 'loss'\n",
    "        else:\n",
    "            return 'push'\n",
    "    elif bet_on == 'push':\n",
    "        if winner_line == 'push':\n",
    "            return 'win'\n",
    "        else:\n",
    "            return 'loss'\n",
    "    else:  # Team bet\n",
    "        cursor.execute(\"SELECT DISTINCT team_id FROM team_history WHERE name = %s;\", (bet_on,))\n",
    "        bet_team = cursor.fetchone()\n",
    "        if bet_team:\n",
    "            bet_team = bet_team[0]\n",
    "            \n",
    "            # Home or away team\n",
    "            if bet_team == team_home:\n",
    "                if winner_line == 'home':\n",
    "                    return 'win'\n",
    "                elif winner_line == 'away':\n",
    "                    return 'loss'\n",
    "                else:\n",
    "                    return 'push'\n",
    "            else:\n",
    "                if winner_line == 'away':\n",
    "                    return 'win'\n",
    "                elif winner_line == 'home':\n",
    "                    return 'loss'\n",
    "                else:\n",
    "                    return 'push'\n",
    "        else:\n",
    "            print(f\"Error: Could not find team ID for bet on {bet_on}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3192b747-c8a0-476a-8a71-5859e05a4477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establish connections\n",
    "conn = psycopg2.connect(\n",
    "    database=\"iwdm\", \n",
    "    user='dw_chancewiese',\n",
    "    password='Spikeball2020',\n",
    "    host='database-1.czsooswggscz.us-east-2.rds.amazonaws.com',\n",
    "    port='5432'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "pymssql_conn = pymssql.connect(\n",
    "    server='stairwaytoheaven.usu.edu',\n",
    "    user='5330user',\n",
    "    password='pipelinesnow',\n",
    "    database='ironwill'\n",
    ")\n",
    "pymssql_cursor = pymssql_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60927470-6198-4929-b7f9-1cc19ac3303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For testing\n",
    "# cursor.execute('''\n",
    "# DROP TABLE IF EXISTS placed_bets;\n",
    "# DROP TABLE IF EXISTS games;\n",
    "# DROP TABLE IF EXISTS stadiums;\n",
    "# DROP TABLE IF EXISTS weather_stations;\n",
    "# DROP TABLE IF EXISTS teams;\n",
    "# DROP TABLE IF EXISTS team_history;\n",
    "# DROP TABLE IF EXISTS current_teams;\n",
    "# DROP TABLE IF EXISTS customers;\n",
    "# ''')\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71776ef-598e-4565-b31d-a763e01353e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customers table\n",
      "Created current teams table\n",
      "Created team history table\n",
      "Created weather stations table\n",
      "Created stadiums table\n",
      "Created games table\n",
      "Created placed_bets table\n"
     ]
    }
   ],
   "source": [
    "# Create Tables\n",
    "# Customers\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS customers (\n",
    "    customer_id INTEGER PRIMARY KEY,\n",
    "    first_name VARCHAR(50) NOT NULL,\n",
    "    last_name VARCHAR(50) NOT NULL,\n",
    "    age SMALLINT NOT NULL,\n",
    "    customer_type VARCHAR(10) NOT NULL,\n",
    "    customer_since SMALLINT NOT NULL,\n",
    "    income INTEGER NOT NULL,\n",
    "    household_size SMALLINT NOT NULL,\n",
    "    mode_color VARCHAR(10) NOT NULL\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created customers table\")\n",
    "\n",
    "# Current Teams\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS current_teams (\n",
    "    team_id VARCHAR(5) PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    name_short VARCHAR(50) NOT NULL,\n",
    "    team_id_pfr VARCHAR(5) NOT NULL,\n",
    "    conference VARCHAR(5),\n",
    "    division VARCHAR(20)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created current teams table\")\n",
    "\n",
    "# Team History\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS team_history (\n",
    "    team_history_id SERIAL PRIMARY KEY,\n",
    "    team_id VARCHAR(5) NOT NULL,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    name_short VARCHAR(50) NOT NULL,\n",
    "    team_id_pfr VARCHAR(5) NOT NULL,\n",
    "    conference VARCHAR(5),\n",
    "    division VARCHAR(20),\n",
    "    FOREIGN KEY (team_id) REFERENCES current_teams (team_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created team history table\")\n",
    "\n",
    "# Weather Stations\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS weather_stations (\n",
    "    weather_station_id CHAR(11) PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    state CHAR(2),\n",
    "    country CHAR(2),\n",
    "    latitude DECIMAL(8,5) NOT NULL,\n",
    "    longitude DECIMAL(8,5) NOT NULL,\n",
    "    elevation DECIMAL(5,1) NOT NULL\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created weather stations table\")\n",
    "\n",
    "# Stadiums\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS stadiums (\n",
    "    stadium_id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    stadium_open SMALLINT,\n",
    "    stadium_close SMALLINT,\n",
    "    stadium_type VARCHAR(20),\n",
    "    street_address VARCHAR(100),\n",
    "    city VARCHAR(50),\n",
    "    state CHAR(2),\n",
    "    postal_code VARCHAR(10),\n",
    "    country CHAR(2),\n",
    "    weather_station_id CHAR(11),\n",
    "    stadium_weather_station_code INTEGER,\n",
    "    stadium_weather_type VARCHAR(20),\n",
    "    surface VARCHAR(50),\n",
    "    FOREIGN KEY (weather_station_id) \n",
    "        REFERENCES weather_stations (weather_station_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created stadiums table\")\n",
    "\n",
    "# Games\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS games (\n",
    "    game_id VARCHAR(50) PRIMARY KEY,\n",
    "    schedule_date DATE NOT NULL,\n",
    "    schedule_season SMALLINT NOT NULL,\n",
    "    schedule_week SMALLINT NOT NULL,\n",
    "    schedule_playoff BOOLEAN NOT NULL,\n",
    "    playoff_type VARCHAR(20),\n",
    "    team_id_home VARCHAR(5) NOT NULL,\n",
    "    team_id_away VARCHAR(5) NOT NULL,\n",
    "    score_home SMALLINT,\n",
    "    score_away SMALLINT,\n",
    "    team_id_favorite VARCHAR(5),\n",
    "    spread_favorite DECIMAL(4,1),\n",
    "    over_under_line DECIMAL(4,1),\n",
    "    stadium_id INTEGER,\n",
    "    stadium_neutral BOOLEAN NOT NULL,\n",
    "    weather_temperature SMALLINT,\n",
    "    weather_wind_mph SMALLINT,\n",
    "    weather_humidity SMALLINT,\n",
    "    weather_detail VARCHAR(100),\n",
    "    winner_ou VARCHAR(10),\n",
    "    winner_line VARCHAR(10),\n",
    "    FOREIGN KEY (team_id_home) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_away) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_favorite) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (stadium_id) \n",
    "        REFERENCES stadiums (stadium_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created games table\")\n",
    "\n",
    "# Placed Bets\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS placed_bets (\n",
    "    bet_id INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER NOT NULL,\n",
    "    game_id VARCHAR(50) NOT NULL,\n",
    "    bet_amount INTEGER NOT NULL,\n",
    "    bet_on VARCHAR(50) NOT NULL,\n",
    "    bet_on_team_id VARCHAR(5),\n",
    "    result VARCHAR(10),\n",
    "    commission_amount DECIMAL(10,2),\n",
    "    FOREIGN KEY (customer_id) \n",
    "        REFERENCES customers (customer_id),\n",
    "    FOREIGN KEY (game_id) \n",
    "        REFERENCES games (game_id),\n",
    "    FOREIGN KEY (bet_on_team_id) \n",
    "        REFERENCES current_teams (team_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created placed_bets table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc9ea31-1b36-47d2-82b6-7a4b1d33ec10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/2151444998.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_weather_stations = pd.read_sql(\"SELECT weather_station_id FROM weather_stations;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted station USW00094823: PITTSBURGH ASOS\n",
      "Inserted station US1MOJC0028: KANSAS CITY 5.1 SE\n",
      "Inserted station USC00410337: ARLINGTON SIX FLAGS\n",
      "Inserted station USW00013881: CHARLOTTE DOUGLAS AIRPORT\n",
      "Inserted station US1NYER0093: BUFFALO 1.5 W\n",
      "Inserted station USC00238791: WEBSTER GROVES\n",
      "Inserted station USW00023234: SAN FRANCISCO INTERNATIONAL AIRPORT\n",
      "Inserted station US1WAKG0038: SEATTLE 3.5 NW\n",
      "Inserted station USW00003871: CINCINNATI WEATHER SERVICE OFFICE CITY\n",
      "Inserted station USW00014820: CLEVELAND HOPKINS INTERNATIONAL AIRPORT\n",
      "Inserted station USW00023062: DENVER STAPLETON\n",
      "Inserted station USW00093837: JACKSONVILLE NAS\n",
      "Inserted station USC00186350: NATIONAL ARBORETUM DC\n",
      "Inserted station USC00190860: BROCKTON\n",
      "Inserted station USW00014734: NEWARK LIBERTY INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012839: MIAMI INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012842: TAMPA INTERNATIONAL AIRPORT\n",
      "Inserted station USW00014898: GREEN BAY AUSTIN STRAUBEL INTERNATIONAL AIRPORT\n",
      "Inserted station USW00013739: PHILADELPHIA INTERNATIONAL AIRPORT\n",
      "Inserted station USW00023174: LOS ANGELES INTERNATIONAL AIRPORT\n",
      "Inserted station USW00013897: NASHVILLE INTERNATIONAL AIRPORT\n",
      "Inserted station US1INMR0076: INDIANAPOLIS 6.8 NNE\n",
      "Inserted station USW00093721: BALTIMORE WASHINGTON INTERNATIONAL AIRPORT\n",
      "Inserted station USW00014922: MINNEAPOLIS ST PAUL INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012918: HOUSTON WILLIAM P HOBBY AIRPORT\n",
      "Inserted station USW00023230: OAKLAND METROPOLITAN INTERNATIONAL AIRPORT\n",
      "Inserted station USW00093107: SAN DIEGO MIRAMAR NAS\n",
      "Inserted station USC00111550: CHICAGO NORTHERLY ISLAND\n",
      "Inserted station US1AZMR0451: TEMPE 3.6 NNW\n",
      "Number of records: 29\n",
      "                                                                name state  \\\n",
      "weather_station_id                                                          \n",
      "USW00094823                                         PITTSBURGH ASOS    PA   \n",
      "US1MOJC0028                                      KANSAS CITY 5.1 SE    MO   \n",
      "USC00410337                                     ARLINGTON SIX FLAGS    TX   \n",
      "USW00013881                               CHARLOTTE DOUGLAS AIRPORT    NC   \n",
      "US1NYER0093                                           BUFFALO 1.5 W    NY   \n",
      "USC00238791                                          WEBSTER GROVES    MO   \n",
      "USW00023234                     SAN FRANCISCO INTERNATIONAL AIRPORT    CA   \n",
      "US1WAKG0038                                          SEATTLE 3.5 NW    WA   \n",
      "USW00003871                  CINCINNATI WEATHER SERVICE OFFICE CITY    OH   \n",
      "USW00014820                 CLEVELAND HOPKINS INTERNATIONAL AIRPORT    OH   \n",
      "USW00023062                                        DENVER STAPLETON    CO   \n",
      "USW00093837                                        JACKSONVILLE NAS    FL   \n",
      "USC00186350                                   NATIONAL ARBORETUM DC    MD   \n",
      "USC00190860                                                BROCKTON    MA   \n",
      "USW00014734                    NEWARK LIBERTY INTERNATIONAL AIRPORT    NJ   \n",
      "USW00012839                             MIAMI INTERNATIONAL AIRPORT    FL   \n",
      "USW00012842                             TAMPA INTERNATIONAL AIRPORT    FL   \n",
      "USW00014898         GREEN BAY AUSTIN STRAUBEL INTERNATIONAL AIRPORT    WI   \n",
      "USW00013739                      PHILADELPHIA INTERNATIONAL AIRPORT    PA   \n",
      "USW00023174                       LOS ANGELES INTERNATIONAL AIRPORT    CA   \n",
      "USW00013897                         NASHVILLE INTERNATIONAL AIRPORT    TN   \n",
      "US1INMR0076                                    INDIANAPOLIS 6.8 NNE    IN   \n",
      "USW00093721              BALTIMORE WASHINGTON INTERNATIONAL AIRPORT    MD   \n",
      "USW00014922               MINNEAPOLIS ST PAUL INTERNATIONAL AIRPORT    MN   \n",
      "USW00012918                         HOUSTON WILLIAM P HOBBY AIRPORT    TX   \n",
      "USW00023230              OAKLAND METROPOLITAN INTERNATIONAL AIRPORT    CA   \n",
      "USW00093107                                   SAN DIEGO MIRAMAR NAS    CA   \n",
      "USC00111550                                CHICAGO NORTHERLY ISLAND    IL   \n",
      "US1AZMR0451                                           TEMPE 3.6 NNW    AZ   \n",
      "\n",
      "                   country  latitude  longitude  elevation  \n",
      "weather_station_id                                          \n",
      "USW00094823             US  40.48460  -80.21440      366.7  \n",
      "US1MOJC0028             US  39.06920  -94.48710      264.9  \n",
      "USC00410337             US  32.75720  -97.07360      163.4  \n",
      "USW00013881             US  35.22360  -80.95520      221.9  \n",
      "US1NYER0093             US  42.88900  -78.89010      178.0  \n",
      "USC00238791             US  38.56667  -90.36667      189.0  \n",
      "USW00023234             US  37.61970 -122.36470        2.4  \n",
      "US1WAKG0038             US  47.65230 -122.40950       93.0  \n",
      "USW00003871             US  39.10000  -84.51667      193.9  \n",
      "USW00014820             US  41.40570  -81.85200      238.0  \n",
      "USW00023062             US  39.76330 -104.86940     1611.2  \n",
      "USW00093837             US  30.23333  -81.66667        6.1  \n",
      "USC00186350             US  38.91330  -76.97000       15.2  \n",
      "USC00190860             US  42.04790  -71.00500       24.4  \n",
      "USW00014734             US  40.68250  -74.16940        2.1  \n",
      "USW00012839             US  25.79050  -80.31630        8.8  \n",
      "USW00012842             US  27.96194  -82.54030        5.8  \n",
      "USW00014898             US  44.47940  -88.13660      209.4  \n",
      "USW00013739             US  39.87327  -75.22678        3.0  \n",
      "USW00023174             US  33.93800 -118.38880       29.6  \n",
      "USW00013897             US  36.11889  -86.68917      182.9  \n",
      "US1INMR0076             US  39.87210  -86.12010      227.1  \n",
      "USW00093721             US  39.17330  -76.68400       47.5  \n",
      "USW00014922             US  44.88310  -93.22890      265.8  \n",
      "USW00012918             US  29.63806  -95.28194       13.4  \n",
      "USW00023230             US  37.72139 -122.22083        1.8  \n",
      "USW00093107             US  32.86667 -117.13333      145.4  \n",
      "USC00111550             US  41.85580  -87.60940      177.7  \n",
      "US1AZMR0451             US  33.45520 -111.93160      375.2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/2151444998.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM weather_stations\", conn, index_col='weather_station_id')\n"
     ]
    }
   ],
   "source": [
    "# Ingest Weather Stations\n",
    "\n",
    "stadiums_df = pd.read_csv('nfl_stadiums.csv')\n",
    "weather_stations_df = stadiums_df[['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION']]\n",
    "df = weather_stations_df.dropna()\n",
    "\n",
    "# Get current stations and convert to list\n",
    "current_weather_stations = pd.read_sql(\"SELECT weather_station_id FROM weather_stations;\", conn)\n",
    "cws = current_weather_stations['weather_station_id'].tolist()\n",
    "\n",
    "for x in df.index:\n",
    "    weather_station_id = df['STATION'].loc[x]\n",
    "    \n",
    "    # Only proceed if station is new\n",
    "    if weather_station_id not in cws:\n",
    "        cws.append(weather_station_id) # Make sure a station isn't inserted twice\n",
    "        name = df['NAME'].loc[x]\n",
    "        latitude = df['LATITUDE'].loc[x]\n",
    "        longitude = df['LONGITUDE'].loc[x]\n",
    "        elevation = df['ELEVATION'].loc[x]\n",
    "\n",
    "        # Get state and country codes\n",
    "        name, state_country = name.split(', ')\n",
    "        state, country = state_country.split(' ')\n",
    "\n",
    "        cursor.execute('''\n",
    "            INSERT INTO weather_stations (weather_station_id, name, state, country, latitude, longitude, elevation)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (weather_station_id, name, state, country, latitude, longitude, elevation))\n",
    "        print(f\"Inserted station {weather_station_id}: {name}\")\n",
    "        \n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "df = pd.read_sql(\"SELECT * FROM weather_stations\", conn, index_col='weather_station_id')\n",
    "print(f\"Number of records: {len(cws)}\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5dce61e-ad0c-4ee2-8a4a-7a9f071bb76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/216549753.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_stadiums = pd.read_sql(\"SELECT name FROM stadiums;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted stadium: Acrisure Stadium\n",
      "Inserted stadium: Alamo Dome\n",
      "Inserted stadium: Allegiant Stadium\n",
      "Inserted stadium: Allianz Arena\n",
      "Inserted stadium: Alltel Stadium\n",
      "Inserted stadium: Alumni Stadium\n",
      "Inserted stadium: Anaheim Stadium\n",
      "Inserted stadium: Arrowhead Stadium\n",
      "Inserted stadium: AT&T Stadium\n",
      "Inserted stadium: Atlanta-Fulton County Stadium\n",
      "Inserted stadium: Balboa Stadium\n",
      "Inserted stadium: Bank of America Stadium\n",
      "Inserted stadium: Bills Stadium\n",
      "Inserted stadium: Busch Memorial Stadium\n",
      "Inserted stadium: Caesars Superdome\n",
      "Inserted stadium: Candlestick Park\n",
      "Inserted stadium: CenturyLink Field\n",
      "Inserted stadium: Cinergy Field\n",
      "Inserted stadium: Cleveland Municipal Stadium\n",
      "Inserted stadium: Cotton Bowl\n",
      "Inserted stadium: Cowboys Stadium\n",
      "Inserted stadium: Dolphin Stadium\n",
      "Inserted stadium: Edward Jones Dome\n",
      "Inserted stadium: Empower Field at Mile High\n",
      "Inserted stadium: Estadio Azteca\n",
      "Inserted stadium: EverBank Field\n",
      "Inserted stadium: FedEx Field\n",
      "Inserted stadium: Fenway Park\n",
      "Inserted stadium: FirstEnergy Stadium\n",
      "Inserted stadium: Ford Field\n",
      "Inserted stadium: Foxboro Stadium\n",
      "Inserted stadium: Franklin Field\n",
      "Inserted stadium: GEHA Field at Arrowhead Stadium\n",
      "Inserted stadium: Georgia Dome\n",
      "Inserted stadium: Giants Stadium\n",
      "Inserted stadium: Gillette Stadium\n",
      "Inserted stadium: Hard Rock Stadium\n",
      "Inserted stadium: Harvard Stadium\n",
      "Inserted stadium: Heinz Field\n",
      "Inserted stadium: Highmark Stadium\n",
      "Inserted stadium: Houlihan's Stadium\n",
      "Inserted stadium: Houston Astrodome\n",
      "Inserted stadium: Hubert H. Humphrey Metrodome\n",
      "Inserted stadium: Husky Stadium\n",
      "Inserted stadium: Jack Murphy Stadium\n",
      "Inserted stadium: Joe Robbie Stadium\n",
      "Inserted stadium: Kansas City Municipal Stadium\n",
      "Inserted stadium: Kezar Stadium\n",
      "Inserted stadium: Lambeau Field\n",
      "Inserted stadium: Legion Field\n",
      "Inserted stadium: Levi's Stadium\n",
      "Inserted stadium: Liberty Bowl Memorial Stadium\n",
      "Inserted stadium: Lincoln Financial Field\n",
      "Inserted stadium: Los Angeles Memorial Coliseum\n",
      "Inserted stadium: Louisiana Superdome\n",
      "Inserted stadium: LP Stadium\n",
      "Inserted stadium: Lucas Oil Stadium\n",
      "Inserted stadium: Lumen Field\n",
      "Inserted stadium: M&T Bank Stadium\n",
      "Inserted stadium: Mall of America Field\n",
      "Inserted stadium: Memorial Stadium (Baltimore)\n",
      "Inserted stadium: Memorial Stadium (Champaign)\n",
      "Inserted stadium: Memorial Stadium (Clemson)\n",
      "Inserted stadium: Mercedes-Benz Stadium\n",
      "Inserted stadium: Mercedes-Benz Superdome\n",
      "Inserted stadium: MetLife Stadium\n",
      "Inserted stadium: Metropolitan Stadium\n",
      "Inserted stadium: Mile High Stadium\n",
      "Inserted stadium: New Era Field\n",
      "Inserted stadium: Nippert Stadium\n",
      "Inserted stadium: Nissan Stadium\n",
      "Inserted stadium: NRG Stadium\n",
      "Inserted stadium: Oakland Coliseum\n",
      "Inserted stadium: Orange Bowl\n",
      "Inserted stadium: Paul Brown Stadium\n",
      "Inserted stadium: Paycor Stadium\n",
      "Inserted stadium: Pitt Stadium\n",
      "Inserted stadium: Pontiac Silverdome\n",
      "Inserted stadium: Pro Player Stadium\n",
      "Inserted stadium: Qualcomm Stadium\n",
      "Inserted stadium: Ralph Wilson Stadium\n",
      "Inserted stadium: Raymond James Stadium\n",
      "Inserted stadium: RCA Dome\n",
      "Inserted stadium: Reliant Stadium\n",
      "Inserted stadium: RFK Memorial Stadium\n",
      "Inserted stadium: Rice Stadium\n",
      "Inserted stadium: Rogers Centre\n",
      "Inserted stadium: Rose Bowl\n",
      "Inserted stadium: Seattle Kingdome\n",
      "Inserted stadium: Shea Stadium\n",
      "Inserted stadium: SoFi Stadium\n",
      "Inserted stadium: Soldier Field\n",
      "Inserted stadium: Sports Authority Field at Mile High\n",
      "Inserted stadium: Stanford Stadium\n",
      "Inserted stadium: State Farm Stadium\n",
      "Inserted stadium: StubHub Center\n",
      "Inserted stadium: Sun Devil Stadium\n",
      "Inserted stadium: Sun Life Stadium\n",
      "Inserted stadium: Tampa Stadium\n",
      "Inserted stadium: TCF Bank Stadium\n",
      "Inserted stadium: Texas Stadium\n",
      "Inserted stadium: Three Rivers Stadium\n",
      "Inserted stadium: TIAA Bank Field\n",
      "Inserted stadium: Tiger Stadium\n",
      "Inserted stadium: Tiger Stadium (LSU)\n",
      "Inserted stadium: Tottenham Hotspur Stadium\n",
      "Inserted stadium: Tottenham Stadium\n",
      "Inserted stadium: Tulane Stadium\n",
      "Inserted stadium: Twickenham Stadium\n",
      "Inserted stadium: U.S. Bank Stadium\n",
      "Inserted stadium: University of Phoenix Stadium\n",
      "Inserted stadium: Vanderbilt Stadium\n",
      "Inserted stadium: Veterans Stadium\n",
      "Inserted stadium: War Memorial Stadium\n",
      "Inserted stadium: Wembley Stadium\n",
      "Inserted stadium: Wrigley Field\n",
      "Inserted stadium: Yale Bowl\n",
      "Inserted stadium: Yankee Stadium\n",
      "Number of records: 118\n",
      "                             name  stadium_open  stadium_close stadium_type  \\\n",
      "stadium_id                                                                   \n",
      "1               Acrisure Stadium        2001.0            NaN      outdoor   \n",
      "2                     Alamo Dome           NaN            NaN       indoor   \n",
      "3              Allegiant Stadium        2020.0            NaN       indoor   \n",
      "4                  Allianz Arena           NaN            NaN      outdoor   \n",
      "5                 Alltel Stadium           NaN            NaN         None   \n",
      "...                          ...           ...            ...          ...   \n",
      "114         War Memorial Stadium        1960.0         1972.0      outdoor   \n",
      "115              Wembley Stadium        2007.0            NaN      outdoor   \n",
      "116                Wrigley Field        1920.0         1970.0      outdoor   \n",
      "117                    Yale Bowl           NaN            NaN      outdoor   \n",
      "118               Yankee Stadium           NaN            NaN      outdoor   \n",
      "\n",
      "                      street_address          city state postal_code country  \\\n",
      "stadium_id                                                                     \n",
      "1                 100 Art Rooney Ave    Pittsburgh    PA       15212      US   \n",
      "2                     100 Montana St   San Antonio    TX       78203      US   \n",
      "3                               None      Paradise    NV        None      US   \n",
      "4                               None        Munich  None        None      DE   \n",
      "5                               None  Jacksonville    FL        None      US   \n",
      "...                              ...           ...   ...         ...     ...   \n",
      "114                 285 Dodge Street       Buffalo    NY       14208      US   \n",
      "115                          Wembley        London  None     HA9 0WS      UK   \n",
      "116         1060 West Addison Street       Chicago    IL       60613      US   \n",
      "117                    276 Derby Ave     New Haven    CT       06516      US   \n",
      "118                             None         Bronx    NY        None      US   \n",
      "\n",
      "           weather_station_id  stadium_weather_station_code  \\\n",
      "stadium_id                                                    \n",
      "1                 USW00094823                       15212.0   \n",
      "2                        None                       78203.0   \n",
      "3                        None                           NaN   \n",
      "4                        None                           NaN   \n",
      "5                        None                           NaN   \n",
      "...                       ...                           ...   \n",
      "114                      None                       14208.0   \n",
      "115                      None                           NaN   \n",
      "116                      None                       60613.0   \n",
      "117                      None                        6516.0   \n",
      "118                      None                           NaN   \n",
      "\n",
      "           stadium_weather_type surface  \n",
      "stadium_id                               \n",
      "1                          cold   Grass  \n",
      "2                          dome    Turf  \n",
      "3                          dome   Grass  \n",
      "4                      moderate   Grass  \n",
      "5                          None    None  \n",
      "...                         ...     ...  \n",
      "114                        cold    None  \n",
      "115                    moderate    None  \n",
      "116                        cold    None  \n",
      "117                        cold   Grass  \n",
      "118                        cold    None  \n",
      "\n",
      "[118 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/216549753.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM stadiums\", conn, index_col='stadium_id')\n"
     ]
    }
   ],
   "source": [
    "# Ingest Stadiums\n",
    "\n",
    "df = pd.read_csv('nfl_stadiums.csv')\n",
    "\n",
    "# Get current stadiums and convert to list\n",
    "current_stadiums = pd.read_sql(\"SELECT name FROM stadiums;\", conn)\n",
    "cs = current_stadiums['name'].tolist()\n",
    "\n",
    "for x in df.index:\n",
    "    name = df['stadium_name'].loc[x]\n",
    "    \n",
    "    if name not in cs:\n",
    "        cs.append(name)  # Make sure a stadium isn't inserted twice\n",
    "        location = df['stadium_location'].loc[x]\n",
    "        stadium_open = df['stadium_open'].loc[x]\n",
    "        stadium_close = df['stadium_close'].loc[x]\n",
    "        stadium_type = df['stadium_type'].loc[x]\n",
    "        address = df['stadium_address'].loc[x]\n",
    "        stadium_weather_station_code = df['stadium_weather_station_code'].loc[x]\n",
    "        weather_station_id = df['STATION'].loc[x]\n",
    "        stadium_weather_type = df['stadium_weather_type'].loc[x]\n",
    "        surface = df['stadium_surface'].loc[x]\n",
    "        street_address = city = state = postal_code = country = None\n",
    "\n",
    "        ### addresscleaning\n",
    "        if pd.notna(location):\n",
    "            if 'UK' in location:\n",
    "                city, country = location.split(', ')\n",
    "            elif 'MX' in str(stadium_weather_station_code):\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'MX'\n",
    "            elif 'Canada' in location:\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'CA'\n",
    "            elif 'Germany' in location:\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'DE'\n",
    "            elif ',' in location:  # US locations\n",
    "                city, state = location.split(', ')\n",
    "                country = 'US'\n",
    "        # Parse address if it exists\n",
    "        if pd.notna(address):\n",
    "            if country == 'UK':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                postal_code = parts[1].replace('London', '').strip()\n",
    "            elif country == 'MX': # no clue how to handle this one\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "            elif country == 'CA':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                state = parts[2].split(' ')[0]\n",
    "                postal_code = parts[2].split(' ')[1] + ' ' + parts[2].split(' ')[2]\n",
    "            elif country == 'US':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                postal_code = parts[-1].split(' ')[-1]\n",
    "        \n",
    "        ## Integer converting and null handling for insertion\n",
    "        stadium_open = int_convert(stadium_open)\n",
    "        stadium_close = int_convert(stadium_close)\n",
    "        stadium_weather_station_code = int_convert(stadium_weather_station_code)\n",
    "        weather_station_id = handle_na(weather_station_id)\n",
    "        stadium_type = handle_na(stadium_type)\n",
    "        stadium_weather_type = handle_na(stadium_weather_type)\n",
    "                \n",
    "                \n",
    "        ## surface\n",
    "        if pd.notna(surface):  # Check if surface exists before lowercase\n",
    "            if 'grass' in surface.lower():\n",
    "                surface = 'Grass'\n",
    "            elif 'turf' in surface.lower():\n",
    "                surface = 'Turf'\n",
    "        else:\n",
    "            surface = None\n",
    "            \n",
    "        ### Ingest\n",
    "        cursor.execute('''\n",
    "            INSERT INTO stadiums (name, stadium_open, stadium_close, stadium_type, street_address, city, state, postal_code, country, weather_station_id, stadium_weather_station_code, stadium_weather_type, surface)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (name, stadium_open, stadium_close, stadium_type, street_address, city, state, postal_code, country, weather_station_id, stadium_weather_station_code, stadium_weather_type, surface))\n",
    "        print(f\"Inserted stadium: {name}\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "df = pd.read_sql(\"SELECT * FROM stadiums\", conn, index_col='stadium_id')\n",
    "print(f\"Number of records: {len(cs)}\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4372267-0032-4676-9ee4-606689ce5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted pre-2002 record for team: Arizona Cardinals\n",
      "Inserted pre-2002 record for team: Atlanta Falcons\n",
      "Inserted pre-2002 record for team: Baltimore Colts\n",
      "Inserted pre-2002 record for team: Baltimore Ravens\n",
      "Inserted pre-2002 record for team: Boston Patriots\n",
      "Inserted pre-2002 record for team: Buffalo Bills\n",
      "Inserted pre-2002 record for team: Carolina Panthers\n",
      "Inserted pre-2002 record for team: Chicago Bears\n",
      "Inserted pre-2002 record for team: Cincinnati Bengals\n",
      "Inserted pre-2002 record for team: Cleveland Browns\n",
      "Inserted pre-2002 record for team: Dallas Cowboys\n",
      "Inserted pre-2002 record for team: Denver Broncos\n",
      "Inserted pre-2002 record for team: Detroit Lions\n",
      "Inserted pre-2002 record for team: Green Bay Packers\n",
      "Inserted pre-2002 record for team: Houston Oilers\n",
      "Inserted pre-2002 record for team: Houston Texans\n",
      "Inserted pre-2002 record for team: Jacksonville Jaguars\n",
      "Inserted pre-2002 record for team: Kansas City Chiefs\n",
      "Inserted pre-2002 record for team: Las Vegas Raiders\n",
      "Inserted pre-2002 record for team: Los Angeles Chargers\n",
      "Inserted pre-2002 record for team: Los Angeles Rams\n",
      "Inserted pre-2002 record for team: Miami Dolphins\n",
      "Inserted pre-2002 record for team: Minnesota Vikings\n",
      "Inserted pre-2002 record for team: New Orleans Saints\n",
      "Inserted pre-2002 record for team: New York Giants\n",
      "Inserted pre-2002 record for team: New York Jets\n",
      "Inserted pre-2002 record for team: Philadelphia Eagles\n",
      "Inserted pre-2002 record for team: Pittsburgh Steelers\n",
      "Inserted pre-2002 record for team: San Francisco 49ers\n",
      "Inserted pre-2002 record for team: Seattle Seahawks\n",
      "Inserted pre-2002 record for team: Tampa Bay Buccaneers\n",
      "Inserted pre-2002 record for team: Washington Commanders\n",
      "Updated record for team: Atlanta Falcons\n",
      "Updated record for team: Baltimore Colts\n",
      "Updated record for team: Baltimore Ravens\n",
      "Updated record for team: Carolina Panthers\n",
      "Updated record for team: Chicago Bears\n",
      "Updated record for team: Cincinnati Bengals\n",
      "Updated record for team: Cleveland Browns\n",
      "Updated record for team: Detroit Lions\n",
      "Updated record for team: Green Bay Packers\n",
      "Updated record for team: Houston Oilers\n",
      "Updated record for team: Houston Texans\n",
      "Updated record for team: Indianapolis Colts\n",
      "Updated record for team: Jacksonville Jaguars\n",
      "Updated record for team: Las Vegas Raiders\n",
      "Updated record for team: Los Angeles Raiders\n",
      "Updated record for team: Minnesota Vikings\n",
      "Updated record for team: New England Patriots\n",
      "Updated record for team: New Orleans Saints\n",
      "Updated record for team: Oakland Raiders\n",
      "Updated record for team: Phoenix Cardinals\n",
      "Updated record for team: Pittsburgh Steelers\n",
      "Updated record for team: San Diego Chargers\n",
      "Updated record for team: Seattle Seahawks\n",
      "Updated record for team: St. Louis Cardinals\n",
      "Updated record for team: St. Louis Rams\n",
      "Updated record for team: Tampa Bay Buccaneers\n",
      "Updated record for team: Tennessee Oilers\n",
      "Updated record for team: Tennessee Titans\n",
      "Updated record for team: Washington Football Team\n",
      "Updated record for team: Washington Redskins\n",
      "\n",
      "Current Teams table:\n",
      "Number of current teams: 32\n",
      "    team_id                  name  name_short team_id_pfr conference   division\n",
      "0      BUF         Buffalo Bills       Bills         BUF        AFC   AFC East\n",
      "1      DAL        Dallas Cowboys     Cowboys         DAL        NFC   NFC East\n",
      "2      DEN        Denver Broncos     Broncos         DEN        AFC   AFC West\n",
      "3       KC    Kansas City Chiefs      Chiefs         KAN        AFC   AFC West\n",
      "4      MIA        Miami Dolphins    Dolphins         MIA        AFC   AFC East\n",
      "5      NYG       New York Giants      Giants         NYG        NFC   NFC East\n",
      "6      NYJ         New York Jets        Jets         NYJ        NFC   AFC East\n",
      "7      PHI   Philadelphia Eagles      Eagles         PHI        NFC   NFC East\n",
      "8       SF   San Francisco 49ers       49ers         SFO        NFC   NFC West\n",
      "9      ATL       Atlanta Falcons     Falcons         ATL        NFC  NFC South\n",
      "10     BAL      Baltimore Ravens      Ravens         RAV        AFC  AFC North\n",
      "11     CAR     Carolina Panthers    Panthers         CAR        NFC  NFC South\n",
      "12     CHI         Chicago Bears       Bears         CHI        NFC  NFC North\n",
      "13     CIN    Cincinnati Bengals     Bengals         CIN        AFC  AFC North\n",
      "14     CLE      Cleveland Browns      Browns         CLE        AFC  AFC North\n",
      "15     DET         Detroit Lions       Lions         DET        NFC  NFC North\n",
      "16      GB     Green Bay Packers     Packers         GNB        NFC  NFC North\n",
      "17     HOU        Houston Texans      Texans         HTX        AFC  AFC South\n",
      "18     IND    Indianapolis Colts       Colts         CLT        AFC  AFC South\n",
      "19     JAX  Jacksonville Jaguars     Jaguars         JAX        AFC  AFC South\n",
      "20     MIN     Minnesota Vikings     Vikings         MIN        NFC  NFC North\n",
      "21      NE  New England Patriots    Patriots         NWE        AFC   AFC East\n",
      "22      NO    New Orleans Saints      Saints         NOR        NFC  NFC South\n",
      "23     LVR       Oakland Raiders     Raiders         RAI        AFC   AFC West\n",
      "24     PIT   Pittsburgh Steelers    Steelers         PIT        AFC  AFC North\n",
      "25     LAC    San Diego Chargers    Chargers         SDG        AFC   AFC West\n",
      "26     SEA      Seattle Seahawks    Seahawks         SEA        NFC   NFC West\n",
      "27     ARI   St. Louis Cardinals   Cardinals         ARI        NFC       None\n",
      "28     LAR        St. Louis Rams        Rams         RAM        NFC       None\n",
      "29      TB  Tampa Bay Buccaneers  Buccaneers         TAM        NFC  NFC South\n",
      "30     TEN      Tennessee Titans      Titans         OTI        AFC  AFC South\n",
      "31     WAS   Washington Redskins  Washington         WAS        NFC   NFC East\n",
      "\n",
      "Team History table:\n",
      "Number of history records: 62\n",
      "     team_history_id team_id                      name  name_short team_id_pfr  \\\n",
      "0                 1     ARI         Arizona Cardinals   Cardinals         CRD   \n",
      "1                 2     ATL           Atlanta Falcons     Falcons         ATL   \n",
      "2                 3     IND           Baltimore Colts       Colts         CLT   \n",
      "3                 4     BAL          Baltimore Ravens      Ravens         RAV   \n",
      "4                 5      NE           Boston Patriots    Patriots         NWE   \n",
      "..              ...     ...                       ...         ...         ...   \n",
      "57               58      TB      Tampa Bay Buccaneers  Buccaneers         TAM   \n",
      "58               59     TEN          Tennessee Oilers      Oilers         OTI   \n",
      "59               60     TEN          Tennessee Titans      Titans         OTI   \n",
      "60               61     WAS  Washington Football Team  Washington         WAS   \n",
      "61               62     WAS       Washington Redskins  Washington         WAS   \n",
      "\n",
      "   conference     division  \n",
      "0         NFC     NFC West  \n",
      "1         NFC     NFC West  \n",
      "2         AFC     AFC East  \n",
      "3         AFC  AFC Central  \n",
      "4         AFC         None  \n",
      "..        ...          ...  \n",
      "57        NFC    NFC South  \n",
      "58        AFC         None  \n",
      "59        AFC    AFC South  \n",
      "60        NFC     NFC East  \n",
      "61        NFC     NFC East  \n",
      "\n",
      "[62 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/2418123640.py:87: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  teams_df = pd.read_sql(\"SELECT * FROM current_teams\", conn)\n",
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/2418123640.py:91: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  history_df = pd.read_sql(\"SELECT * FROM team_history\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Ingest Teams\n",
    "df = pd.read_csv('nfl_teams.csv')\n",
    "\n",
    "# Insert pre-2002 data first\n",
    "for x in df.index:\n",
    "    team_id = df['team_id'].loc[x]\n",
    "    name = df['team_name'].loc[x]\n",
    "    name_short = df['team_name_short'].loc[x]\n",
    "    team_id_pfr = df['team_id_pfr'].loc[x]\n",
    "    conference = df['team_conference_pre2002'].loc[x]\n",
    "    division = df['team_division_pre2002'].loc[x]\n",
    "\n",
    "    # Clean data\n",
    "    team_id = handle_na(team_id)\n",
    "    name = handle_na(name)\n",
    "    name_short = handle_na(name_short)\n",
    "    team_id_pfr = handle_na(team_id_pfr)\n",
    "    conference = handle_na(conference)\n",
    "    division = handle_na(division)\n",
    "    \n",
    "    # Check if team_id exists\n",
    "    cursor.execute('SELECT team_id FROM current_teams WHERE team_id = %s', (team_id,))\n",
    "    exists = cursor.fetchone()\n",
    "    \n",
    "    if not exists:\n",
    "        # Insert into current_teams only if it doesn't exist\n",
    "        cursor.execute('''\n",
    "            INSERT INTO current_teams (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "        \n",
    "        # Insert into team_history\n",
    "        cursor.execute('''\n",
    "            INSERT INTO team_history \n",
    "            (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "        \n",
    "        print(f\"Inserted pre-2002 record for team: {name}\")\n",
    "    \n",
    "# Check for changes and update if needed\n",
    "for x in df.index:\n",
    "    team_id = df['team_id'].loc[x]\n",
    "    name = df['team_name'].loc[x]\n",
    "    name_short = df['team_name_short'].loc[x]\n",
    "    team_id_pfr = df['team_id_pfr'].loc[x]\n",
    "    conference = df['team_conference'].loc[x]\n",
    "    division = df['team_division'].loc[x]\n",
    "\n",
    "    # Clean data\n",
    "    team_id = handle_na(team_id)\n",
    "    name = handle_na(name)\n",
    "    name_short = handle_na(name_short)\n",
    "    team_id_pfr = handle_na(team_id_pfr)\n",
    "    conference = handle_na(conference)\n",
    "    division = handle_na(division)\n",
    "\n",
    "    # Get current values\n",
    "    cursor.execute(\"SELECT name, name_short, team_id_pfr, conference, division FROM current_teams WHERE team_id = %s;\", (team_id,))\n",
    "    current = cursor.fetchone()\n",
    "    \n",
    "    if current:\n",
    "        current_values = list(current)\n",
    "        new_values = [name, name_short, team_id_pfr, conference, division]\n",
    "        \n",
    "        # Check if any values have changed\n",
    "        if current_values != new_values:            \n",
    "            cursor.execute('''\n",
    "                INSERT INTO team_history \n",
    "                (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s);\n",
    "            ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "            \n",
    "            # Update current_teams\n",
    "            cursor.execute('''\n",
    "                UPDATE current_teams \n",
    "                SET name = %s, name_short = %s, team_id_pfr = %s, conference = %s, division = %s\n",
    "                WHERE team_id = %s;\n",
    "            ''', (name, name_short, team_id_pfr, conference, division, team_id))\n",
    "            \n",
    "            print(f\"Updated record for team: {name}\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nCurrent Teams table:\")\n",
    "teams_df = pd.read_sql(\"SELECT * FROM current_teams\", conn)\n",
    "print(f\"Number of current teams: {len(teams_df)}\\n\", teams_df)\n",
    "\n",
    "print(\"\\nTeam History table:\")\n",
    "history_df = pd.read_sql(\"SELECT * FROM team_history\", conn)\n",
    "print(f\"Number of history records: {len(history_df)}\\n\", history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffcdf7fa-3858-450b-a112-c1d21ff3cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/4107959282.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_customers = pd.read_sql('SELECT customer_id FROM customers;', conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2024-12-07 12:02:38\n",
      "Processed 100 customers (5.0%) | Last 100 customers: 0:04 | Total time: 0:04 | Finished at: 2024-12-07 12:02:43\n",
      "Processed 200 customers (10.0%) | Last 100 customers: 0:04 | Total time: 0:08 | Finished at: 2024-12-07 12:02:47\n",
      "Processed 300 customers (15.0%) | Last 100 customers: 0:04 | Total time: 0:13 | Finished at: 2024-12-07 12:02:52\n",
      "Processed 400 customers (20.0%) | Last 100 customers: 0:04 | Total time: 0:17 | Finished at: 2024-12-07 12:02:56\n",
      "Processed 500 customers (25.0%) | Last 100 customers: 0:04 | Total time: 0:21 | Finished at: 2024-12-07 12:03:00\n",
      "Processed 600 customers (30.0%) | Last 100 customers: 0:04 | Total time: 0:26 | Finished at: 2024-12-07 12:03:05\n",
      "Processed 700 customers (35.0%) | Last 100 customers: 0:04 | Total time: 0:30 | Finished at: 2024-12-07 12:03:09\n",
      "Processed 800 customers (40.0%) | Last 100 customers: 0:04 | Total time: 0:34 | Finished at: 2024-12-07 12:03:13\n",
      "Processed 900 customers (45.0%) | Last 100 customers: 0:04 | Total time: 0:39 | Finished at: 2024-12-07 12:03:18\n",
      "Processed 1000 customers (50.0%) | Last 100 customers: 0:04 | Total time: 0:43 | Finished at: 2024-12-07 12:03:22\n",
      "Processed 1100 customers (55.0%) | Last 100 customers: 0:04 | Total time: 0:48 | Finished at: 2024-12-07 12:03:27\n",
      "Processed 1200 customers (60.0%) | Last 100 customers: 0:04 | Total time: 0:52 | Finished at: 2024-12-07 12:03:31\n",
      "Processed 1300 customers (65.0%) | Last 100 customers: 0:04 | Total time: 0:56 | Finished at: 2024-12-07 12:03:35\n",
      "Processed 1400 customers (70.0%) | Last 100 customers: 0:04 | Total time: 1:01 | Finished at: 2024-12-07 12:03:40\n",
      "Processed 1500 customers (75.0%) | Last 100 customers: 0:04 | Total time: 1:05 | Finished at: 2024-12-07 12:03:44\n",
      "Processed 1600 customers (80.0%) | Last 100 customers: 0:04 | Total time: 1:10 | Finished at: 2024-12-07 12:03:49\n",
      "Processed 1700 customers (85.0%) | Last 100 customers: 0:04 | Total time: 1:14 | Finished at: 2024-12-07 12:03:53\n",
      "Processed 1800 customers (90.0%) | Last 100 customers: 0:04 | Total time: 1:18 | Finished at: 2024-12-07 12:03:57\n",
      "Processed 1900 customers (95.0%) | Last 100 customers: 0:04 | Total time: 1:23 | Finished at: 2024-12-07 12:04:02\n",
      "Processed 2000 customers (100.0%) | Last 100 customers: 0:04 | Total time: 1:27 | Finished at: 2024-12-07 12:04:06\n",
      "\n",
      "Total processing time: 1:27\n",
      "\n",
      "Customers table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/4107959282.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customers_df = pd.read_sql(\"SELECT * FROM customers\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers: 2000\n",
      "      customer_id first_name last_name  age customer_type  customer_since  \\\n",
      "0               1   Coraline    Flores   23        online            2022   \n",
      "1               2    Presley     Ortiz   41        online            2021   \n",
      "2               3       Reid    Knight   40        online            2023   \n",
      "3               4   Clarissa  Chandler   43         local            2023   \n",
      "4               5      Isaac    Vaughn   23         phone            2023   \n",
      "...           ...        ...       ...  ...           ...             ...   \n",
      "1995         1996     Maxine      Pope   36         local            2020   \n",
      "1996         1997    Camilla     Wolfe   46         local            2020   \n",
      "1997         1998     Karina    Knight   36         local            2020   \n",
      "1998         1999  Sebastian   Winters   55         local            2020   \n",
      "1999         2000   Hadassah      Wade   29         local            2021   \n",
      "\n",
      "      income  household_size mode_color  \n",
      "0     116000               1        red  \n",
      "1     111000               1       blue  \n",
      "2      55000               1      green  \n",
      "3      32000               2     orange  \n",
      "4      46000               1       blue  \n",
      "...      ...             ...        ...  \n",
      "1995   29000               2       blue  \n",
      "1996   62000               2     purple  \n",
      "1997   64000               1     orange  \n",
      "1998   93000               1     purple  \n",
      "1999  150000               4      black  \n",
      "\n",
      "[2000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Customers\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM customer_table;\", pymssql_conn)\n",
    "# df = pd.read_csv('customer_data.csv') # Testing because mac won't connect to pymssql\n",
    "\n",
    "# Get current customers and convert to list\n",
    "current_customers = pd.read_sql('SELECT customer_id FROM customers;', conn)\n",
    "cc = current_customers['customer_id'].tolist()\n",
    "\n",
    "# Initialize timer to see how long ingestion takes. (just out of curiosity)\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each customer\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    customer_id = int_convert(df['customer_id'].loc[x])\n",
    "    \n",
    "    # Only proceed if customer is new\n",
    "    if customer_id not in cc:\n",
    "        cc.append(customer_id)\n",
    "        \n",
    "        customer_name = df['customer_name'].loc[x]\n",
    "        age = int_convert(df['customer_age'].loc[x])\n",
    "        customer_type = handle_na(df['customer_type'].loc[x])\n",
    "        customer_since = int_convert(df['customer_since'].loc[x])\n",
    "        income = int_convert(df['customer_income'].loc[x])\n",
    "        household_size = int_convert(df['household_size'].loc[x])\n",
    "        mode_color = handle_na(df['mode_color'].loc[x])\n",
    "        \n",
    "        # Name\n",
    "        name_parts = customer_name.split(' ')\n",
    "        if len(name_parts) == 2:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = name_parts[1]\n",
    "        else:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = ' '.join(name_parts[1:])\n",
    "        \n",
    "        # Insert into customers table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO customers \n",
    "            (customer_id, first_name, last_name, age, customer_type, customer_since, income, household_size, mode_color)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (customer_id, first_name, last_name, age, customer_type, customer_since, income, household_size, mode_color))\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0 or counter == 1:  # Print progress every 100 records\n",
    "            current_time = time.time()\n",
    "            elapsed_since_last = current_time - last_check\n",
    "            total_elapsed = current_time - start_time\n",
    "    \n",
    "            last_check_min = int(elapsed_since_last // 60)\n",
    "            last_check_sec = int(elapsed_since_last % 60)\n",
    "            total_min = int(total_elapsed // 60)\n",
    "            total_sec = int(total_elapsed % 60)\n",
    "    \n",
    "            percent_complete = (counter / len(df)) * 100\n",
    "\n",
    "            readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(current_time))\n",
    "            if counter == 1:\n",
    "                print(f\"Started at {readable_time}\")\n",
    "            else:\n",
    "                print(f\"Processed {counter} customers ({percent_complete:.1f}%) | Last 100 customers: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d} | Finished at: {readable_time}\")\n",
    "            \n",
    "            last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nCustomers table:\")\n",
    "customers_df = pd.read_sql(\"SELECT * FROM customers\", conn)\n",
    "print(f\"Number of customers: {len(cc)}\")\n",
    "print(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a6bd5dc-67eb-4e4d-9144-90fa887c4efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/573614324.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_games = pd.read_sql(\"SELECT game_id FROM games;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2024-12-07 12:04:07\n",
      "Processed 100 games (4.1%) | Last 100 games: 0:17 | Total time: 0:17 | Finished at: 2024-12-07 12:04:25\n",
      "Processed 200 games (8.1%) | Last 100 games: 0:17 | Total time: 0:35 | Finished at: 2024-12-07 12:04:42\n",
      "Processed 300 games (12.2%) | Last 100 games: 0:17 | Total time: 0:52 | Finished at: 2024-12-07 12:05:00\n",
      "Processed 400 games (16.3%) | Last 100 games: 0:17 | Total time: 1:10 | Finished at: 2024-12-07 12:05:17\n",
      "Processed 500 games (20.3%) | Last 100 games: 0:17 | Total time: 1:27 | Finished at: 2024-12-07 12:05:35\n",
      "Processed 600 games (24.4%) | Last 100 games: 0:17 | Total time: 1:45 | Finished at: 2024-12-07 12:05:52\n",
      "Processed 700 games (28.5%) | Last 100 games: 0:17 | Total time: 2:03 | Finished at: 2024-12-07 12:06:10\n",
      "Processed 800 games (32.5%) | Last 100 games: 0:17 | Total time: 2:20 | Finished at: 2024-12-07 12:06:27\n",
      "Processed 900 games (36.6%) | Last 100 games: 0:17 | Total time: 2:37 | Finished at: 2024-12-07 12:06:45\n",
      "Processed 1000 games (40.7%) | Last 100 games: 0:17 | Total time: 2:55 | Finished at: 2024-12-07 12:07:02\n",
      "Added new stadium: Dignity Health Sports Park with ID: 119\n",
      "Processed 1100 games (44.8%) | Last 100 games: 0:17 | Total time: 3:13 | Finished at: 2024-12-07 12:07:20\n",
      "Processed 1200 games (48.8%) | Last 100 games: 0:17 | Total time: 3:30 | Finished at: 2024-12-07 12:07:38\n",
      "Processed 1300 games (52.9%) | Last 100 games: 0:17 | Total time: 3:48 | Finished at: 2024-12-07 12:07:55\n",
      "Processed 1400 games (57.0%) | Last 100 games: 0:17 | Total time: 4:05 | Finished at: 2024-12-07 12:08:13\n",
      "Processed 1500 games (61.0%) | Last 100 games: 0:17 | Total time: 4:23 | Finished at: 2024-12-07 12:08:30\n",
      "Processed 1600 games (65.1%) | Last 100 games: 0:17 | Total time: 4:41 | Finished at: 2024-12-07 12:08:48\n",
      "Processed 1700 games (69.2%) | Last 100 games: 0:17 | Total time: 4:58 | Finished at: 2024-12-07 12:09:05\n",
      "Processed 1800 games (73.2%) | Last 100 games: 0:17 | Total time: 5:16 | Finished at: 2024-12-07 12:09:23\n",
      "Processed 1900 games (77.3%) | Last 100 games: 0:17 | Total time: 5:33 | Finished at: 2024-12-07 12:09:40\n",
      "Processed 2000 games (81.4%) | Last 100 games: 0:17 | Total time: 5:51 | Finished at: 2024-12-07 12:09:58\n",
      "Processed 2100 games (85.4%) | Last 100 games: 0:17 | Total time: 6:09 | Finished at: 2024-12-07 12:10:16\n",
      "Processed 2200 games (89.5%) | Last 100 games: 0:17 | Total time: 6:26 | Finished at: 2024-12-07 12:10:33\n",
      "Processed 2300 games (93.6%) | Last 100 games: 0:17 | Total time: 6:43 | Finished at: 2024-12-07 12:10:51\n",
      "Added new stadium: Frankfurt Stadium with ID: 120\n",
      "Processed 2400 games (97.6%) | Last 100 games: 0:17 | Total time: 7:01 | Finished at: 2024-12-07 12:11:08\n",
      "\n",
      "Total processing time: 7:11\n",
      "\n",
      "Games table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_7036/573614324.py:157: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  games_df = pd.read_sql(\"SELECT * FROM games;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games: 2458\n",
      "             game_id schedule_date  schedule_season  schedule_week  \\\n",
      "0      201501-NE-PIT    2015-09-10             2015              1   \n",
      "1      201501-ARI-NO    2015-09-13             2015              1   \n",
      "2     201501-BUF-IND    2015-09-13             2015              1   \n",
      "3      201501-CHI-GB    2015-09-13             2015              1   \n",
      "4     201501-DAL-NYG    2015-09-13             2015              1   \n",
      "...              ...           ...              ...            ...   \n",
      "2453   202320-BUF-KC    2024-01-21             2023             20   \n",
      "2454   202320-DET-TB    2024-01-21             2023             20   \n",
      "2455   202321-BAL-KC    2024-01-28             2023             21   \n",
      "2456   202321-SF-DET    2024-01-28             2023             21   \n",
      "2457    202322-KC-SF    2024-02-11             2023             22   \n",
      "\n",
      "      schedule_playoff playoff_type team_id_home team_id_away  score_home  \\\n",
      "0                False         None           NE          PIT          28   \n",
      "1                False         None          ARI           NO          31   \n",
      "2                False         None          BUF          IND          27   \n",
      "3                False         None          CHI           GB          23   \n",
      "4                False         None          DAL          NYG          27   \n",
      "...                ...          ...          ...          ...         ...   \n",
      "2453              True     Division          BUF           KC          24   \n",
      "2454              True     Division          DET           TB          31   \n",
      "2455              True   Conference          BAL           KC          10   \n",
      "2456              True   Conference           SF          DET          34   \n",
      "2457              True    Superbowl           KC           SF          25   \n",
      "\n",
      "      score_away  ... spread_favorite  over_under_line  stadium_id  \\\n",
      "0             21  ...            -7.0             51.0          36   \n",
      "1             19  ...            -2.5             48.5         111   \n",
      "2             14  ...            -1.0             44.5          81   \n",
      "3             31  ...            -6.5             48.5          92   \n",
      "4             26  ...            -7.0             52.5          21   \n",
      "...          ...  ...             ...              ...         ...   \n",
      "2453          27  ...            -2.5             46.0          40   \n",
      "2454          23  ...            -6.0             49.5          30   \n",
      "2455          17  ...            -4.5             44.0          59   \n",
      "2456          31  ...            -7.5             53.5          51   \n",
      "2457          22  ...            -2.0             47.0           3   \n",
      "\n",
      "      stadium_neutral  weather_temperature  weather_wind_mph  \\\n",
      "0               False                 64.0               9.0   \n",
      "1               False                 72.0               0.0   \n",
      "2               False                 53.0               7.0   \n",
      "3               False                 68.0               4.0   \n",
      "4               False                 72.0               0.0   \n",
      "...               ...                  ...               ...   \n",
      "2453            False                 25.0              11.0   \n",
      "2454            False                 72.0               0.0   \n",
      "2455            False                 47.0               7.0   \n",
      "2456            False                 69.0               5.0   \n",
      "2457             True                 72.0               0.0   \n",
      "\n",
      "      weather_humidity  weather_detail winner_ou winner_line  \n",
      "0                  NaN            rain     under        push  \n",
      "1                  NaN          indoor      over        home  \n",
      "2                  NaN            None     under        home  \n",
      "3                  NaN            None      over        away  \n",
      "4                  NaN          indoor      over        away  \n",
      "...                ...             ...       ...         ...  \n",
      "2453              67.0            None      over        away  \n",
      "2454               NaN          indoor      over        home  \n",
      "2455              83.0            None     under        away  \n",
      "2456              55.0            None      over        away  \n",
      "2457               NaN          indoor      push        home  \n",
      "\n",
      "[2458 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Games\n",
    "\n",
    "# Read games data\n",
    "df = pd.read_csv('spread_scores-2.csv')\n",
    "\n",
    "# Filter for games in/after 2015\n",
    "df = df[df['schedule_season'] >= 2015]\n",
    "\n",
    "# Get current games and convert to list\n",
    "current_games = pd.read_sql(\"SELECT game_id FROM games;\", conn)\n",
    "cg = current_games['game_id'].tolist()\n",
    "\n",
    "TEAM_ID_CORRECTIONS = {'LV': 'LVR'}\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each game\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    # Build game_id \n",
    "    season = str(df['schedule_season'].loc[x])\n",
    "    weeknum = df['schedule_week'].loc[x]\n",
    "    \n",
    "    if weeknum == \"Wildcard\":\n",
    "        playoff_type = \"Wildcard\"\n",
    "        weeknum = \"19\"\n",
    "    elif weeknum == \"Division\":\n",
    "        playoff_type = \"Division\"\n",
    "        weeknum = \"20\"\n",
    "    elif weeknum == \"Conference\":\n",
    "        playoff_type = \"Conference\"\n",
    "        weeknum = \"21\"\n",
    "    elif weeknum == \"Superbowl\":\n",
    "        playoff_type = \"Superbowl\"\n",
    "        weeknum = \"22\"\n",
    "    else:\n",
    "        playoff_type = None\n",
    "        weeknum = str(weeknum)\n",
    "        \n",
    "    if len(weeknum) < 2: \n",
    "        weeknum = \"0\" + weeknum\n",
    "\n",
    "    weekstring = weeknum\n",
    "    weeknum = int_convert(weeknum)\n",
    "    \n",
    "    cursor.execute(f\"SELECT DISTINCT team_id FROM team_history WHERE name = '{df['team_home'].loc[x]}';\")\n",
    "    home_id = cursor.fetchone()[0]\n",
    "    home_id = TEAM_ID_CORRECTIONS.get(home_id, home_id)\n",
    "    \n",
    "    cursor.execute(f\"SELECT DISTINCT team_id FROM team_history WHERE name = '{df['team_away'].loc[x]}';\")\n",
    "    away_id = cursor.fetchone()[0]\n",
    "    away_id = TEAM_ID_CORRECTIONS.get(away_id, away_id)\n",
    "    \n",
    "    game_id = f\"{season}{weekstring}-{home_id}-{away_id}\"\n",
    "    \n",
    "    # Only proceed if game is new\n",
    "    if game_id not in cg:\n",
    "        cg.append(game_id)\n",
    "        \n",
    "        # Get data and clean\n",
    "        schedule_date = datetime.strptime(df['schedule_date'].loc[x], '%m/%d/%Y')\n",
    "        schedule_season = int_convert(df['schedule_season'].loc[x])\n",
    "        schedule_week = weeknum\n",
    "        schedule_playoff = bool(df['schedule_playoff'].loc[x])\n",
    "        score_home = int_convert(df['score_home'].loc[x])\n",
    "        score_away = int_convert(df['score_away'].loc[x])\n",
    "        team_favorite_id = df['team_favorite_id'].loc[x]\n",
    "        spread_favorite = df['spread_favorite'].loc[x]\n",
    "        over_under_line = df['over_under_line'].loc[x]\n",
    "        stadium_name = df['stadium'].loc[x]\n",
    "        stadium_neutral = bool(df['stadium_neutral'].loc[x])\n",
    "        weather_temperature = int_convert(df['weather_temperature'].loc[x])\n",
    "        weather_wind_mph = int_convert(df['weather_wind_mph'].loc[x])\n",
    "        weather_humidity = int_convert(df['weather_humidity'].loc[x])\n",
    "        weather_detail = handle_na(df['weather_detail'].loc[x])        \n",
    "\n",
    "\n",
    "        # Find stadium\n",
    "        stadium_id = None\n",
    "        cursor.execute(\"SELECT stadium_id FROM stadiums WHERE name = %s;\", (stadium_name,))\n",
    "        stadium_result = cursor.fetchone()\n",
    "\n",
    "        if stadium_result:\n",
    "            stadium_id = stadium_result[0]\n",
    "        else:\n",
    "            # Insert new stadium and get its ID\n",
    "            cursor.execute('''INSERT INTO stadiums (name) VALUES (%s);''', (stadium_name,))\n",
    "            conn.commit()\n",
    "            cursor.execute(\"SELECT stadium_id FROM stadiums WHERE name = %s;\", (stadium_name,))\n",
    "            stadium_id = cursor.fetchone()[0]\n",
    "            print(f\"Added new stadium: {stadium_name} with ID: {stadium_id}\")\n",
    "        \n",
    "        # Handle PICK\n",
    "        if team_favorite_id == 'PICK':\n",
    "            team_favorite_id = home_id  # Use home team because PICK messes with FK. Will always be a push anyways\n",
    "        else:\n",
    "            team_favorite_id = TEAM_ID_CORRECTIONS.get(team_favorite_id, team_favorite_id)\n",
    "        \n",
    "        # Calculate winner_ou and winner_line\n",
    "        total_score = score_home + score_away\n",
    "        winner_ou = get_winner_ou(total_score, over_under_line)\n",
    "        winner_line = get_winner_line(score_home, score_away, spread_favorite, team_favorite_id, home_id)\n",
    "\n",
    "        # Insert into games table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO games (\n",
    "                game_id, schedule_date, schedule_season, schedule_week, \n",
    "                schedule_playoff, playoff_type, team_id_home, team_id_away, \n",
    "                score_home, score_away, team_id_favorite, spread_favorite,\n",
    "                over_under_line, stadium_id, stadium_neutral, \n",
    "                weather_temperature, weather_wind_mph, weather_humidity,\n",
    "                weather_detail, winner_ou, winner_line)\n",
    "            VALUES (\n",
    "                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (game_id, schedule_date, schedule_season, schedule_week,\n",
    "              schedule_playoff, playoff_type, home_id, away_id,\n",
    "              score_home, score_away, team_favorite_id, spread_favorite,\n",
    "              over_under_line, stadium_id, stadium_neutral,\n",
    "              weather_temperature, weather_wind_mph, weather_humidity,\n",
    "              weather_detail, winner_ou, winner_line))\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0 or counter == 1:  # Print progress every 100 records\n",
    "            current_time = time.time()\n",
    "            elapsed_since_last = current_time - last_check\n",
    "            total_elapsed = current_time - start_time\n",
    "    \n",
    "            last_check_min = int(elapsed_since_last // 60)\n",
    "            last_check_sec = int(elapsed_since_last % 60)\n",
    "            total_min = int(total_elapsed // 60)\n",
    "            total_sec = int(total_elapsed % 60)\n",
    "    \n",
    "            percent_complete = (counter / len(df)) * 100\n",
    "\n",
    "            readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(current_time))\n",
    "            if counter == 1:\n",
    "                print(f\"Started at {readable_time}\")\n",
    "            else:\n",
    "                print(f\"Processed {counter} games ({percent_complete:.1f}%) | Last 100 games: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d} | Finished at: {readable_time}\")\n",
    "            \n",
    "            last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nGames table:\")\n",
    "games_df = pd.read_sql(\"SELECT * FROM games;\", conn)\n",
    "print(f\"Number of games: {len(cg)}\")\n",
    "print(games_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "271b9f85-0c0a-4f8b-a641-0d1305806292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/200328037.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_bets = pd.read_sql(\"SELECT bet_id FROM placed_bets;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 80000 bets (63.5%) | Last 1000 bets: 2:52 | Total time: 2:52 | Finished at: 2024-12-08 01:07:20\n",
      "Processed 81000 bets (64.3%) | Last 1000 bets: 2:52 | Total time: 5:44 | Finished at: 2024-12-08 01:10:13\n",
      "Processed 82000 bets (65.1%) | Last 1000 bets: 2:51 | Total time: 8:36 | Finished at: 2024-12-08 01:13:05\n",
      "Processed 83000 bets (65.8%) | Last 1000 bets: 2:50 | Total time: 11:27 | Finished at: 2024-12-08 01:15:56\n",
      "Processed 84000 bets (66.6%) | Last 1000 bets: 2:52 | Total time: 14:19 | Finished at: 2024-12-08 01:18:48\n",
      "Processed 85000 bets (67.4%) | Last 1000 bets: 3:01 | Total time: 17:20 | Finished at: 2024-12-08 01:21:49\n",
      "Processed 86000 bets (68.2%) | Last 1000 bets: 3:01 | Total time: 20:21 | Finished at: 2024-12-08 01:24:50\n",
      "Processed 87000 bets (69.0%) | Last 1000 bets: 2:52 | Total time: 23:14 | Finished at: 2024-12-08 01:27:43\n",
      "Processed 88000 bets (69.8%) | Last 1000 bets: 2:53 | Total time: 26:07 | Finished at: 2024-12-08 01:30:36\n",
      "Processed 89000 bets (70.6%) | Last 1000 bets: 2:49 | Total time: 28:57 | Finished at: 2024-12-08 01:33:25\n",
      "Processed 90000 bets (71.4%) | Last 1000 bets: 2:51 | Total time: 31:48 | Finished at: 2024-12-08 01:36:16\n",
      "Processed 91000 bets (72.2%) | Last 1000 bets: 2:52 | Total time: 34:40 | Finished at: 2024-12-08 01:39:09\n",
      "Processed 92000 bets (73.0%) | Last 1000 bets: 2:50 | Total time: 37:31 | Finished at: 2024-12-08 01:41:59\n",
      "Processed 93000 bets (73.8%) | Last 1000 bets: 2:51 | Total time: 40:22 | Finished at: 2024-12-08 01:44:51\n",
      "Processed 94000 bets (74.6%) | Last 1000 bets: 2:54 | Total time: 43:16 | Finished at: 2024-12-08 01:47:45\n",
      "Processed 95000 bets (75.4%) | Last 1000 bets: 2:52 | Total time: 46:09 | Finished at: 2024-12-08 01:50:37\n",
      "Processed 96000 bets (76.2%) | Last 1000 bets: 2:49 | Total time: 48:58 | Finished at: 2024-12-08 01:53:27\n",
      "Processed 97000 bets (77.0%) | Last 1000 bets: 2:52 | Total time: 51:51 | Finished at: 2024-12-08 01:56:19\n",
      "Processed 98000 bets (77.7%) | Last 1000 bets: 2:52 | Total time: 54:43 | Finished at: 2024-12-08 01:59:12\n",
      "Processed 99000 bets (78.5%) | Last 1000 bets: 2:50 | Total time: 57:34 | Finished at: 2024-12-08 02:02:03\n",
      "Processed 100000 bets (79.3%) | Last 1000 bets: 2:49 | Total time: 60:23 | Finished at: 2024-12-08 02:04:52\n",
      "Processed 101000 bets (80.1%) | Last 1000 bets: 2:51 | Total time: 63:15 | Finished at: 2024-12-08 02:07:43\n",
      "Processed 102000 bets (80.9%) | Last 1000 bets: 2:51 | Total time: 66:06 | Finished at: 2024-12-08 02:10:35\n",
      "Processed 103000 bets (81.7%) | Last 1000 bets: 2:52 | Total time: 68:58 | Finished at: 2024-12-08 02:13:27\n",
      "Processed 104000 bets (82.5%) | Last 1000 bets: 2:52 | Total time: 71:51 | Finished at: 2024-12-08 02:16:20\n",
      "Processed 105000 bets (83.3%) | Last 1000 bets: 2:50 | Total time: 74:42 | Finished at: 2024-12-08 02:19:11\n",
      "Processed 106000 bets (84.1%) | Last 1000 bets: 2:54 | Total time: 77:36 | Finished at: 2024-12-08 02:22:05\n",
      "Processed 107000 bets (84.9%) | Last 1000 bets: 2:52 | Total time: 80:29 | Finished at: 2024-12-08 02:24:58\n",
      "Processed 108000 bets (85.7%) | Last 1000 bets: 2:52 | Total time: 83:22 | Finished at: 2024-12-08 02:27:51\n",
      "Processed 109000 bets (86.5%) | Last 1000 bets: 2:53 | Total time: 86:15 | Finished at: 2024-12-08 02:30:44\n",
      "Processed 110000 bets (87.3%) | Last 1000 bets: 2:51 | Total time: 89:07 | Finished at: 2024-12-08 02:33:36\n",
      "Processed 111000 bets (88.1%) | Last 1000 bets: 2:52 | Total time: 91:59 | Finished at: 2024-12-08 02:36:28\n",
      "Processed 112000 bets (88.9%) | Last 1000 bets: 2:52 | Total time: 94:52 | Finished at: 2024-12-08 02:39:21\n",
      "Processed 113000 bets (89.6%) | Last 1000 bets: 2:51 | Total time: 97:43 | Finished at: 2024-12-08 02:42:12\n",
      "Processed 114000 bets (90.4%) | Last 1000 bets: 2:50 | Total time: 100:33 | Finished at: 2024-12-08 02:45:02\n",
      "Processed 115000 bets (91.2%) | Last 1000 bets: 2:52 | Total time: 103:26 | Finished at: 2024-12-08 02:47:55\n",
      "Processed 116000 bets (92.0%) | Last 1000 bets: 2:52 | Total time: 106:19 | Finished at: 2024-12-08 02:50:47\n",
      "Processed 117000 bets (92.8%) | Last 1000 bets: 2:53 | Total time: 109:12 | Finished at: 2024-12-08 02:53:40\n",
      "Processed 118000 bets (93.6%) | Last 1000 bets: 2:52 | Total time: 112:04 | Finished at: 2024-12-08 02:56:33\n",
      "Processed 119000 bets (94.4%) | Last 1000 bets: 2:52 | Total time: 114:56 | Finished at: 2024-12-08 02:59:25\n",
      "Processed 120000 bets (95.2%) | Last 1000 bets: 2:51 | Total time: 117:48 | Finished at: 2024-12-08 03:02:17\n",
      "Processed 121000 bets (96.0%) | Last 1000 bets: 2:52 | Total time: 120:41 | Finished at: 2024-12-08 03:05:09\n",
      "Processed 122000 bets (96.8%) | Last 1000 bets: 2:51 | Total time: 123:32 | Finished at: 2024-12-08 03:08:01\n",
      "Processed 123000 bets (97.6%) | Last 1000 bets: 2:51 | Total time: 126:24 | Finished at: 2024-12-08 03:10:53\n",
      "Processed 124000 bets (98.4%) | Last 1000 bets: 2:52 | Total time: 129:16 | Finished at: 2024-12-08 03:13:45\n",
      "Processed 125000 bets (99.2%) | Last 1000 bets: 2:53 | Total time: 132:10 | Finished at: 2024-12-08 03:16:38\n",
      "Processed 126000 bets (100.0%) | Last 1000 bets: 2:52 | Total time: 135:02 | Finished at: 2024-12-08 03:19:31\n",
      "\n",
      "Total processing time: 135:10\n",
      "\n",
      "Bets table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/200328037.py:103: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  bets_df = pd.read_sql(\"SELECT * FROM placed_bets;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bets: 126047\n",
      "        bet_id  customer_id        game_id  bet_amount               bet_on  \\\n",
      "0            1            1  202301-KC-DET        8500        Detroit Lions   \n",
      "1            2            7  202301-KC-DET         350                under   \n",
      "2            3            8  202301-KC-DET       10000   Kansas City Chiefs   \n",
      "3            4           23  202301-KC-DET         200                under   \n",
      "4            5           24  202301-KC-DET         400                 over   \n",
      "...        ...          ...            ...         ...                  ...   \n",
      "126042  126043         1988   202322-KC-SF        2500  San Francisco 49ers   \n",
      "126043  126044         1989   202322-KC-SF         100  San Francisco 49ers   \n",
      "126044  126045         1991   202322-KC-SF        1700   Kansas City Chiefs   \n",
      "126045  126046         1995   202322-KC-SF         225                 push   \n",
      "126046  126047         1999   202322-KC-SF        1800   Kansas City Chiefs   \n",
      "\n",
      "       bet_on_team_id result  commission_amount  \n",
      "0                 DET    win              630.0  \n",
      "1                None    win               35.0  \n",
      "2                  KC   loss              720.0  \n",
      "3                None    win               20.0  \n",
      "4                None   loss               40.0  \n",
      "...               ...    ...                ...  \n",
      "126042             SF   loss              220.0  \n",
      "126043             SF   loss               10.0  \n",
      "126044             KC    win              156.0  \n",
      "126045           None   loss               22.5  \n",
      "126046             KC    win              164.0  \n",
      "\n",
      "[126047 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Bets\n",
    "\n",
    "# Read betting data\n",
    "df = pd.read_sql(\"SELECT * FROM betlog;\", pymssql_conn)\n",
    "# df = pd.read_csv('betting_data.csv') # Testing because mac won't connect to pymssql\n",
    "\n",
    "# Get current bets and convert to list\n",
    "current_bets = pd.read_sql(\"SELECT bet_id FROM placed_bets;\", conn)\n",
    "cb = current_bets['bet_id'].tolist()\n",
    "GAME_ID_CORRECTIONS = {'LV': 'LVR', 'JAC': 'JAX'}\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each bet\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    # if counter >= 3000: # Testing\n",
    "    #     break\n",
    "    # if counter < 79000:  # Skip records we already processed\n",
    "    #     counter += 1\n",
    "    #     continue\n",
    "        \n",
    "    bet_id = int_convert(df['bet_id'].loc[x])\n",
    "    \n",
    "    # Only proceed if bet is new\n",
    "    if bet_id not in cb:\n",
    "        cb.append(bet_id)\n",
    "        \n",
    "        customer_id = int_convert(df['customer_id'].loc[x])\n",
    "\n",
    "        # Fix game ids\n",
    "        game_id = df['game_id'].loc[x]\n",
    "        game_id_parts = game_id.split('-')\n",
    "        season_week, team1, team2 = game_id_parts\n",
    "        team1 = GAME_ID_CORRECTIONS.get(team1, team1)\n",
    "        team2 = GAME_ID_CORRECTIONS.get(team2, team2)\n",
    "        game_id = f\"{season_week}-{team1}-{team2}\"\n",
    "\n",
    "        bet_amount = int_convert(df['bet_amount'].loc[x])\n",
    "        bet_on = df['bet_on'].loc[x]\n",
    "\n",
    "        if bet_on not in ['over', 'under', 'push']:\n",
    "            cursor.execute(\"SELECT DISTINCT team_id FROM team_history WHERE name = %s;\", (bet_on,))\n",
    "            bet_team = cursor.fetchone()\n",
    "            bet_on_team_id = bet_team[0] if bet_team else None\n",
    "        else:\n",
    "            bet_on_team_id = None\n",
    "        \n",
    "        # Get game details for bet result\n",
    "        cursor.execute(\"SELECT winner_line, winner_ou, team_id_home FROM games WHERE game_id = %s;\", (game_id,))\n",
    "        game_details = cursor.fetchone()\n",
    "        \n",
    "        if game_details:\n",
    "            winner_line, winner_ou, team_id_home = game_details\n",
    "            \n",
    "            # Get result and commission\n",
    "            result = determine_bet_result(bet_on, winner_line, winner_ou, team_id_home)                \n",
    "            commission_amount = calculate_commission(bet_amount)\n",
    "            \n",
    "            # Insert into placed_bets table\n",
    "            cursor.execute('''\n",
    "                INSERT INTO placed_bets (bet_id, customer_id, game_id, bet_amount, bet_on, bet_on_team_id, result, commission_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n",
    "            ''', (bet_id, customer_id, game_id, bet_amount, bet_on, bet_on_team_id, result, commission_amount))\n",
    "        else:\n",
    "            print(f\"Error: Could not find game details for game_id {game_id}\")\n",
    "            \n",
    "    counter += 1\n",
    "    if counter % 1000 == 0 or counter == 1:  # Print progress every 1000 records\n",
    "        conn.commit()\n",
    "        current_time = time.time()\n",
    "        elapsed_since_last = current_time - last_check\n",
    "        total_elapsed = current_time - start_time\n",
    "\n",
    "        last_check_min = int(elapsed_since_last // 60)\n",
    "        last_check_sec = int(elapsed_since_last % 60)\n",
    "        total_min = int(total_elapsed // 60)\n",
    "        total_sec = int(total_elapsed % 60)\n",
    "\n",
    "        percent_complete = (counter / len(df)) * 100\n",
    "\n",
    "        readable_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(current_time))\n",
    "        if counter == 1:\n",
    "            print(f\"Started at {readable_time}\")\n",
    "        else:\n",
    "            print(f\"Processed {counter} bets ({percent_complete:.1f}%) | Last 1000 bets: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d} | Finished at: {readable_time}\")\n",
    "        \n",
    "        last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nBets table:\")\n",
    "bets_df = pd.read_sql(\"SELECT * FROM placed_bets;\", conn)\n",
    "print(f\"Number of bets: {len(cb)}\")\n",
    "print(bets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72365cf2-5df5-4b66-b274-d5d9600bddb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows from customers:\n",
      "    customer_id first_name last_name  age customer_type  customer_since  \\\n",
      "0            1   Coraline    Flores   23        online            2022   \n",
      "1            2    Presley     Ortiz   41        online            2021   \n",
      "2            3       Reid    Knight   40        online            2023   \n",
      "3            4   Clarissa  Chandler   43         local            2023   \n",
      "4            5      Isaac    Vaughn   23         phone            2023   \n",
      "\n",
      "   income  household_size mode_color  \n",
      "0  116000               1        red  \n",
      "1  111000               1       blue  \n",
      "2   55000               1      green  \n",
      "3   32000               2     orange  \n",
      "4   46000               1       blue  \n",
      "\n",
      "First 5 rows from placed_bets:\n",
      "    bet_id  customer_id        game_id  bet_amount              bet_on  \\\n",
      "0       1            1  202301-KC-DET        8500       Detroit Lions   \n",
      "1       2            7  202301-KC-DET         350               under   \n",
      "2       3            8  202301-KC-DET       10000  Kansas City Chiefs   \n",
      "3       4           23  202301-KC-DET         200               under   \n",
      "4       5           24  202301-KC-DET         400                over   \n",
      "\n",
      "  bet_on_team_id result  commission_amount  \n",
      "0            DET    win              630.0  \n",
      "1           None    win               35.0  \n",
      "2             KC   loss              720.0  \n",
      "3           None    win               20.0  \n",
      "4           None   loss               40.0  \n",
      "\n",
      "First 5 rows from games:\n",
      "           game_id schedule_date  schedule_season  schedule_week  \\\n",
      "0   201501-NE-PIT    2015-09-10             2015              1   \n",
      "1   201501-ARI-NO    2015-09-13             2015              1   \n",
      "2  201501-BUF-IND    2015-09-13             2015              1   \n",
      "3   201501-CHI-GB    2015-09-13             2015              1   \n",
      "4  201501-DAL-NYG    2015-09-13             2015              1   \n",
      "\n",
      "   schedule_playoff playoff_type team_id_home team_id_away  score_home  \\\n",
      "0             False         None           NE          PIT          28   \n",
      "1             False         None          ARI           NO          31   \n",
      "2             False         None          BUF          IND          27   \n",
      "3             False         None          CHI           GB          23   \n",
      "4             False         None          DAL          NYG          27   \n",
      "\n",
      "   score_away  ... spread_favorite  over_under_line  stadium_id  \\\n",
      "0          21  ...            -7.0             51.0          36   \n",
      "1          19  ...            -2.5             48.5         111   \n",
      "2          14  ...            -1.0             44.5          81   \n",
      "3          31  ...            -6.5             48.5          92   \n",
      "4          26  ...            -7.0             52.5          21   \n",
      "\n",
      "   stadium_neutral  weather_temperature  weather_wind_mph  weather_humidity  \\\n",
      "0            False                   64                 9              None   \n",
      "1            False                   72                 0              None   \n",
      "2            False                   53                 7              None   \n",
      "3            False                   68                 4              None   \n",
      "4            False                   72                 0              None   \n",
      "\n",
      "  weather_detail winner_ou winner_line  \n",
      "0           rain     under        push  \n",
      "1         indoor      over        home  \n",
      "2           None     under        home  \n",
      "3           None      over        away  \n",
      "4         indoor      over        away  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/226558871.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/226558871.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/226558871.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/226558871.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows from team_history:\n",
      "    team_history_id team_id               name name_short team_id_pfr  \\\n",
      "0                1     ARI  Arizona Cardinals  Cardinals         CRD   \n",
      "1                2     ATL    Atlanta Falcons    Falcons         ATL   \n",
      "2                3     IND    Baltimore Colts      Colts         CLT   \n",
      "3                4     BAL   Baltimore Ravens     Ravens         RAV   \n",
      "4                5      NE    Boston Patriots   Patriots         NWE   \n",
      "\n",
      "  conference     division  \n",
      "0        NFC     NFC West  \n",
      "1        NFC     NFC West  \n",
      "2        AFC     AFC East  \n",
      "3        AFC  AFC Central  \n",
      "4        AFC         None  \n",
      "\n",
      "First 5 rows from current_teams:\n",
      "   team_id                name name_short team_id_pfr conference  division\n",
      "0     BUF       Buffalo Bills      Bills         BUF        AFC  AFC East\n",
      "1     DAL      Dallas Cowboys    Cowboys         DAL        NFC  NFC East\n",
      "2     DEN      Denver Broncos    Broncos         DEN        AFC  AFC West\n",
      "3      KC  Kansas City Chiefs     Chiefs         KAN        AFC  AFC West\n",
      "4     MIA      Miami Dolphins   Dolphins         MIA        AFC  AFC East\n",
      "\n",
      "First 5 rows from stadiums:\n",
      "    stadium_id               name  stadium_open stadium_close stadium_type  \\\n",
      "0           1   Acrisure Stadium        2001.0          None      outdoor   \n",
      "1           2         Alamo Dome           NaN          None       indoor   \n",
      "2           3  Allegiant Stadium        2020.0          None       indoor   \n",
      "3           4      Allianz Arena           NaN          None      outdoor   \n",
      "4           5     Alltel Stadium           NaN          None         None   \n",
      "\n",
      "       street_address          city state postal_code country  \\\n",
      "0  100 Art Rooney Ave    Pittsburgh    PA       15212      US   \n",
      "1      100 Montana St   San Antonio    TX       78203      US   \n",
      "2                None      Paradise    NV        None      US   \n",
      "3                None        Munich  None        None      DE   \n",
      "4                None  Jacksonville    FL        None      US   \n",
      "\n",
      "  weather_station_id  stadium_weather_station_code stadium_weather_type  \\\n",
      "0        USW00094823                       15212.0                 cold   \n",
      "1               None                       78203.0                 dome   \n",
      "2               None                           NaN                 dome   \n",
      "3               None                           NaN             moderate   \n",
      "4               None                           NaN                 None   \n",
      "\n",
      "  surface  \n",
      "0   Grass  \n",
      "1    Turf  \n",
      "2   Grass  \n",
      "3   Grass  \n",
      "4    None  \n",
      "\n",
      "First 5 rows from weather_stations:\n",
      "   weather_station_id                       name state country  latitude  \\\n",
      "0        USW00094823            PITTSBURGH ASOS    PA      US   40.4846   \n",
      "1        US1MOJC0028         KANSAS CITY 5.1 SE    MO      US   39.0692   \n",
      "2        USC00410337        ARLINGTON SIX FLAGS    TX      US   32.7572   \n",
      "3        USW00013881  CHARLOTTE DOUGLAS AIRPORT    NC      US   35.2236   \n",
      "4        US1NYER0093              BUFFALO 1.5 W    NY      US   42.8890   \n",
      "\n",
      "   longitude  elevation  \n",
      "0   -80.2144      366.7  \n",
      "1   -94.4871      264.9  \n",
      "2   -97.0736      163.4  \n",
      "3   -80.9552      221.9  \n",
      "4   -78.8901      178.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/226558871.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/226558871.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/226558871.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Test Queries\n",
    "\n",
    "# 1\n",
    "tables = ['customers', 'placed_bets', 'games', 'team_history', 'current_teams', 'stadiums', 'weather_stations']\n",
    "for table in tables:\n",
    "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(f\"\\nFirst 5 rows from {table}:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63d3c53-9633-4aa0-9192-f89465cf2ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/2919843573.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/2919843573.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of high-commission customers:\n",
      "    customers_over_20k  total_customers  percentage\n",
      "0                 236             2000        11.8\n",
      "\n",
      "Top 20 commission payers:\n",
      "    first_name last_name  total_commission\n",
      "0        Gary   McClain          160114.5\n",
      "1     Matthew     Booth          147968.5\n",
      "2      Vaughn     Ortiz          126964.0\n",
      "3      Bailey    Sparks          123294.0\n",
      "4       Alexa   Mendoza          122644.0\n",
      "5      Violet    Tanner          110888.0\n",
      "6       Nadia     Frank          107458.0\n",
      "7     Harmoni   Burnett           98722.5\n",
      "8       Simon     Cohen           98533.5\n",
      "9       Lucas    Wagner           96160.5\n",
      "10      Clark    Jordan           93224.5\n",
      "11      April    Martin           93212.5\n",
      "12       Kate     Noble           89231.0\n",
      "13       Lara   Hoffman           89225.0\n",
      "14    Winston     Short           86980.0\n",
      "15     Chanel      Pope           86525.5\n",
      "16     Austin    Flores           86287.5\n",
      "17     Warren   Barnett           85294.0\n",
      "18    Adeline    Conner           85096.5\n",
      "19   Emmaline    Hodges           84723.0\n"
     ]
    }
   ],
   "source": [
    "# 2a\n",
    "query = \"\"\"\n",
    "WITH commission_totals AS (\n",
    "    SELECT c.customer_id, SUM(commission_amount) AS total_commission\n",
    "    FROM customers c\n",
    "    JOIN placed_bets pb ON c.customer_id = pb.customer_id\n",
    "    GROUP BY c.customer_id\n",
    "    HAVING SUM(commission_amount) > 20000\n",
    ")\n",
    "SELECT \n",
    "    COUNT(*) AS customers_over_20k,\n",
    "    (SELECT COUNT(*) FROM customers) AS total_customers,\n",
    "    CAST(COUNT(*) AS DECIMAL) / (SELECT COUNT(*) FROM customers) * 100 AS percentage\n",
    "FROM commission_totals;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Summary of high-commission customers:\\n\", df)\n",
    "\n",
    "# 2b\n",
    "query = \"\"\"\n",
    "SELECT c.first_name, c.last_name, SUM(commission_amount) AS total_commission\n",
    "FROM customers c\n",
    "JOIN placed_bets pb ON c.customer_id = pb.customer_id\n",
    "GROUP BY c.customer_id, first_name, last_name\n",
    "HAVING SUM(commission_amount) > 20000\n",
    "ORDER BY total_commission DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"\\nTop 20 commission payers:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3bb6b2-2d33-4125-8e0b-da764595dc37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/983587097.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 luckiest bettors:\n",
      "   first_name last_name  total_bets  wins  win_percentage  total_winnings\n",
      "0  Anastasia    Powell           6     6          100.00             825\n",
      "1      Caleb  Reynolds         126   119           94.44           91475\n",
      "2      Grace      Ford          11    10           90.91           13550\n",
      "3      Henry  Anderson           9     8           88.89            3300\n",
      "4    Valerie   Wheeler           8     7           87.50             850\n",
      "5  Alexander   Sherman           7     6           85.71            4225\n",
      "6       John       Lee          13    11           84.62           14900\n",
      "7    Ezekiel  Martinez          13    11           84.62           11550\n",
      "8    Sabrina    Wilson          12    10           83.33           41700\n",
      "9    Houston    Foster           6     5           83.33           10300\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "query = \"\"\"\n",
    "WITH bet_stats AS (\n",
    "    SELECT \n",
    "        c.customer_id, first_name, last_name, COUNT(*) AS total_bets,\n",
    "        COUNT(CASE WHEN pb.result = 'win' THEN 1 END) AS wins,\n",
    "        SUM(CASE \n",
    "            WHEN pb.result = 'win' THEN pb.bet_amount\n",
    "            WHEN pb.result = 'loss' THEN -pb.bet_amount\n",
    "            WHEN pb.result = 'push' THEN 0 END) AS total_winnings\n",
    "    FROM customers c\n",
    "    JOIN placed_bets pb ON c.customer_id = pb.customer_id\n",
    "    GROUP BY c.customer_id, c.first_name, c.last_name\n",
    "    HAVING COUNT(*) >= 6\n",
    ")\n",
    "SELECT \n",
    "    first_name, last_name, total_bets, wins,\n",
    "    ROUND((CAST(wins AS DECIMAL) / total_bets * 100), 2) AS win_percentage,\n",
    "    total_winnings\n",
    "FROM bet_stats\n",
    "ORDER BY win_percentage DESC, total_winnings DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Top 10 luckiest bettors:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162ea3a7-3c56-4f0f-86d7-d717988fc35d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/2361486645.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 costliest customers for the sports book:\n",
      "    first_name last_name  total_bets  wins  net_lost_for_company\n",
      "0      Bailey    Sparks         180   100            -1206521.0\n",
      "1        Kate     Noble         148    89            -1159675.0\n",
      "2      Chanel      Pope         145    82             -829695.0\n",
      "3     Adeline    Conner         194   112             -825578.0\n",
      "4        Lara   Hoffman         119    65             -821873.0\n",
      "5        Owen  Garrison          77    48             -810180.0\n",
      "6     Matthew     Booth         250   117             -808651.5\n",
      "7     Jackson   Fischer         137    79             -775182.0\n",
      "8     Winston     Short         206   111             -766862.5\n",
      "9        Ryan      Lane          81    49             -765602.0\n",
      "10     Lennox      Bean         122    66             -756874.0\n",
      "11     Vaughn     Ortiz         232   105             -724253.0\n",
      "12      Clark    Jordan         163    85             -707735.0\n",
      "13      Tiana  Lawrence         121    81             -688153.0\n",
      "14      Logan     Riley         142    69             -686705.0\n",
      "15    Delilah      Bush         118    68             -663563.5\n",
      "16      Alexa   Mendoza         265   128             -655491.0\n",
      "17     Austin    Flores         153    73             -630503.5\n",
      "18      Lucas     Eaton         149    86             -617446.0\n",
      "19        Lia     Drake         117    62             -613745.0\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    first_name, last_name, COUNT(*) AS total_bets,\n",
    "    COUNT(CASE WHEN result = 'win' THEN 1 END) AS wins,\n",
    "    SUM(CASE \n",
    "        WHEN result = 'win' THEN -(bet_amount * 2)\n",
    "        WHEN result = 'loss' THEN bet_amount + commission_amount\n",
    "        WHEN result = 'push' THEN commission_amount END) AS net_lost_for_company\n",
    "FROM customers c\n",
    "JOIN placed_bets pb ON c.customer_id = pb.customer_id\n",
    "GROUP BY c.customer_id, first_name, last_name\n",
    "ORDER BY net_lost_for_company\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"20 costliest customers for the sports book:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f510e79c-3ffe-42fb-8bd6-154032d43117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/3296380341.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly house performance for 2023 season:\n",
      "     schedule_week  total_games  winners  losers  winner_percentage  \\\n",
      "0               1           16       12       4              75.00   \n",
      "1               2           16        7       7              43.75   \n",
      "2               3           16        7       8              43.75   \n",
      "3               4           16        7       8              43.75   \n",
      "4               5           14        8       6              57.14   \n",
      "5               6           15        6       9              40.00   \n",
      "6               7           13        3      10              23.08   \n",
      "7               8           16        5       8              31.25   \n",
      "8               9           14        6       8              42.86   \n",
      "9              10           14        8       6              57.14   \n",
      "10             11           14        8       5              57.14   \n",
      "11             12           16        9       7              56.25   \n",
      "12             13           13        9       4              69.23   \n",
      "13             14           15        7       7              46.67   \n",
      "14             15           16        5       9              31.25   \n",
      "15             16           16        7       8              43.75   \n",
      "16             17           16        8       8              50.00   \n",
      "17             18           16        8       8              50.00   \n",
      "\n",
      "    loser_percentage  \n",
      "0              25.00  \n",
      "1              43.75  \n",
      "2              50.00  \n",
      "3              50.00  \n",
      "4              42.86  \n",
      "5              60.00  \n",
      "6              76.92  \n",
      "7              50.00  \n",
      "8              57.14  \n",
      "9              42.86  \n",
      "10             35.71  \n",
      "11             43.75  \n",
      "12             30.77  \n",
      "13             46.67  \n",
      "14             56.25  \n",
      "15             50.00  \n",
      "16             50.00  \n",
      "17             50.00  \n"
     ]
    }
   ],
   "source": [
    "# 5 \n",
    "query = \"\"\"\n",
    "WITH weekly_games AS (\n",
    "    SELECT \n",
    "        schedule_week, COUNT(*) AS total_games,\n",
    "        COUNT(CASE WHEN \n",
    "            (winner_line = 'home' AND spread_favorite > 0) OR \n",
    "            (winner_line = 'away' AND spread_favorite < 0) THEN 1 END) AS winners,\n",
    "        COUNT(CASE WHEN \n",
    "            (winner_line = 'away' AND spread_favorite > 0) OR\n",
    "            (winner_line = 'home' AND spread_favorite < 0) THEN 1 END) AS losers\n",
    "    FROM games\n",
    "    WHERE schedule_season = 2023 AND schedule_playoff = false\n",
    "    GROUP BY schedule_week\n",
    ")\n",
    "SELECT \n",
    "    schedule_week, total_games, winners, losers,\n",
    "    ROUND((CAST(winners AS DECIMAL) / total_games * 100), 2) AS winner_percentage,\n",
    "    ROUND((CAST(losers AS DECIMAL) / total_games * 100), 2) AS loser_percentage\n",
    "FROM weekly_games\n",
    "ORDER BY schedule_week;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Weekly house performance for 2023 season:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93ec73d-782a-497b-b1b4-14c1a43f182d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_18178/2418816236.py:56: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-team betting analysis for 2023 season:\n",
      "                 team_name  wins  losses  beat_spread  bets_for  bets_against\n",
      "0       Arizona Cardinals     4      13            8      3058          3025\n",
      "1         Atlanta Falcons     7      10            5      3020          2917\n",
      "2        Baltimore Ravens    14       5           12      3465          3476\n",
      "3           Buffalo Bills    12       7            8      3368          3341\n",
      "4       Carolina Panthers     2      15            4      2956          2939\n",
      "5           Chicago Bears     7      10            8      3003          2889\n",
      "6      Cincinnati Bengals     9       8            8      2906          3057\n",
      "7        Cleveland Browns    11       7            9      3223          3186\n",
      "8          Dallas Cowboys    12       6           10      3195          3126\n",
      "9          Denver Broncos     8       9            6      3001          2935\n",
      "10          Detroit Lions    14       6           14      3533          3639\n",
      "11      Green Bay Packers    10       9           10      3346          3435\n",
      "12         Houston Texans    11       8           10      3430          3331\n",
      "13     Indianapolis Colts     9       8            9      3034          2884\n",
      "14   Jacksonville Jaguars     9       8            9      2996          3100\n",
      "15     Kansas City Chiefs    15       6           14      3834          3915\n",
      "16      Las Vegas Raiders     8       9           10      2923          2963\n",
      "17   Los Angeles Chargers     5      12            6      3023          2911\n",
      "18       Los Angeles Rams    10       8           11      3190          3318\n",
      "19         Miami Dolphins    11       7           10      3130          3185\n",
      "20      Minnesota Vikings     7      10            7      3018          3002\n",
      "21   New England Patriots     4      13            5      3004          2824\n",
      "22     New Orleans Saints     9       8            6      3029          2925\n",
      "23        New York Giants     6      11            8      2872          3046\n",
      "24          New York Jets     7      10            6      2964          2892\n",
      "25    Philadelphia Eagles    11       7            7      3214          3107\n",
      "26    Pittsburgh Steelers    10       8           10      3196          3233\n",
      "27    San Francisco 49ers    14       6            9      3696          3709\n",
      "28       Seattle Seahawks     9       8            8      3010          2977\n",
      "29   Tampa Bay Buccaneers    10       9           13      3272          3446\n",
      "30       Tennessee Titans     6      11            7      2950          3039\n",
      "31  Washington Commanders     4      13            6      2967          3054\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "query = \"\"\"\n",
    "WITH unique_bet_teams AS (\n",
    "    SELECT DISTINCT bet_on AS team_name, bet_on_team_id AS team_id\n",
    "    FROM placed_bets \n",
    "    WHERE bet_on_team_id IS NOT NULL\n",
    "),\n",
    "team_games AS (\n",
    "    SELECT \n",
    "        ubt.team_name, g.game_id, score_home, score_away, winner_line, spread_favorite, team_id_favorite,\n",
    "        CASE WHEN team_id_home = ubt.team_id THEN 'home'\n",
    "             ELSE 'away' END AS home_or_away\n",
    "    FROM unique_bet_teams ubt\n",
    "    JOIN games g ON ubt.team_id = g.team_id_home OR ubt.team_id = g.team_id_away\n",
    "    WHERE schedule_season = 2023\n",
    "),\n",
    "team_records AS (\n",
    "    SELECT \n",
    "        team_name,\n",
    "        COUNT(*) AS games_played,\n",
    "        COUNT(CASE WHEN \n",
    "            (home_or_away = 'home' AND score_home > score_away) OR\n",
    "            (home_or_away = 'away' AND score_away > score_home) \n",
    "            THEN 1 END) AS wins,\n",
    "        COUNT(CASE WHEN \n",
    "            (home_or_away = 'home' AND score_home < score_away) OR\n",
    "            (home_or_away = 'away' AND score_away < score_home) \n",
    "            THEN 1 END) AS losses,\n",
    "        COUNT(CASE WHEN home_or_away = winner_line THEN 1 END) AS beat_spread\n",
    "    FROM team_games\n",
    "    GROUP BY team_name\n",
    "),\n",
    "betting_counts AS (\n",
    "    SELECT \n",
    "        ubt.team_name,\n",
    "        COUNT(CASE WHEN pb.bet_on = ubt.team_name THEN 1 END) AS bets_for,\n",
    "        COUNT(CASE WHEN \n",
    "            pb.bet_on_team_id IS NOT NULL AND\n",
    "            pb.bet_on != ubt.team_name\n",
    "            THEN 1 END) AS bets_against\n",
    "    FROM unique_bet_teams ubt\n",
    "    LEFT JOIN games g ON ubt.team_id = g.team_id_home \n",
    "                     OR ubt.team_id = g.team_id_away\n",
    "    LEFT JOIN placed_bets pb ON g.game_id = pb.game_id\n",
    "    WHERE schedule_season = 2023\n",
    "    GROUP BY ubt.team_id, ubt.team_name\n",
    ")\n",
    "SELECT \n",
    "    r.team_name, wins, losses, beat_spread,\n",
    "    COALESCE(bets_for, 0) AS bets_for,\n",
    "    COALESCE(bets_against, 0) AS bets_against\n",
    "FROM team_records r\n",
    "LEFT JOIN betting_counts b ON r.team_name = b.team_name\n",
    "ORDER BY r.team_name;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Per-team betting analysis for 2023 season:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2411348a-c3d9-4f99-b951-2a39be0ffdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_26287/3403901508.py:39: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Correlation Matrix:\n",
      "                      age    income  household_size  type_local  type_online  \\\n",
      "age             1.000000 -0.003367       -0.003167    0.003520     0.012831   \n",
      "income         -0.003367  1.000000       -0.010054    0.020711    -0.011735   \n",
      "household_size -0.003167 -0.010054        1.000000   -0.017376     0.012117   \n",
      "type_local      0.003520  0.020711       -0.017376    1.000000    -0.772538   \n",
      "type_online     0.012831 -0.011735        0.012117   -0.772538     1.000000   \n",
      "type_phone     -0.023397 -0.015428        0.009761   -0.456359    -0.212437   \n",
      "years_customer  0.020605  0.005408       -0.009284    0.056665    -0.027774   \n",
      "name_length     0.006064 -0.045654       -0.047149    0.001623    -0.020042   \n",
      "\n",
      "                type_phone  years_customer  name_length  \n",
      "age              -0.023397        0.020605     0.006064  \n",
      "income           -0.015428        0.005408    -0.045654  \n",
      "household_size    0.009761       -0.009284    -0.047149  \n",
      "type_local       -0.456359        0.056665     0.001623  \n",
      "type_online      -0.212437       -0.027774    -0.020042  \n",
      "type_phone        1.000000       -0.048285     0.025588  \n",
      "years_customer   -0.048285        1.000000     0.007465  \n",
      "name_length       0.025588        0.007465     1.000000  \n",
      "\n",
      "First Model Results:\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         customer_value   R-squared:                       0.052\n",
      "Model:                            OLS   Adj. R-squared:                  0.050\n",
      "Method:                 Least Squares   F-statistic:                     27.45\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           3.27e-22\n",
      "Time:                        19:17:45   Log-Likelihood:                -25659.\n",
      "No. Observations:                2000   AIC:                         5.133e+04\n",
      "Df Residuals:                    1995   BIC:                         5.136e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const           2.201e+04   1.05e+04      2.087      0.037    1322.973    4.27e+04\n",
      "age               -8.8775    217.388     -0.041      0.967    -435.209     417.454\n",
      "income            -0.3963      0.041     -9.583      0.000      -0.477      -0.315\n",
      "household_size -4961.6613   1343.763     -3.692      0.000   -7596.988   -2326.335\n",
      "type_local      9901.6260   4173.516      2.372      0.018    1716.719    1.81e+04\n",
      "==============================================================================\n",
      "Omnibus:                     1598.683   Durbin-Watson:                   1.887\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            94189.639\n",
      "Skew:                          -3.284   Prob(JB):                         0.00\n",
      "Kurtosis:                      35.972   Cond. No.                     5.92e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.92e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Second Model Results:\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         customer_value   R-squared:                       0.074\n",
      "Model:                            OLS   Adj. R-squared:                  0.072\n",
      "Method:                 Least Squares   F-statistic:                     31.83\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           2.74e-31\n",
      "Time:                        19:17:45   Log-Likelihood:                -25636.\n",
      "No. Observations:                2000   AIC:                         5.128e+04\n",
      "Df Residuals:                    1994   BIC:                         5.132e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const           2.669e+04   1.35e+04      1.972      0.049     151.182    5.32e+04\n",
      "income            -0.3927      0.041     -9.593      0.000      -0.473      -0.312\n",
      "years_customer -7331.4011   1090.019     -6.726      0.000   -9469.097   -5193.705\n",
      "household_size -4952.5126   1330.135     -3.723      0.000   -7561.114   -2343.912\n",
      "name_length     1247.0204    952.736      1.309      0.191    -621.442    3115.483\n",
      "type_local      1.146e+04   4132.954      2.773      0.006    3354.546    1.96e+04\n",
      "==============================================================================\n",
      "Omnibus:                     1593.019   Durbin-Watson:                   1.900\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            94973.526\n",
      "Skew:                          -3.261   Prob(JB):                         0.00\n",
      "Kurtosis:                      36.123   Cond. No.                     7.66e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.66e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Regression Analysis Summary:\n",
      "--------------------------\n",
      "Correlation Analysis:\n",
      "- Collinearity Issues:\n",
      "    * High collinearity between customer type dummy variables\n",
      "- Correlation Values:\n",
      "    * type_online and type_local: -0.773\n",
      "    * type_phone and type_local: -0.456\n",
      "    * type_phone and type_online: -0.212\n",
      "    \n",
      "First Regression Model:\n",
      "- Independent variables: age, income, household_size, type_local\n",
      "- Adjusted R-squared: 0.050\n",
      "- All variables except age are significant at p<0.05 (age: p=0.967)\n",
      "\n",
      "Second Regression Model (Adjusted):\n",
      "- Independent variables: win_rate, years_customer, type_local, household_size \n",
      "- Adjusted R-squared: 0.074\n",
      "- All variables significant at p<0.05\n",
      "- Achieved higher adjusted R-squared by:\n",
      "    * Adding the engineered variables win_rate and years_customer\n",
      "    * Removed insignificant age variable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Analysis\n",
    "\n",
    "# Query to calculate customer value and create features\n",
    "query = \"\"\"\n",
    "WITH bet_values AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        SUM(bet_amount) AS total_bet,\n",
    "        SUM(commission_amount) as total_commission,\n",
    "        COUNT(*) as num_bets,\n",
    "        COUNT(CASE WHEN result = 'win' THEN 1 END) as num_wins,\n",
    "        SUM(CASE \n",
    "            WHEN result = 'win' THEN -(bet_amount * 2) + commission_amount\n",
    "            WHEN result = 'loss' THEN bet_amount + commission_amount\n",
    "            WHEN result = 'push' THEN commission_amount\n",
    "        END) AS bet_outcomes\n",
    "    FROM placed_bets\n",
    "    GROUP BY customer_id\n",
    ")\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    age,\n",
    "    income,\n",
    "    household_size, \n",
    "    customer_type,\n",
    "    customer_since,\n",
    "    mode_color,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    num_bets,\n",
    "    num_wins,\n",
    "    CASE WHEN customer_type = 'local' THEN 1 ELSE 0 END as type_local,\n",
    "    CASE WHEN customer_type = 'online' THEN 1 ELSE 0 END as type_online,\n",
    "    CASE WHEN customer_type = 'phone' THEN 1 ELSE 0 END as type_phone,\n",
    "    total_commission + bet_outcomes as customer_value\n",
    "FROM customers c\n",
    "LEFT JOIN bet_values bv ON c.customer_id = bv.customer_id;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Feature engineering\n",
    "df['name_length'] = df['first_name'].str.len() + df['last_name'].str.len()\n",
    "df['years_customer'] = 2024 - df['customer_since']\n",
    "\n",
    "# A: Initial correlation matrix with all variables\n",
    "initial_predictors = ['age', 'income', 'household_size', 'type_local', 'type_online', 'type_phone', 'years_customer', 'name_length']\n",
    "corr_matrix = df[initial_predictors].corr()\n",
    "print(\"\\nInitial Correlation Matrix:\\n\", corr_matrix)\n",
    "    \n",
    "# B: First regression\n",
    "first_predictors = ['age', 'income', 'household_size', 'type_local']\n",
    "X = df[first_predictors]\n",
    "y = df['customer_value']\n",
    "X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X).fit()\n",
    "print(\"\\nFirst Model Results:\\n\", model1.summary())\n",
    "\n",
    "# C: Second regression\n",
    "second_predictors = ['income', 'years_customer', 'household_size', 'name_length', 'type_local']\n",
    "X2 = df[second_predictors]\n",
    "y = df['customer_value']\n",
    "X2 = sm.add_constant(X2)\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "print(\"\\nSecond Model Results:\\n\", model2.summary())\n",
    "\n",
    "print(\"\"\"\n",
    "Regression Analysis Summary:\n",
    "--------------------------\n",
    "Correlation Analysis:\n",
    "- Collinearity Issues:\n",
    "   * High collinearity between customer type dummy variables\n",
    "- Correlation Values:\n",
    "   * type_online and type_local: -0.773\n",
    "   * type_phone and type_local: -0.456\n",
    "   * type_phone and type_online: -0.212\n",
    "   \n",
    "First Regression Model:\n",
    "- Independent variables: age, income, household_size, type_local\n",
    "- Adjusted R-squared: 0.050\n",
    "- All variables except age are significant at p<0.05 (age: p=0.967)\n",
    "\n",
    "Second Regression Model (Adjusted):\n",
    "- Independent variables: income, years_customer, household_size, name_length, type_local\n",
    "- Adjusted R-squared: 0.072\n",
    "- All variables except name_length are significant at p<0.05 (name_length: p=0.191)\n",
    "- Achieved higher adjusted R-squared by:\n",
    "   * Adding engineered variables years_customer and name_length\n",
    "   * Removing insignificant age variable\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f46860-7a6c-471a-8073-690cfe5cf1d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close cursors and connections\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "pymssql_cursor.close() \n",
    "pymssql_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
