{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de6ca219-3d5c-4eb0-8720-672d64e636a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "# import pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7816fe97-38ff-450a-a3f5-4aa96c82673c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Convert to integer\n",
    "def int_convert(value):\n",
    "    if pd.notna(value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Handle Null Values\n",
    "def handle_na(value):\n",
    "    if pd.notna(value):\n",
    "        return value\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Determine winner_ou\n",
    "def get_winner_ou(total_score, over_under_line):\n",
    "    if total_score > over_under_line:\n",
    "        return 'over'\n",
    "    elif total_score < over_under_line:\n",
    "        return 'under'\n",
    "    else:\n",
    "        return 'push'\n",
    "\n",
    "# Determine winner_line\n",
    "def get_winner_line(score_home, score_away, spread_favorite, team_favorite_id):\n",
    "    score_diff = score_home - score_away\n",
    "    \n",
    "    # Special handling for pick games (spread is 0)\n",
    "    if spread_favorite == 0:\n",
    "        if score_diff > 0:\n",
    "            return 'home'\n",
    "        elif score_diff < 0:\n",
    "            return 'away'\n",
    "        else:\n",
    "            return 'push'\n",
    "\n",
    "    adjusted_spread = -spread_favorite\n",
    "        \n",
    "    if score_diff > adjusted_spread:\n",
    "        return 'home'\n",
    "    elif score_diff < adjusted_spread:\n",
    "        return 'away'\n",
    "    else:\n",
    "        return 'push'\n",
    "\n",
    "# Calculate commission based on bet amount\n",
    "def calculate_commission(bet_amount):\n",
    "    \"\"\"\n",
    "    - 10% on first $1,000\n",
    "    - 8% on next $4,000\n",
    "    - 6% on remaining amount\n",
    "    \"\"\"\n",
    "    commission = 0\n",
    "    \n",
    "    # First $1,000\n",
    "    if bet_amount <= 1000:\n",
    "        commission = bet_amount * 0.10\n",
    "    else:\n",
    "        commission = 1000 * 0.10\n",
    "        remaining = bet_amount - 1000\n",
    "        \n",
    "        # Next $4,000\n",
    "        if remaining <= 4000:\n",
    "            commission += remaining * 0.08\n",
    "        else:\n",
    "            commission += 4000 * 0.08\n",
    "            remaining = remaining - 4000\n",
    "            \n",
    "            # Anything over $5,000\n",
    "            commission += remaining * 0.06\n",
    "            \n",
    "    return round(commission, 2)\n",
    "\n",
    "# Bet result\n",
    "def determine_bet_result(bet_on, winner_line, winner_ou, team_id_home, team_id_away):    \n",
    "    if bet_on == 'over':\n",
    "        if winner_ou == 'over':\n",
    "            return 'win'\n",
    "        elif winner_ou == 'under':\n",
    "            return 'loss'\n",
    "        else:\n",
    "            return 'push'\n",
    "    elif bet_on == 'under':\n",
    "        if winner_ou == 'under':\n",
    "            return 'win'\n",
    "        elif winner_ou == 'over':\n",
    "            return 'loss'\n",
    "        else:\n",
    "            return 'push'\n",
    "    elif bet_on == 'push':\n",
    "        if winner_line == 'push':\n",
    "            return 'win'\n",
    "        else:\n",
    "            return 'loss'\n",
    "    else:  # Team bet\n",
    "        cursor.execute(\"SELECT DISTINCT team_id FROM team_history WHERE name = %s;\", (bet_on,))\n",
    "        bet_team_id = cursor.fetchone()\n",
    "        if bet_team_id:\n",
    "            bet_team_id = bet_team_id[0]\n",
    "            \n",
    "            # Home or away team\n",
    "            if bet_team_id == team_id_home:\n",
    "                if winner_line == 'home':\n",
    "                    return 'win'\n",
    "                elif winner_line == 'away':\n",
    "                    return 'loss'\n",
    "                else:\n",
    "                    return 'push'\n",
    "            else:\n",
    "                if winner_line == 'away':\n",
    "                    return 'win'\n",
    "                elif winner_line == 'home':\n",
    "                    return 'loss'\n",
    "                else:\n",
    "                    return 'push'\n",
    "        else:\n",
    "            print(f\"Warning: Could not find team ID for bet on {bet_on}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3192b747-c8a0-476a-8a71-5859e05a4477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establish connections\n",
    "conn = psycopg2.connect(\n",
    "    database=\"iwdm\", \n",
    "    user='dw_chancewiese',\n",
    "    password='Spikeball2020',\n",
    "    host='database-1.czsooswggscz.us-east-2.rds.amazonaws.com',\n",
    "    port='5432'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# pymssql_conn = pymssql.connect(\n",
    "#     server='stairwaytoheaven.usu.edu',\n",
    "#     user='5330user',\n",
    "#     password='pipelinesnow',\n",
    "#     database='ironwill'\n",
    "# )\n",
    "# pymssql_cursor = pymssql_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485d2f39-d13e-4602-8a9e-e808a848c254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created games table\n",
      "Created placed_bets table\n"
     ]
    }
   ],
   "source": [
    "# Drop all tables in the correct order, considering foreign key dependencies\n",
    "try:\n",
    "    cursor.execute('''\n",
    "    DROP TABLE IF EXISTS bets;\n",
    "    DROP TABLE IF EXISTS games;\n",
    "    ''')\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "    \n",
    "# Games\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS games (\n",
    "    game_id VARCHAR(50) PRIMARY KEY,\n",
    "    schedule_date DATE NOT NULL,\n",
    "    schedule_season SMALLINT NOT NULL,\n",
    "    schedule_week SMALLINT NOT NULL,\n",
    "    schedule_playoff BOOLEAN NOT NULL,\n",
    "    playoff_type VARCHAR(20),\n",
    "    team_id_home VARCHAR(5) NOT NULL,\n",
    "    team_id_away VARCHAR(5) NOT NULL,\n",
    "    score_home SMALLINT,\n",
    "    score_away SMALLINT,\n",
    "    team_id_favorite VARCHAR(5),\n",
    "    spread_favorite DECIMAL(4,1),\n",
    "    over_under_line DECIMAL(4,1),\n",
    "    stadium_id INTEGER,\n",
    "    stadium_neutral BOOLEAN NOT NULL,\n",
    "    weather_temperature SMALLINT,\n",
    "    weather_wind_mph SMALLINT,\n",
    "    weather_humidity SMALLINT,\n",
    "    weather_detail VARCHAR(100),\n",
    "    winner_ou VARCHAR(10),\n",
    "    winner_line VARCHAR(10),\n",
    "    FOREIGN KEY (team_id_home) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_away) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_favorite) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (stadium_id) \n",
    "        REFERENCES stadiums (stadium_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created games table\")\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS placed_bets (\n",
    "    bet_id INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER NOT NULL,\n",
    "    game_id VARCHAR(50) NOT NULL,\n",
    "    bet_amount INTEGER NOT NULL,\n",
    "    bet_on VARCHAR(50) NOT NULL,\n",
    "    result VARCHAR(10),\n",
    "    commission_amount DECIMAL(10,2),\n",
    "    FOREIGN KEY (customer_id) \n",
    "        REFERENCES customers (customer_id),\n",
    "    FOREIGN KEY (game_id) \n",
    "        REFERENCES games (game_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created placed_bets table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60927470-6198-4929-b7f9-1cc19ac3303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all tables in the correct order, considering foreign key dependencies\n",
    "try:\n",
    "    cursor.execute('''\n",
    "    DROP TABLE IF EXISTS placed_bets;\n",
    "    DROP TABLE IF EXISTS games;\n",
    "    DROP TABLE IF EXISTS stadiums;\n",
    "    DROP TABLE IF EXISTS weather_stations;\n",
    "    DROP TABLE IF EXISTS teams;\n",
    "    DROP TABLE IF EXISTS team_history;\n",
    "    DROP TABLE IF EXISTS current_teams;\n",
    "    DROP TABLE IF EXISTS customers;\n",
    "    ''')\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71776ef-598e-4565-b31d-a763e01353e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customers table\n",
      "Created current teams table\n",
      "Created team history table\n",
      "Created weather stations table\n",
      "Created stadiums table\n",
      "Created games table\n",
      "Created bets table\n"
     ]
    }
   ],
   "source": [
    "# Create Tables\n",
    "# Customers\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS customers (\n",
    "    customer_id INTEGER PRIMARY KEY,\n",
    "    first_name VARCHAR(50) NOT NULL,\n",
    "    last_name VARCHAR(50) NOT NULL,\n",
    "    age INTEGER NOT NULL,\n",
    "    customer_type VARCHAR(10) NOT NULL,\n",
    "    customer_since INTEGER NOT NULL,\n",
    "    income INTEGER NOT NULL,\n",
    "    household_size INTEGER NOT NULL,\n",
    "    mode_color VARCHAR(10) NOT NULL\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created customers table\")\n",
    "\n",
    "# Current Teams\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS current_teams (\n",
    "    team_id VARCHAR(5) PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    name_short VARCHAR(50) NOT NULL,\n",
    "    team_id_pfr VARCHAR(5) NOT NULL,\n",
    "    conference VARCHAR(5),\n",
    "    division VARCHAR(20)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created current teams table\")\n",
    "\n",
    "# Team History\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS team_history (\n",
    "    team_history_id SERIAL PRIMARY KEY,\n",
    "    team_id VARCHAR(5) NOT NULL,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    name_short VARCHAR(50) NOT NULL,\n",
    "    team_id_pfr VARCHAR(5) NOT NULL,\n",
    "    conference VARCHAR(5),\n",
    "    division VARCHAR(20),\n",
    "    FOREIGN KEY (team_id) REFERENCES current_teams (team_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created team history table\")\n",
    "\n",
    "# Weather Stations\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS weather_stations (\n",
    "    weather_station_id CHAR(11) PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    state CHAR(2),\n",
    "    country CHAR(2),\n",
    "    latitude DECIMAL(8,5) NOT NULL,\n",
    "    longitude DECIMAL(8,5) NOT NULL,\n",
    "    elevation DECIMAL(5,1) NOT NULL\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created weather stations table\")\n",
    "\n",
    "# Stadiums\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS stadiums (\n",
    "    stadium_id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    stadium_open SMALLINT,\n",
    "    stadium_close INTEGER,\n",
    "    stadium_type VARCHAR(20),\n",
    "    street_address VARCHAR(100),\n",
    "    city VARCHAR(50),\n",
    "    state CHAR(2),\n",
    "    postal_code VARCHAR(10),\n",
    "    country CHAR(2),\n",
    "    weather_station_id CHAR(11),\n",
    "    stadium_weather_station_code INTEGER,\n",
    "    stadium_weather_type VARCHAR(20),\n",
    "    surface VARCHAR(50),\n",
    "    FOREIGN KEY (weather_station_id) \n",
    "        REFERENCES weather_stations (weather_station_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created stadiums table\")\n",
    "\n",
    "# Games\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS games (\n",
    "    game_id VARCHAR(50) PRIMARY KEY,\n",
    "    schedule_date DATE NOT NULL,\n",
    "    schedule_season SMALLINT NOT NULL,\n",
    "    schedule_week SMALLINT NOT NULL,\n",
    "    schedule_playoff BOOLEAN NOT NULL,\n",
    "    playoff_type VARCHAR(20),\n",
    "    team_id_home VARCHAR(5) NOT NULL,\n",
    "    team_id_away VARCHAR(5) NOT NULL,\n",
    "    score_home SMALLINT,\n",
    "    score_away SMALLINT,\n",
    "    team_id_favorite VARCHAR(5),\n",
    "    spread_favorite DECIMAL(4,1),\n",
    "    over_under_line DECIMAL(4,1),\n",
    "    stadium_id INTEGER,\n",
    "    stadium_neutral BOOLEAN NOT NULL,\n",
    "    weather_temperature SMALLINT,\n",
    "    weather_wind_mph SMALLINT,\n",
    "    weather_humidity SMALLINT,\n",
    "    weather_detail VARCHAR(100),\n",
    "    winner_ou VARCHAR(10),\n",
    "    winner_line VARCHAR(10),\n",
    "    FOREIGN KEY (team_id_home) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_away) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (team_id_favorite) \n",
    "        REFERENCES current_teams (team_id),\n",
    "    FOREIGN KEY (stadium_id) \n",
    "        REFERENCES stadiums (stadium_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created games table\")\n",
    "\n",
    "# Bets\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS placed_bets (\n",
    "    bet_id INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER NOT NULL,\n",
    "    game_id VARCHAR(50) NOT NULL,\n",
    "    bet_amount INTEGER NOT NULL,\n",
    "    bet_on VARCHAR(50) NOT NULL,\n",
    "    result VARCHAR(10),\n",
    "    commission_amount DECIMAL(10,2),\n",
    "    FOREIGN KEY (customer_id) \n",
    "        REFERENCES customers (customer_id),\n",
    "    FOREIGN KEY (game_id) \n",
    "        REFERENCES games (game_id)\n",
    "    );''')\n",
    "conn.commit()\n",
    "print(\"Created placed_bets table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc9ea31-1b36-47d2-82b6-7a4b1d33ec10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\2151444998.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_weather_stations = pd.read_sql(\"SELECT weather_station_id FROM weather_stations;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted station USW00094823: PITTSBURGH ASOS\n",
      "Inserted station US1MOJC0028: KANSAS CITY 5.1 SE\n",
      "Inserted station USC00410337: ARLINGTON SIX FLAGS\n",
      "Inserted station USW00013881: CHARLOTTE DOUGLAS AIRPORT\n",
      "Inserted station US1NYER0093: BUFFALO 1.5 W\n",
      "Inserted station USC00238791: WEBSTER GROVES\n",
      "Inserted station USW00023234: SAN FRANCISCO INTERNATIONAL AIRPORT\n",
      "Inserted station US1WAKG0038: SEATTLE 3.5 NW\n",
      "Inserted station USW00003871: CINCINNATI WEATHER SERVICE OFFICE CITY\n",
      "Inserted station USW00014820: CLEVELAND HOPKINS INTERNATIONAL AIRPORT\n",
      "Inserted station USW00023062: DENVER STAPLETON\n",
      "Inserted station USW00093837: JACKSONVILLE NAS\n",
      "Inserted station USC00186350: NATIONAL ARBORETUM DC\n",
      "Inserted station USC00190860: BROCKTON\n",
      "Inserted station USW00014734: NEWARK LIBERTY INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012839: MIAMI INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012842: TAMPA INTERNATIONAL AIRPORT\n",
      "Inserted station USW00014898: GREEN BAY AUSTIN STRAUBEL INTERNATIONAL AIRPORT\n",
      "Inserted station USW00013739: PHILADELPHIA INTERNATIONAL AIRPORT\n",
      "Inserted station USW00023174: LOS ANGELES INTERNATIONAL AIRPORT\n",
      "Inserted station USW00013897: NASHVILLE INTERNATIONAL AIRPORT\n",
      "Inserted station US1INMR0076: INDIANAPOLIS 6.8 NNE\n",
      "Inserted station USW00093721: BALTIMORE WASHINGTON INTERNATIONAL AIRPORT\n",
      "Inserted station USW00014922: MINNEAPOLIS ST PAUL INTERNATIONAL AIRPORT\n",
      "Inserted station USW00012918: HOUSTON WILLIAM P HOBBY AIRPORT\n",
      "Inserted station USW00023230: OAKLAND METROPOLITAN INTERNATIONAL AIRPORT\n",
      "Inserted station USW00093107: SAN DIEGO MIRAMAR NAS\n",
      "Inserted station USC00111550: CHICAGO NORTHERLY ISLAND\n",
      "Inserted station US1AZMR0451: TEMPE 3.6 NNW\n",
      "Number of records: 29\n",
      "                                                                name state  \\\n",
      "weather_station_id                                                          \n",
      "USW00094823                                         PITTSBURGH ASOS    PA   \n",
      "US1MOJC0028                                      KANSAS CITY 5.1 SE    MO   \n",
      "USC00410337                                     ARLINGTON SIX FLAGS    TX   \n",
      "USW00013881                               CHARLOTTE DOUGLAS AIRPORT    NC   \n",
      "US1NYER0093                                           BUFFALO 1.5 W    NY   \n",
      "USC00238791                                          WEBSTER GROVES    MO   \n",
      "USW00023234                     SAN FRANCISCO INTERNATIONAL AIRPORT    CA   \n",
      "US1WAKG0038                                          SEATTLE 3.5 NW    WA   \n",
      "USW00003871                  CINCINNATI WEATHER SERVICE OFFICE CITY    OH   \n",
      "USW00014820                 CLEVELAND HOPKINS INTERNATIONAL AIRPORT    OH   \n",
      "USW00023062                                        DENVER STAPLETON    CO   \n",
      "USW00093837                                        JACKSONVILLE NAS    FL   \n",
      "USC00186350                                   NATIONAL ARBORETUM DC    MD   \n",
      "USC00190860                                                BROCKTON    MA   \n",
      "USW00014734                    NEWARK LIBERTY INTERNATIONAL AIRPORT    NJ   \n",
      "USW00012839                             MIAMI INTERNATIONAL AIRPORT    FL   \n",
      "USW00012842                             TAMPA INTERNATIONAL AIRPORT    FL   \n",
      "USW00014898         GREEN BAY AUSTIN STRAUBEL INTERNATIONAL AIRPORT    WI   \n",
      "USW00013739                      PHILADELPHIA INTERNATIONAL AIRPORT    PA   \n",
      "USW00023174                       LOS ANGELES INTERNATIONAL AIRPORT    CA   \n",
      "USW00013897                         NASHVILLE INTERNATIONAL AIRPORT    TN   \n",
      "US1INMR0076                                    INDIANAPOLIS 6.8 NNE    IN   \n",
      "USW00093721              BALTIMORE WASHINGTON INTERNATIONAL AIRPORT    MD   \n",
      "USW00014922               MINNEAPOLIS ST PAUL INTERNATIONAL AIRPORT    MN   \n",
      "USW00012918                         HOUSTON WILLIAM P HOBBY AIRPORT    TX   \n",
      "USW00023230              OAKLAND METROPOLITAN INTERNATIONAL AIRPORT    CA   \n",
      "USW00093107                                   SAN DIEGO MIRAMAR NAS    CA   \n",
      "USC00111550                                CHICAGO NORTHERLY ISLAND    IL   \n",
      "US1AZMR0451                                           TEMPE 3.6 NNW    AZ   \n",
      "\n",
      "                   country  latitude  longitude  elevation  \n",
      "weather_station_id                                          \n",
      "USW00094823             US  40.48460  -80.21440      366.7  \n",
      "US1MOJC0028             US  39.06920  -94.48710      264.9  \n",
      "USC00410337             US  32.75720  -97.07360      163.4  \n",
      "USW00013881             US  35.22360  -80.95520      221.9  \n",
      "US1NYER0093             US  42.88900  -78.89010      178.0  \n",
      "USC00238791             US  38.56667  -90.36667      189.0  \n",
      "USW00023234             US  37.61970 -122.36470        2.4  \n",
      "US1WAKG0038             US  47.65230 -122.40950       93.0  \n",
      "USW00003871             US  39.10000  -84.51667      193.9  \n",
      "USW00014820             US  41.40570  -81.85200      238.0  \n",
      "USW00023062             US  39.76330 -104.86940     1611.2  \n",
      "USW00093837             US  30.23333  -81.66667        6.1  \n",
      "USC00186350             US  38.91330  -76.97000       15.2  \n",
      "USC00190860             US  42.04790  -71.00500       24.4  \n",
      "USW00014734             US  40.68250  -74.16940        2.1  \n",
      "USW00012839             US  25.79050  -80.31630        8.8  \n",
      "USW00012842             US  27.96194  -82.54030        5.8  \n",
      "USW00014898             US  44.47940  -88.13660      209.4  \n",
      "USW00013739             US  39.87327  -75.22678        3.0  \n",
      "USW00023174             US  33.93800 -118.38880       29.6  \n",
      "USW00013897             US  36.11889  -86.68917      182.9  \n",
      "US1INMR0076             US  39.87210  -86.12010      227.1  \n",
      "USW00093721             US  39.17330  -76.68400       47.5  \n",
      "USW00014922             US  44.88310  -93.22890      265.8  \n",
      "USW00012918             US  29.63806  -95.28194       13.4  \n",
      "USW00023230             US  37.72139 -122.22083        1.8  \n",
      "USW00093107             US  32.86667 -117.13333      145.4  \n",
      "USC00111550             US  41.85580  -87.60940      177.7  \n",
      "US1AZMR0451             US  33.45520 -111.93160      375.2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\2151444998.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM weather_stations\", conn, index_col='weather_station_id')\n"
     ]
    }
   ],
   "source": [
    "# Ingest Weather Stations\n",
    "\n",
    "stadiums_df = pd.read_csv('nfl_stadiums.csv')\n",
    "weather_stations_df = stadiums_df[['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION']]\n",
    "df = weather_stations_df.dropna()\n",
    "\n",
    "# Get current stations and convert to list\n",
    "current_weather_stations = pd.read_sql(\"SELECT weather_station_id FROM weather_stations;\", conn)\n",
    "cws = current_weather_stations['weather_station_id'].tolist()\n",
    "\n",
    "for x in df.index:\n",
    "    weather_station_id = df['STATION'].loc[x]\n",
    "    \n",
    "    # Only proceed if station is new\n",
    "    if weather_station_id not in cws:\n",
    "        cws.append(weather_station_id) # Make sure a station isn't inserted twice\n",
    "        name = df['NAME'].loc[x]\n",
    "        latitude = df['LATITUDE'].loc[x]\n",
    "        longitude = df['LONGITUDE'].loc[x]\n",
    "        elevation = df['ELEVATION'].loc[x]\n",
    "\n",
    "        # Get state and country codes\n",
    "        name, state_country = name.split(', ')\n",
    "        state, country = state_country.split(' ')\n",
    "\n",
    "        cursor.execute('''\n",
    "            INSERT INTO weather_stations (weather_station_id, name, state, country, latitude, longitude, elevation)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (weather_station_id, name, state, country, latitude, longitude, elevation))\n",
    "        print(f\"Inserted station {weather_station_id}: {name}\")\n",
    "        \n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "df = pd.read_sql(\"SELECT * FROM weather_stations\", conn, index_col='weather_station_id')\n",
    "print(f\"Number of records: {len(cws)}\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5dce61e-ad0c-4ee2-8a4a-7a9f071bb76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3946041491.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_stadiums = pd.read_sql(\"SELECT name FROM stadiums;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted stadium: Acrisure Stadium\n",
      "Inserted stadium: Alamo Dome\n",
      "Inserted stadium: Allegiant Stadium\n",
      "Inserted stadium: Allianz Arena\n",
      "Inserted stadium: Alltel Stadium\n",
      "Inserted stadium: Alumni Stadium\n",
      "Inserted stadium: Anaheim Stadium\n",
      "Inserted stadium: Arrowhead Stadium\n",
      "Inserted stadium: AT&T Stadium\n",
      "Inserted stadium: Atlanta-Fulton County Stadium\n",
      "Inserted stadium: Balboa Stadium\n",
      "Inserted stadium: Bank of America Stadium\n",
      "Inserted stadium: Bills Stadium\n",
      "Inserted stadium: Busch Memorial Stadium\n",
      "Inserted stadium: Caesars Superdome\n",
      "Inserted stadium: Candlestick Park\n",
      "Inserted stadium: CenturyLink Field\n",
      "Inserted stadium: Cinergy Field\n",
      "Inserted stadium: Cleveland Municipal Stadium\n",
      "Inserted stadium: Cotton Bowl\n",
      "Inserted stadium: Cowboys Stadium\n",
      "Inserted stadium: Dolphin Stadium\n",
      "Inserted stadium: Edward Jones Dome\n",
      "Inserted stadium: Empower Field at Mile High\n",
      "Inserted stadium: Estadio Azteca\n",
      "Inserted stadium: EverBank Field\n",
      "Inserted stadium: FedEx Field\n",
      "Inserted stadium: Fenway Park\n",
      "Inserted stadium: FirstEnergy Stadium\n",
      "Inserted stadium: Ford Field\n",
      "Inserted stadium: Foxboro Stadium\n",
      "Inserted stadium: Franklin Field\n",
      "Inserted stadium: GEHA Field at Arrowhead Stadium\n",
      "Inserted stadium: Georgia Dome\n",
      "Inserted stadium: Giants Stadium\n",
      "Inserted stadium: Gillette Stadium\n",
      "Inserted stadium: Hard Rock Stadium\n",
      "Inserted stadium: Harvard Stadium\n",
      "Inserted stadium: Heinz Field\n",
      "Inserted stadium: Highmark Stadium\n",
      "Inserted stadium: Houlihan's Stadium\n",
      "Inserted stadium: Houston Astrodome\n",
      "Inserted stadium: Hubert H. Humphrey Metrodome\n",
      "Inserted stadium: Husky Stadium\n",
      "Inserted stadium: Jack Murphy Stadium\n",
      "Inserted stadium: Joe Robbie Stadium\n",
      "Inserted stadium: Kansas City Municipal Stadium\n",
      "Inserted stadium: Kezar Stadium\n",
      "Inserted stadium: Lambeau Field\n",
      "Inserted stadium: Legion Field\n",
      "Inserted stadium: Levi's Stadium\n",
      "Inserted stadium: Liberty Bowl Memorial Stadium\n",
      "Inserted stadium: Lincoln Financial Field\n",
      "Inserted stadium: Los Angeles Memorial Coliseum\n",
      "Inserted stadium: Louisiana Superdome\n",
      "Inserted stadium: LP Stadium\n",
      "Inserted stadium: Lucas Oil Stadium\n",
      "Inserted stadium: Lumen Field\n",
      "Inserted stadium: M&T Bank Stadium\n",
      "Inserted stadium: Mall of America Field\n",
      "Inserted stadium: Memorial Stadium (Baltimore)\n",
      "Inserted stadium: Memorial Stadium (Champaign)\n",
      "Inserted stadium: Memorial Stadium (Clemson)\n",
      "Inserted stadium: Mercedes-Benz Stadium\n",
      "Inserted stadium: Mercedes-Benz Superdome\n",
      "Inserted stadium: MetLife Stadium\n",
      "Inserted stadium: Metropolitan Stadium\n",
      "Inserted stadium: Mile High Stadium\n",
      "Inserted stadium: New Era Field\n",
      "Inserted stadium: Nippert Stadium\n",
      "Inserted stadium: Nissan Stadium\n",
      "Inserted stadium: NRG Stadium\n",
      "Inserted stadium: Oakland Coliseum\n",
      "Inserted stadium: Orange Bowl\n",
      "Inserted stadium: Paul Brown Stadium\n",
      "Inserted stadium: Paycor Stadium\n",
      "Inserted stadium: Pitt Stadium\n",
      "Inserted stadium: Pontiac Silverdome\n",
      "Inserted stadium: Pro Player Stadium\n",
      "Inserted stadium: Qualcomm Stadium\n",
      "Inserted stadium: Ralph Wilson Stadium\n",
      "Inserted stadium: Raymond James Stadium\n",
      "Inserted stadium: RCA Dome\n",
      "Inserted stadium: Reliant Stadium\n",
      "Inserted stadium: RFK Memorial Stadium\n",
      "Inserted stadium: Rice Stadium\n",
      "Inserted stadium: Rogers Centre\n",
      "Inserted stadium: Rose Bowl\n",
      "Inserted stadium: Seattle Kingdome\n",
      "Inserted stadium: Shea Stadium\n",
      "Inserted stadium: SoFi Stadium\n",
      "Inserted stadium: Soldier Field\n",
      "Inserted stadium: Sports Authority Field at Mile High\n",
      "Inserted stadium: Stanford Stadium\n",
      "Inserted stadium: State Farm Stadium\n",
      "Inserted stadium: StubHub Center\n",
      "Inserted stadium: Sun Devil Stadium\n",
      "Inserted stadium: Sun Life Stadium\n",
      "Inserted stadium: Tampa Stadium\n",
      "Inserted stadium: TCF Bank Stadium\n",
      "Inserted stadium: Texas Stadium\n",
      "Inserted stadium: Three Rivers Stadium\n",
      "Inserted stadium: TIAA Bank Field\n",
      "Inserted stadium: Tiger Stadium\n",
      "Inserted stadium: Tiger Stadium (LSU)\n",
      "Inserted stadium: Tottenham Hotspur Stadium\n",
      "Inserted stadium: Tottenham Stadium\n",
      "Inserted stadium: Tulane Stadium\n",
      "Inserted stadium: Twickenham Stadium\n",
      "Inserted stadium: U.S. Bank Stadium\n",
      "Inserted stadium: University of Phoenix Stadium\n",
      "Inserted stadium: Vanderbilt Stadium\n",
      "Inserted stadium: Veterans Stadium\n",
      "Inserted stadium: War Memorial Stadium\n",
      "Inserted stadium: Wembley Stadium\n",
      "Inserted stadium: Wrigley Field\n",
      "Inserted stadium: Yale Bowl\n",
      "Inserted stadium: Yankee Stadium\n",
      "Number of records: 118\n",
      "                             name  stadium_open  stadium_close stadium_type  \\\n",
      "stadium_id                                                                   \n",
      "1               Acrisure Stadium        2001.0            NaN      outdoor   \n",
      "2                     Alamo Dome           NaN            NaN       indoor   \n",
      "3              Allegiant Stadium        2020.0            NaN       indoor   \n",
      "4                  Allianz Arena           NaN            NaN      outdoor   \n",
      "5                 Alltel Stadium           NaN            NaN         None   \n",
      "...                          ...           ...            ...          ...   \n",
      "114         War Memorial Stadium        1960.0         1972.0      outdoor   \n",
      "115              Wembley Stadium        2007.0            NaN      outdoor   \n",
      "116                Wrigley Field        1920.0         1970.0      outdoor   \n",
      "117                    Yale Bowl           NaN            NaN      outdoor   \n",
      "118               Yankee Stadium           NaN            NaN      outdoor   \n",
      "\n",
      "                      street_address          city state postal_code country  \\\n",
      "stadium_id                                                                     \n",
      "1                 100 Art Rooney Ave    Pittsburgh    PA       15212      US   \n",
      "2                     100 Montana St   San Antonio    TX       78203      US   \n",
      "3                               None      Paradise    NV        None      US   \n",
      "4                               None        Munich  None        None      DE   \n",
      "5                               None  Jacksonville    FL        None      US   \n",
      "...                              ...           ...   ...         ...     ...   \n",
      "114                 285 Dodge Street       Buffalo    NY       14208      US   \n",
      "115                          Wembley        London  None     HA9 0WS      UK   \n",
      "116         1060 West Addison Street       Chicago    IL       60613      US   \n",
      "117                    276 Derby Ave     New Haven    CT       06516      US   \n",
      "118                             None         Bronx    NY        None      US   \n",
      "\n",
      "           weather_station_id  stadium_weather_station_code  \\\n",
      "stadium_id                                                    \n",
      "1                 USW00094823                       15212.0   \n",
      "2                        None                       78203.0   \n",
      "3                        None                           NaN   \n",
      "4                        None                           NaN   \n",
      "5                        None                           NaN   \n",
      "...                       ...                           ...   \n",
      "114                      None                       14208.0   \n",
      "115                      None                           NaN   \n",
      "116                      None                       60613.0   \n",
      "117                      None                        6516.0   \n",
      "118                      None                           NaN   \n",
      "\n",
      "           stadium_weather_type surface  \n",
      "stadium_id                               \n",
      "1                          cold   Grass  \n",
      "2                          dome    Turf  \n",
      "3                          dome   Grass  \n",
      "4                      moderate   Grass  \n",
      "5                          None    None  \n",
      "...                         ...     ...  \n",
      "114                        cold    None  \n",
      "115                    moderate    None  \n",
      "116                        cold    None  \n",
      "117                        cold   Grass  \n",
      "118                        cold    None  \n",
      "\n",
      "[118 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\3946041491.py:108: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM stadiums\", conn, index_col='stadium_id')\n"
     ]
    }
   ],
   "source": [
    "# Ingest Stadiums\n",
    "\n",
    "df = pd.read_csv('nfl_stadiums.csv')\n",
    "\n",
    "# Get current stadiums and convert to list\n",
    "current_stadiums = pd.read_sql(\"SELECT name FROM stadiums;\", conn)\n",
    "cs = current_stadiums['name'].tolist()\n",
    "\n",
    "for x in df.index:\n",
    "    name = df['stadium_name'].loc[x]\n",
    "    \n",
    "    # Only proceed if stadium is new\n",
    "    if name not in cs:\n",
    "        cs.append(name)  # Make sure a stadium isn't inserted twice\n",
    "        location = df['stadium_location'].loc[x]\n",
    "        stadium_open = df['stadium_open'].loc[x]\n",
    "        stadium_close = df['stadium_close'].loc[x]\n",
    "        stadium_type = df['stadium_type'].loc[x]\n",
    "        address = df['stadium_address'].loc[x]\n",
    "        stadium_weather_station_code = df['stadium_weather_station_code'].loc[x]\n",
    "        weather_station_id = df['STATION'].loc[x]\n",
    "        stadium_weather_type = df['stadium_weather_type'].loc[x]\n",
    "        surface = df['stadium_surface'].loc[x]\n",
    "        street_address = city = state = postal_code = country = None\n",
    "\n",
    "        ### cleaning\n",
    "        ## address --> street_address, city, state, zip, country\n",
    "        # Get city/state/country from location\n",
    "        if pd.notna(location):\n",
    "            if 'UK' in location:\n",
    "                city, country = location.split(', ')\n",
    "            elif 'MX' in str(stadium_weather_station_code):\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'MX'\n",
    "            elif 'Canada' in location:\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'CA'\n",
    "            elif 'Germany' in location:\n",
    "                city = location.split(', ')[0]\n",
    "                country = 'DE'\n",
    "            elif ',' in location:  # US locations\n",
    "                city, state = location.split(', ')\n",
    "                country = 'US'\n",
    "        # Parse address if it exists\n",
    "        if pd.notna(address):\n",
    "            if country == 'UK':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                postal_code = parts[1].replace('London', '').strip()\n",
    "            elif country == 'MX': # no clue how to handle this one\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "            elif country == 'CA':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                state = parts[2].split(' ')[0]\n",
    "                postal_code = parts[2].split(' ')[1] + ' ' + parts[2].split(' ')[2]\n",
    "            elif country == 'US':\n",
    "                parts = address.split(', ')\n",
    "                street_address = parts[0]\n",
    "                postal_code = parts[-1].split(' ')[-1]\n",
    "        \n",
    "        \n",
    "        ## stadium_open\n",
    "        stadium_open = int_convert(stadium_open)\n",
    "        \n",
    "        \n",
    "        ## stadium_close\n",
    "        stadium_close = int_convert(stadium_close)\n",
    "        \n",
    "        \n",
    "        ## stadium_weather_station_code\n",
    "        stadium_weather_station_code = int_convert(stadium_weather_station_code)\n",
    "                \n",
    "                \n",
    "        ## surface\n",
    "        if pd.notna(surface):  # Check if surface exists before lowercase\n",
    "            if 'grass' in surface.lower():\n",
    "                surface = 'Grass'\n",
    "            elif 'turf' in surface.lower():\n",
    "                surface = 'Turf'\n",
    "        else:\n",
    "            surface = None\n",
    "            \n",
    "        \n",
    "        ## weather_station_id\n",
    "        weather_station_id = handle_na(weather_station_id)\n",
    "        \n",
    "        \n",
    "        ## stadium_type\n",
    "        stadium_type = handle_na(stadium_type)\n",
    "            \n",
    "            \n",
    "        ## stadium_weather_type\n",
    "        stadium_weather_type = handle_na(stadium_weather_type)\n",
    "          \n",
    "            \n",
    "        ### Ingest\n",
    "        cursor.execute('''\n",
    "            INSERT INTO stadiums (name, stadium_open, stadium_close, stadium_type, street_address, city, state, postal_code, country, weather_station_id, stadium_weather_station_code, stadium_weather_type, surface)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (name, stadium_open, stadium_close, stadium_type, street_address, city, state, postal_code, country, weather_station_id, stadium_weather_station_code, stadium_weather_type, surface))\n",
    "        print(f\"Inserted stadium: {name}\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "df = pd.read_sql(\"SELECT * FROM stadiums\", conn, index_col='stadium_id')\n",
    "print(f\"Number of records: {len(cs)}\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4372267-0032-4676-9ee4-606689ce5f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted pre-2002 record for team: Arizona Cardinals\n",
      "Inserted pre-2002 record for team: Atlanta Falcons\n",
      "Inserted pre-2002 record for team: Baltimore Colts\n",
      "Inserted pre-2002 record for team: Baltimore Ravens\n",
      "Inserted pre-2002 record for team: Boston Patriots\n",
      "Inserted pre-2002 record for team: Buffalo Bills\n",
      "Inserted pre-2002 record for team: Carolina Panthers\n",
      "Inserted pre-2002 record for team: Chicago Bears\n",
      "Inserted pre-2002 record for team: Cincinnati Bengals\n",
      "Inserted pre-2002 record for team: Cleveland Browns\n",
      "Inserted pre-2002 record for team: Dallas Cowboys\n",
      "Inserted pre-2002 record for team: Denver Broncos\n",
      "Inserted pre-2002 record for team: Detroit Lions\n",
      "Inserted pre-2002 record for team: Green Bay Packers\n",
      "Inserted pre-2002 record for team: Houston Oilers\n",
      "Inserted pre-2002 record for team: Houston Texans\n",
      "Inserted pre-2002 record for team: Jacksonville Jaguars\n",
      "Inserted pre-2002 record for team: Kansas City Chiefs\n",
      "Inserted pre-2002 record for team: Las Vegas Raiders\n",
      "Inserted pre-2002 record for team: Los Angeles Chargers\n",
      "Inserted pre-2002 record for team: Los Angeles Rams\n",
      "Inserted pre-2002 record for team: Miami Dolphins\n",
      "Inserted pre-2002 record for team: Minnesota Vikings\n",
      "Inserted pre-2002 record for team: New Orleans Saints\n",
      "Inserted pre-2002 record for team: New York Giants\n",
      "Inserted pre-2002 record for team: New York Jets\n",
      "Inserted pre-2002 record for team: Philadelphia Eagles\n",
      "Inserted pre-2002 record for team: Pittsburgh Steelers\n",
      "Inserted pre-2002 record for team: San Francisco 49ers\n",
      "Inserted pre-2002 record for team: Seattle Seahawks\n",
      "Inserted pre-2002 record for team: Tampa Bay Buccaneers\n",
      "Inserted pre-2002 record for team: Washington Commanders\n",
      "Updated record for team: Atlanta Falcons\n",
      "Updated record for team: Baltimore Colts\n",
      "Updated record for team: Baltimore Ravens\n",
      "Updated record for team: Carolina Panthers\n",
      "Updated record for team: Chicago Bears\n",
      "Updated record for team: Cincinnati Bengals\n",
      "Updated record for team: Cleveland Browns\n",
      "Updated record for team: Detroit Lions\n",
      "Updated record for team: Green Bay Packers\n",
      "Updated record for team: Houston Oilers\n",
      "Updated record for team: Houston Texans\n",
      "Updated record for team: Indianapolis Colts\n",
      "Updated record for team: Jacksonville Jaguars\n",
      "Updated record for team: Las Vegas Raiders\n",
      "Updated record for team: Los Angeles Raiders\n",
      "Updated record for team: Minnesota Vikings\n",
      "Updated record for team: New England Patriots\n",
      "Updated record for team: New Orleans Saints\n",
      "Updated record for team: Oakland Raiders\n",
      "Updated record for team: Phoenix Cardinals\n",
      "Updated record for team: Pittsburgh Steelers\n",
      "Updated record for team: San Diego Chargers\n",
      "Updated record for team: Seattle Seahawks\n",
      "Updated record for team: St. Louis Cardinals\n",
      "Updated record for team: St. Louis Rams\n",
      "Updated record for team: Tampa Bay Buccaneers\n",
      "Updated record for team: Tennessee Oilers\n",
      "Updated record for team: Tennessee Titans\n",
      "Updated record for team: Washington Football Team\n",
      "Updated record for team: Washington Redskins\n",
      "\n",
      "Current Teams table:\n",
      "Number of current teams: 32\n",
      "    team_id                  name  name_short team_id_pfr conference   division\n",
      "0      BUF         Buffalo Bills       Bills         BUF        AFC   AFC East\n",
      "1      DAL        Dallas Cowboys     Cowboys         DAL        NFC   NFC East\n",
      "2      DEN        Denver Broncos     Broncos         DEN        AFC   AFC West\n",
      "3       KC    Kansas City Chiefs      Chiefs         KAN        AFC   AFC West\n",
      "4      MIA        Miami Dolphins    Dolphins         MIA        AFC   AFC East\n",
      "5      NYG       New York Giants      Giants         NYG        NFC   NFC East\n",
      "6      NYJ         New York Jets        Jets         NYJ        NFC   AFC East\n",
      "7      PHI   Philadelphia Eagles      Eagles         PHI        NFC   NFC East\n",
      "8       SF   San Francisco 49ers       49ers         SFO        NFC   NFC West\n",
      "9      ATL       Atlanta Falcons     Falcons         ATL        NFC  NFC South\n",
      "10     BAL      Baltimore Ravens      Ravens         RAV        AFC  AFC North\n",
      "11     CAR     Carolina Panthers    Panthers         CAR        NFC  NFC South\n",
      "12     CHI         Chicago Bears       Bears         CHI        NFC  NFC North\n",
      "13     CIN    Cincinnati Bengals     Bengals         CIN        AFC  AFC North\n",
      "14     CLE      Cleveland Browns      Browns         CLE        AFC  AFC North\n",
      "15     DET         Detroit Lions       Lions         DET        NFC  NFC North\n",
      "16      GB     Green Bay Packers     Packers         GNB        NFC  NFC North\n",
      "17     HOU        Houston Texans      Texans         HTX        AFC  AFC South\n",
      "18     IND    Indianapolis Colts       Colts         CLT        AFC  AFC South\n",
      "19     JAX  Jacksonville Jaguars     Jaguars         JAX        AFC  AFC South\n",
      "20     MIN     Minnesota Vikings     Vikings         MIN        NFC  NFC North\n",
      "21      NE  New England Patriots    Patriots         NWE        AFC   AFC East\n",
      "22      NO    New Orleans Saints      Saints         NOR        NFC  NFC South\n",
      "23     LVR       Oakland Raiders     Raiders         RAI        AFC   AFC West\n",
      "24     PIT   Pittsburgh Steelers    Steelers         PIT        AFC  AFC North\n",
      "25     LAC    San Diego Chargers    Chargers         SDG        AFC   AFC West\n",
      "26     SEA      Seattle Seahawks    Seahawks         SEA        NFC   NFC West\n",
      "27     ARI   St. Louis Cardinals   Cardinals         ARI        NFC       None\n",
      "28     LAR        St. Louis Rams        Rams         RAM        NFC       None\n",
      "29      TB  Tampa Bay Buccaneers  Buccaneers         TAM        NFC  NFC South\n",
      "30     TEN      Tennessee Titans      Titans         OTI        AFC  AFC South\n",
      "31     WAS   Washington Redskins  Washington         WAS        NFC   NFC East\n",
      "\n",
      "Team History table:\n",
      "Number of history records: 62\n",
      "     team_history_id team_id                      name  name_short team_id_pfr  \\\n",
      "0                 1     ARI         Arizona Cardinals   Cardinals         CRD   \n",
      "1                 2     ATL           Atlanta Falcons     Falcons         ATL   \n",
      "2                 3     IND           Baltimore Colts       Colts         CLT   \n",
      "3                 4     BAL          Baltimore Ravens      Ravens         RAV   \n",
      "4                 5      NE           Boston Patriots    Patriots         NWE   \n",
      "..              ...     ...                       ...         ...         ...   \n",
      "57               58      TB      Tampa Bay Buccaneers  Buccaneers         TAM   \n",
      "58               59     TEN          Tennessee Oilers      Oilers         OTI   \n",
      "59               60     TEN          Tennessee Titans      Titans         OTI   \n",
      "60               61     WAS  Washington Football Team  Washington         WAS   \n",
      "61               62     WAS       Washington Redskins  Washington         WAS   \n",
      "\n",
      "   conference     division  \n",
      "0         NFC     NFC West  \n",
      "1         NFC     NFC West  \n",
      "2         AFC     AFC East  \n",
      "3         AFC  AFC Central  \n",
      "4         AFC         None  \n",
      "..        ...          ...  \n",
      "57        NFC    NFC South  \n",
      "58        AFC         None  \n",
      "59        AFC    AFC South  \n",
      "60        NFC     NFC East  \n",
      "61        NFC     NFC East  \n",
      "\n",
      "[62 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\257198371.py:91: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  teams_df = pd.read_sql(\"SELECT * FROM current_teams\", conn)\n",
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\257198371.py:95: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  history_df = pd.read_sql(\"SELECT * FROM team_history\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Ingest Teams\n",
    "df = pd.read_csv('nfl_teams.csv')\n",
    "\n",
    "# First pass: Insert pre-2002 data\n",
    "for x in df.index:\n",
    "    team_id = df['team_id'].loc[x]\n",
    "    name = df['team_name'].loc[x]\n",
    "    name_short = df['team_name_short'].loc[x]\n",
    "    team_id_pfr = df['team_id_pfr'].loc[x]\n",
    "    conference = df['team_conference_pre2002'].loc[x]\n",
    "    division = df['team_division_pre2002'].loc[x]\n",
    "\n",
    "    # Clean data\n",
    "    team_id = handle_na(team_id)\n",
    "    name = handle_na(name)\n",
    "    name_short = handle_na(name_short)\n",
    "    team_id_pfr = handle_na(team_id_pfr)\n",
    "    conference = handle_na(conference)\n",
    "    division = handle_na(division)\n",
    "    \n",
    "    # Check if team_id exists\n",
    "    cursor.execute('SELECT team_id FROM current_teams WHERE team_id = %s', (team_id,))\n",
    "    exists = cursor.fetchone()\n",
    "    \n",
    "    if not exists:\n",
    "        # Insert into current_teams only if it doesn't exist\n",
    "        cursor.execute('''\n",
    "            INSERT INTO current_teams (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "        \n",
    "        # Insert into team_history\n",
    "        cursor.execute('''\n",
    "            INSERT INTO team_history \n",
    "            (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "        \n",
    "        print(f\"Inserted pre-2002 record for team: {name}\")\n",
    "    \n",
    "# Second pass: Check for changes and update if needed\n",
    "for x in df.index:\n",
    "    team_id = df['team_id'].loc[x]\n",
    "    name = df['team_name'].loc[x]\n",
    "    name_short = df['team_name_short'].loc[x]\n",
    "    team_id_pfr = df['team_id_pfr'].loc[x]\n",
    "    conference = df['team_conference'].loc[x]\n",
    "    division = df['team_division'].loc[x]\n",
    "\n",
    "    # Clean data\n",
    "    team_id = handle_na(team_id)\n",
    "    name = handle_na(name)\n",
    "    name_short = handle_na(name_short)\n",
    "    team_id_pfr = handle_na(team_id_pfr)\n",
    "    conference = handle_na(conference)\n",
    "    division = handle_na(division)\n",
    "\n",
    "    # Get current values\n",
    "    cursor.execute('''\n",
    "        SELECT name, name_short, team_id_pfr, conference, division \n",
    "        FROM current_teams \n",
    "        WHERE team_id = %s;\n",
    "    ''', (team_id,))  # Fixed tuple syntax\n",
    "    \n",
    "    current = cursor.fetchone()\n",
    "    if current:\n",
    "        current_values = list(current)\n",
    "        new_values = [name, name_short, team_id_pfr, conference, division]\n",
    "        \n",
    "        # Check if any values have changed\n",
    "        if current_values != new_values:            \n",
    "            cursor.execute('''\n",
    "                INSERT INTO team_history \n",
    "                (team_id, name, name_short, team_id_pfr, conference, division)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s);\n",
    "            ''', (team_id, name, name_short, team_id_pfr, conference, division))\n",
    "            \n",
    "            # Update current_teams\n",
    "            cursor.execute('''\n",
    "                UPDATE current_teams \n",
    "                SET name = %s, name_short = %s, team_id_pfr = %s, conference = %s, division = %s\n",
    "                WHERE team_id = %s;\n",
    "            ''', (name, name_short, team_id_pfr, conference, division, team_id))\n",
    "            \n",
    "            print(f\"Updated record for team: {name}\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nCurrent Teams table:\")\n",
    "teams_df = pd.read_sql(\"SELECT * FROM current_teams\", conn)\n",
    "print(f\"Number of current teams: {len(teams_df)}\\n\", teams_df)\n",
    "\n",
    "print(\"\\nTeam History table:\")\n",
    "history_df = pd.read_sql(\"SELECT * FROM team_history\", conn)\n",
    "print(f\"Number of history records: {len(history_df)}\\n\", history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffcdf7fa-3858-450b-a112-c1d21ff3cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1053402355.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_customers = pd.read_sql('SELECT customer_id FROM customers;', conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 customers (5.0%) | Last 100 customers: 0:04 | Total time: 0:04\n",
      "Processed 200 customers (10.0%) | Last 100 customers: 0:04 | Total time: 0:09\n",
      "Processed 300 customers (15.0%) | Last 100 customers: 0:04 | Total time: 0:14\n",
      "Processed 400 customers (20.0%) | Last 100 customers: 0:04 | Total time: 0:19\n",
      "Processed 500 customers (25.0%) | Last 100 customers: 0:05 | Total time: 0:24\n",
      "Processed 600 customers (30.0%) | Last 100 customers: 0:05 | Total time: 0:30\n",
      "Processed 700 customers (35.0%) | Last 100 customers: 0:04 | Total time: 0:35\n",
      "Processed 800 customers (40.0%) | Last 100 customers: 0:04 | Total time: 0:39\n",
      "Processed 900 customers (45.0%) | Last 100 customers: 0:04 | Total time: 0:44\n",
      "Processed 1000 customers (50.0%) | Last 100 customers: 0:04 | Total time: 0:48\n",
      "Processed 1100 customers (55.0%) | Last 100 customers: 0:04 | Total time: 0:53\n",
      "Processed 1200 customers (60.0%) | Last 100 customers: 0:05 | Total time: 0:58\n",
      "Processed 1300 customers (65.0%) | Last 100 customers: 0:05 | Total time: 1:04\n",
      "Processed 1400 customers (70.0%) | Last 100 customers: 0:04 | Total time: 1:09\n",
      "Processed 1500 customers (75.0%) | Last 100 customers: 0:04 | Total time: 1:13\n",
      "Processed 1600 customers (80.0%) | Last 100 customers: 0:04 | Total time: 1:18\n",
      "Processed 1700 customers (85.0%) | Last 100 customers: 0:04 | Total time: 1:22\n",
      "Processed 1800 customers (90.0%) | Last 100 customers: 0:04 | Total time: 1:27\n",
      "Processed 1900 customers (95.0%) | Last 100 customers: 0:04 | Total time: 1:32\n",
      "\n",
      "Total processing time: 1:32\n",
      "\n",
      "Customers table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\1053402355.py:76: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  customers_df = pd.read_sql(\"SELECT * FROM customers\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers: 2000\n",
      "      customer_id first_name last_name  age customer_type  customer_since  \\\n",
      "0               1   Coraline    Flores   23        online            2022   \n",
      "1               2    Presley     Ortiz   41        online            2021   \n",
      "2               3       Reid    Knight   40        online            2023   \n",
      "3               4   Clarissa  Chandler   43         local            2023   \n",
      "4               5      Isaac    Vaughn   23         phone            2023   \n",
      "...           ...        ...       ...  ...           ...             ...   \n",
      "1995         1996     Maxine      Pope   36         local            2020   \n",
      "1996         1997    Camilla     Wolfe   46         local            2020   \n",
      "1997         1998     Karina    Knight   36         local            2020   \n",
      "1998         1999  Sebastian   Winters   55         local            2020   \n",
      "1999         2000   Hadassah      Wade   29         local            2021   \n",
      "\n",
      "      income  household_size mode_color  \n",
      "0     116000               1        red  \n",
      "1     111000               1       blue  \n",
      "2      55000               1      green  \n",
      "3      32000               2     orange  \n",
      "4      46000               1       blue  \n",
      "...      ...             ...        ...  \n",
      "1995   29000               2       blue  \n",
      "1996   62000               2     purple  \n",
      "1997   64000               1     orange  \n",
      "1998   93000               1     purple  \n",
      "1999  150000               4      black  \n",
      "\n",
      "[2000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Customers\n",
    "\n",
    "# df = pd.read_sql(\"SELECT * FROM customer_table;\", pymssql_conn)\n",
    "df = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# Get current customers and convert to list\n",
    "current_customers = pd.read_sql('SELECT customer_id FROM customers;', conn)\n",
    "cc = current_customers['customer_id'].tolist()\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each customer\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    customer_id = int_convert(df['customer_id'].loc[x])\n",
    "    \n",
    "    # Only proceed if customer is new\n",
    "    if customer_id not in cc:\n",
    "        cc.append(customer_id)\n",
    "        \n",
    "        customer_name = df['customer_name'].loc[x]\n",
    "        age = int_convert(df['customer_age'].loc[x])\n",
    "        customer_type = handle_na(df['customer_type'].loc[x])\n",
    "        customer_since = int_convert(df['customer_since'].loc[x])\n",
    "        income = int_convert(df['customer_income'].loc[x])\n",
    "        household_size = int_convert(df['household_size'].loc[x])\n",
    "        mode_color = handle_na(df['mode_color'].loc[x])\n",
    "        \n",
    "        # Name\n",
    "        name_parts = customer_name.split(' ')\n",
    "        if len(name_parts) == 2:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = name_parts[1]\n",
    "        else:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = ' '.join(name_parts[1:])\n",
    "        \n",
    "        # Insert into customers table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO customers \n",
    "            (customer_id, first_name, last_name, age, customer_type, \n",
    "             customer_since, income, household_size, mode_color)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (customer_id, first_name, last_name, age, customer_type, \n",
    "              customer_since, income, household_size, mode_color))\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:  # Print progress every 100 records\n",
    "            current_time = time.time()\n",
    "            elapsed_since_last = current_time - last_check\n",
    "            total_elapsed = current_time - start_time\n",
    "    \n",
    "            last_check_min = int(elapsed_since_last // 60)\n",
    "            last_check_sec = int(elapsed_since_last % 60)\n",
    "            total_min = int(total_elapsed // 60)\n",
    "            total_sec = int(total_elapsed % 60)\n",
    "    \n",
    "            percent_complete = (counter / len(df)) * 100\n",
    "            \n",
    "            print(f\"Processed {counter} customers ({percent_complete:.1f}%) | Last 100 customers: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d}\")\n",
    "            last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nCustomers table:\")\n",
    "customers_df = pd.read_sql(\"SELECT * FROM customers\", conn)\n",
    "print(f\"Number of customers: {len(cc)}\")\n",
    "print(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a6bd5dc-67eb-4e4d-9144-90fa887c4efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_52102/3480200415.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_games = pd.read_sql(\"SELECT game_id FROM games;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 games (4.1%) | Last 100 games: 0:27 | Total time: 0:27\n",
      "Processed 200 games (8.1%) | Last 100 games: 0:26 | Total time: 0:53\n",
      "Processed 300 games (12.2%) | Last 100 games: 0:26 | Total time: 1:20\n",
      "Processed 400 games (16.3%) | Last 100 games: 0:30 | Total time: 1:50\n",
      "Processed 500 games (20.3%) | Last 100 games: 0:27 | Total time: 2:17\n",
      "Processed 600 games (24.4%) | Last 100 games: 0:26 | Total time: 2:43\n",
      "Processed 700 games (28.5%) | Last 100 games: 0:26 | Total time: 3:10\n",
      "Processed 800 games (32.5%) | Last 100 games: 0:28 | Total time: 3:38\n",
      "Processed 900 games (36.6%) | Last 100 games: 0:26 | Total time: 4:04\n",
      "Processed 1000 games (40.7%) | Last 100 games: 0:26 | Total time: 4:31\n",
      "Processed 1100 games (44.8%) | Last 100 games: 0:27 | Total time: 4:58\n",
      "Processed 1200 games (48.8%) | Last 100 games: 0:26 | Total time: 5:25\n",
      "Processed 1300 games (52.9%) | Last 100 games: 0:26 | Total time: 5:51\n",
      "Processed 1400 games (57.0%) | Last 100 games: 0:26 | Total time: 6:17\n",
      "Processed 1500 games (61.0%) | Last 100 games: 0:26 | Total time: 6:44\n",
      "Processed 1600 games (65.1%) | Last 100 games: 0:26 | Total time: 7:10\n",
      "Processed 1700 games (69.2%) | Last 100 games: 0:31 | Total time: 7:42\n",
      "Processed 1800 games (73.2%) | Last 100 games: 0:30 | Total time: 8:12\n",
      "Processed 1900 games (77.3%) | Last 100 games: 0:30 | Total time: 8:42\n",
      "Processed 2000 games (81.4%) | Last 100 games: 0:30 | Total time: 9:12\n",
      "Processed 2100 games (85.4%) | Last 100 games: 0:29 | Total time: 9:41\n",
      "Processed 2200 games (89.5%) | Last 100 games: 0:31 | Total time: 10:13\n",
      "Processed 2300 games (93.6%) | Last 100 games: 0:27 | Total time: 10:41\n",
      "Processed 2400 games (97.6%) | Last 100 games: 0:28 | Total time: 11:09\n",
      "\n",
      "Total processing time: 11:24\n",
      "\n",
      "Games table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_52102/3480200415.py:155: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  games_df = pd.read_sql(\"SELECT * FROM games;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games: 2458\n",
      "             game_id schedule_date  schedule_season  schedule_week  \\\n",
      "0      201501-NE-PIT    2015-09-10             2015              1   \n",
      "1      201501-ARI-NO    2015-09-13             2015              1   \n",
      "2     201501-BUF-IND    2015-09-13             2015              1   \n",
      "3      201501-CHI-GB    2015-09-13             2015              1   \n",
      "4     201501-DAL-NYG    2015-09-13             2015              1   \n",
      "...              ...           ...              ...            ...   \n",
      "2453   202320-BUF-KC    2024-01-21             2023             20   \n",
      "2454   202320-DET-TB    2024-01-21             2023             20   \n",
      "2455   202321-BAL-KC    2024-01-28             2023             21   \n",
      "2456   202321-SF-DET    2024-01-28             2023             21   \n",
      "2457    202322-KC-SF    2024-02-11             2023             22   \n",
      "\n",
      "      schedule_playoff playoff_type team_id_home team_id_away  score_home  \\\n",
      "0                False         None           NE          PIT          28   \n",
      "1                False         None          ARI           NO          31   \n",
      "2                False         None          BUF          IND          27   \n",
      "3                False         None          CHI           GB          23   \n",
      "4                False         None          DAL          NYG          27   \n",
      "...                ...          ...          ...          ...         ...   \n",
      "2453              True     Division          BUF           KC          24   \n",
      "2454              True     Division          DET           TB          31   \n",
      "2455              True   Conference          BAL           KC          10   \n",
      "2456              True   Conference           SF          DET          34   \n",
      "2457              True    Superbowl           KC           SF          25   \n",
      "\n",
      "      score_away  ... spread_favorite  over_under_line  stadium_id  \\\n",
      "0             21  ...            -7.0             51.0          36   \n",
      "1             19  ...            -2.5             48.5         111   \n",
      "2             14  ...            -1.0             44.5          81   \n",
      "3             31  ...            -6.5             48.5          92   \n",
      "4             26  ...            -7.0             52.5          21   \n",
      "...          ...  ...             ...              ...         ...   \n",
      "2453          27  ...            -2.5             46.0          40   \n",
      "2454          23  ...            -6.0             49.5          30   \n",
      "2455          17  ...            -4.5             44.0          59   \n",
      "2456          31  ...            -7.5             53.5          51   \n",
      "2457          22  ...            -2.0             47.0           3   \n",
      "\n",
      "      stadium_neutral  weather_temperature  weather_wind_mph  \\\n",
      "0               False                 64.0               9.0   \n",
      "1               False                 72.0               0.0   \n",
      "2               False                 53.0               7.0   \n",
      "3               False                 68.0               4.0   \n",
      "4               False                 72.0               0.0   \n",
      "...               ...                  ...               ...   \n",
      "2453            False                 25.0              11.0   \n",
      "2454            False                 72.0               0.0   \n",
      "2455            False                 47.0               7.0   \n",
      "2456            False                 69.0               5.0   \n",
      "2457             True                 72.0               0.0   \n",
      "\n",
      "      weather_humidity  weather_detail winner_ou winner_line  \n",
      "0                  NaN            rain     under        push  \n",
      "1                  NaN          indoor      over        home  \n",
      "2                  NaN            None     under        home  \n",
      "3                  NaN            None      over        away  \n",
      "4                  NaN          indoor      over        away  \n",
      "...                ...             ...       ...         ...  \n",
      "2453              67.0            None      over        away  \n",
      "2454               NaN          indoor      over        home  \n",
      "2455              83.0            None     under        away  \n",
      "2456              55.0            None      over        away  \n",
      "2457               NaN          indoor      push        home  \n",
      "\n",
      "[2458 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Games\n",
    "\n",
    "# Read games data\n",
    "df = pd.read_csv('spread_scores-2.csv')\n",
    "\n",
    "# Filter for games from 2015 onwards\n",
    "df = df[df['schedule_season'] >= 2015]\n",
    "\n",
    "# Get current games and convert to list\n",
    "current_games = pd.read_sql(\"SELECT game_id FROM games;\", conn)\n",
    "cg = current_games['game_id'].tolist()\n",
    "\n",
    "TEAM_ID_CORRECTIONS = {\n",
    "    'LV': 'LVR',\n",
    "    }\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each game\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    # Construct game_id \n",
    "    season = str(df['schedule_season'].loc[x])\n",
    "    \n",
    "    weeknum = df['schedule_week'].loc[x]\n",
    "    if weeknum == \"Wildcard\":\n",
    "        playoff_type = \"Wildcard\"\n",
    "        weeknum = \"19\"\n",
    "    elif weeknum == \"Division\":\n",
    "        playoff_type = \"Division\"\n",
    "        weeknum = \"20\"\n",
    "    elif weeknum == \"Conference\":\n",
    "        playoff_type = \"Conference\"\n",
    "        weeknum = \"21\"\n",
    "    elif weeknum == \"Superbowl\":\n",
    "        playoff_type = \"Superbowl\"\n",
    "        weeknum = \"22\"\n",
    "    else:\n",
    "        playoff_type = None\n",
    "        weeknum = str(weeknum)\n",
    "        \n",
    "    if len(weeknum) < 2: \n",
    "        weeknum = \"0\" + weeknum\n",
    "\n",
    "    weekstring = weeknum\n",
    "    weeknum = int_convert(weeknum)\n",
    "    \n",
    "    cursor.execute(f\"SELECT DISTINCT team_id FROM team_history WHERE name = '{df['team_home'].loc[x]}';\")\n",
    "    home_id = cursor.fetchone()[0]\n",
    "    home_id = TEAM_ID_CORRECTIONS.get(home_id, home_id)\n",
    "    \n",
    "    cursor.execute(f\"SELECT DISTINCT team_id FROM team_history WHERE name = '{df['team_away'].loc[x]}';\")\n",
    "    away_id = cursor.fetchone()[0]\n",
    "    away_id = TEAM_ID_CORRECTIONS.get(away_id, away_id)\n",
    "    \n",
    "    game_id = f\"{season}{weekstring}-{home_id}-{away_id}\"\n",
    "    \n",
    "    # Only proceed if game is new\n",
    "    if game_id not in cg:\n",
    "        cg.append(game_id)\n",
    "        \n",
    "        # Get required data\n",
    "        schedule_date = datetime.strptime(df['schedule_date'].loc[x], '%m/%d/%Y')\n",
    "        schedule_season = int_convert(df['schedule_season'].loc[x])\n",
    "        schedule_week = weeknum\n",
    "        schedule_playoff = bool(df['schedule_playoff'].loc[x])\n",
    "        score_home = int_convert(df['score_home'].loc[x])\n",
    "        score_away = int_convert(df['score_away'].loc[x])\n",
    "        team_favorite_id = df['team_favorite_id'].loc[x]\n",
    "        spread_favorite = df['spread_favorite'].loc[x]\n",
    "        over_under_line = df['over_under_line'].loc[x]\n",
    "        stadium_name = df['stadium'].loc[x]\n",
    "        stadium_neutral = bool(df['stadium_neutral'].loc[x])\n",
    "        weather_temperature = int_convert(df['weather_temperature'].loc[x])\n",
    "        weather_wind_mph = int_convert(df['weather_wind_mph'].loc[x])\n",
    "        weather_humidity = int_convert(df['weather_humidity'].loc[x])\n",
    "        weather_detail = handle_na(df['weather_detail'].loc[x])        \n",
    "\n",
    "\n",
    "        # Try to find existing stadium\n",
    "        stadium_id = None\n",
    "        cursor.execute(\"SELECT stadium_id FROM stadiums WHERE name = %s;\", (stadium_name,))\n",
    "        stadium_result = cursor.fetchone()\n",
    "\n",
    "        if stadium_result:\n",
    "            stadium_id = stadium_result[0]\n",
    "        else:\n",
    "            # Insert new stadium with minimal info and get its ID\n",
    "            cursor.execute('''INSERT INTO stadiums (name) VALUES (%s);''', (stadium_name,))\n",
    "            conn.commit()\n",
    "            cursor.execute(\"SELECT stadium_id FROM stadiums WHERE name = %s;\", (stadium_name,))\n",
    "            stadium_id = cursor.fetchone()[0]\n",
    "            print(f\"Added new stadium: {stadium_name} with ID: {stadium_id}\")\n",
    "        \n",
    "        # Handle PICK\n",
    "        if team_favorite_id == 'PICK':\n",
    "            team_favorite_id = home_id  # Use home team and set spread to 0 float\n",
    "            spread_favorite = 0.0\n",
    "        else:\n",
    "            team_favorite_id = TEAM_ID_CORRECTIONS.get(team_favorite_id, team_favorite_id)\n",
    "        \n",
    "        # Calculate winner_ou and winner_line\n",
    "        total_score = score_home + score_away\n",
    "        winner_ou = get_winner_ou(total_score, over_under_line)\n",
    "        winner_line = get_winner_line(score_home, score_away, spread_favorite, team_favorite_id)\n",
    "\n",
    "        # Insert into games table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO games (\n",
    "                game_id, schedule_date, schedule_season, schedule_week, \n",
    "                schedule_playoff, playoff_type, team_id_home, team_id_away, \n",
    "                score_home, score_away, team_id_favorite, spread_favorite,\n",
    "                over_under_line, stadium_id, stadium_neutral, \n",
    "                weather_temperature, weather_wind_mph, weather_humidity,\n",
    "                weather_detail, winner_ou, winner_line)\n",
    "            VALUES (\n",
    "                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                %s, %s, %s, %s, %s, %s, %s);\n",
    "        ''', (game_id, schedule_date, schedule_season, schedule_week,\n",
    "              schedule_playoff, playoff_type, home_id, away_id,\n",
    "              score_home, score_away, team_favorite_id, spread_favorite,\n",
    "              over_under_line, stadium_id, stadium_neutral,\n",
    "              weather_temperature, weather_wind_mph, weather_humidity,\n",
    "              weather_detail, winner_ou, winner_line))\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:  # Print progress every 100 records\n",
    "            current_time = time.time()\n",
    "            elapsed_since_last = current_time - last_check\n",
    "            total_elapsed = current_time - start_time\n",
    "    \n",
    "            last_check_min = int(elapsed_since_last // 60)\n",
    "            last_check_sec = int(elapsed_since_last % 60)\n",
    "            total_min = int(total_elapsed // 60)\n",
    "            total_sec = int(total_elapsed % 60)\n",
    "    \n",
    "            percent_complete = (counter / len(df)) * 100\n",
    "            \n",
    "            print(f\"Processed {counter} games ({percent_complete:.1f}%) | Last 100 games: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d}\")\n",
    "            last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nGames table:\")\n",
    "games_df = pd.read_sql(\"SELECT * FROM games;\", conn)\n",
    "print(f\"Number of games: {len(cg)}\")\n",
    "print(games_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "271b9f85-0c0a-4f8b-a641-0d1305806292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_52102/4275608737.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_bets = pd.read_sql(\"SELECT bet_id FROM placed_bets;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 bets (0.8%) | Last 1000 bets: 3:04 | Total time: 3:04\n",
      "Processed 2000 bets (1.6%) | Last 1000 bets: 3:05 | Total time: 6:09\n",
      "Processed 3000 bets (2.4%) | Last 1000 bets: 3:03 | Total time: 9:13\n",
      "\n",
      "Total processing time: 9:13\n",
      "\n",
      "Bets table:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/kzlzzx2556jf68c57bc_gc180000gn/T/ipykernel_52102/4275608737.py:91: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  bets_df = pd.read_sql(\"SELECT * FROM placed_bets;\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bets: 3000\n",
      "      bet_id  customer_id         game_id  bet_amount                bet_on  \\\n",
      "0          1            1   202301-KC-DET        8500         Detroit Lions   \n",
      "1          2            7   202301-KC-DET         350                 under   \n",
      "2          3            8   202301-KC-DET       10000    Kansas City Chiefs   \n",
      "3          4           23   202301-KC-DET         200                 under   \n",
      "4          5           24   202301-KC-DET         400                  over   \n",
      "...      ...          ...             ...         ...                   ...   \n",
      "2995    2996         1963  202301-IND-JAX         100  Jacksonville Jaguars   \n",
      "2996    2997         1968  202301-IND-JAX        3000                 under   \n",
      "2997    2998         1979  202301-IND-JAX        6500  Jacksonville Jaguars   \n",
      "2998    2999         1980  202301-IND-JAX         100  Jacksonville Jaguars   \n",
      "2999    3000         1981  202301-IND-JAX         100    Indianapolis Colts   \n",
      "\n",
      "     result  commission_amount  \n",
      "0       win              630.0  \n",
      "1       win               35.0  \n",
      "2      loss              720.0  \n",
      "3       win               20.0  \n",
      "4      loss               40.0  \n",
      "...     ...                ...  \n",
      "2995    win               10.0  \n",
      "2996   loss              260.0  \n",
      "2997    win              510.0  \n",
      "2998    win               10.0  \n",
      "2999   loss               10.0  \n",
      "\n",
      "[3000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ingest Bets\n",
    "\n",
    "# Read betting data\n",
    "# df = pd.read_sql(\"SELECT * FROM betlog;\", pymssql_conn)\n",
    "df = pd.read_csv('betting_data.csv')\n",
    "\n",
    "# Get current bets and convert to list\n",
    "current_bets = pd.read_sql(\"SELECT bet_id FROM placed_bets;\", conn)\n",
    "cb = current_bets['bet_id'].tolist()\n",
    "GAME_ID_CORRECTIONS = {\n",
    "    'LV': 'LVR',\n",
    "    'JAC': 'JAX'\n",
    "    }\n",
    "\n",
    "# Initialize timer\n",
    "start_time = time.time()\n",
    "last_check = start_time\n",
    "\n",
    "# Process each bet\n",
    "counter = 0\n",
    "for x in df.index:\n",
    "    if counter >= 3000:\n",
    "        break\n",
    "        \n",
    "    bet_id = int_convert(df['bet_id'].loc[x])\n",
    "    \n",
    "    # Only proceed if bet is new\n",
    "    if bet_id not in cb:\n",
    "        cb.append(bet_id)\n",
    "        \n",
    "        customer_id = int_convert(df['customer_id'].loc[x])\n",
    "\n",
    "        # Fix game ids\n",
    "        game_id = df['game_id'].loc[x]\n",
    "        game_id_parts = game_id.split('-')\n",
    "        if len(game_id_parts) == 3:\n",
    "            season_week, team1, team2 = game_id_parts\n",
    "            team1 = GAME_ID_CORRECTIONS.get(team1, team1)\n",
    "            team2 = GAME_ID_CORRECTIONS.get(team2, team2)\n",
    "            game_id = f\"{season_week}-{team1}-{team2}\"\n",
    "\n",
    "        \n",
    "        bet_amount = int_convert(df['bet_amount'].loc[x])\n",
    "        bet_on = df['bet_on'].loc[x]\n",
    "        \n",
    "        # Get game details to determine bet result\n",
    "        cursor.execute(\"SELECT winner_line, winner_ou, team_id_home, team_id_away FROM games WHERE game_id = %s;\", (game_id,))\n",
    "        game_details = cursor.fetchone()\n",
    "        \n",
    "        if game_details:\n",
    "            winner_line, winner_ou, team_id_home, team_id_away = game_details\n",
    "            \n",
    "            # Get result and commission\n",
    "            result = determine_bet_result(bet_on, winner_line, winner_ou, team_id_home, team_id_away)                \n",
    "            commission_amount = calculate_commission(bet_amount)\n",
    "            \n",
    "            # Insert into bets table\n",
    "            cursor.execute('''\n",
    "                INSERT INTO placed_bets (bet_id, customer_id, game_id, bet_amount, bet_on, result, commission_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "            ''', (bet_id, customer_id, game_id, bet_amount, bet_on, result, commission_amount))\n",
    "        else:\n",
    "            print(f\"Warning: Could not find game details for game_id {game_id}\")\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:  # Print progress every 1000 records\n",
    "        current_time = time.time()\n",
    "        elapsed_since_last = current_time - last_check\n",
    "        total_elapsed = current_time - start_time\n",
    "\n",
    "        last_check_min = int(elapsed_since_last // 60)\n",
    "        last_check_sec = int(elapsed_since_last % 60)\n",
    "        total_min = int(total_elapsed // 60)\n",
    "        total_sec = int(total_elapsed % 60)\n",
    "\n",
    "        percent_complete = (counter / len(df)) * 100\n",
    "        \n",
    "        print(f\"Processed {counter} bets ({percent_complete:.1f}%) | Last 1000 bets: {last_check_min}:{last_check_sec:02d} | Total time: {total_min}:{total_sec:02d}\")\n",
    "        last_check = current_time\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Final timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_min = int(total_time // 60)\n",
    "total_sec = int(total_time % 60)\n",
    "print(f\"\\nTotal processing time: {total_min}:{total_sec:02d}\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nBets table:\")\n",
    "bets_df = pd.read_sql(\"SELECT * FROM placed_bets;\", conn)\n",
    "print(f\"Number of bets: {len(cb)}\")\n",
    "print(bets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ed2099-1e87-4a53-a4c8-dfd9886c82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chanc\\AppData\\Local\\Temp\\ipykernel_10660\\661526783.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported customers to iwdm_customers.csv\n",
      "Number of records: 2000\n",
      "Successfully exported bets to iwdm_bets.csv\n",
      "Number of records: 126047\n",
      "Successfully exported games to iwdm_games.csv\n",
      "Number of records: 2458\n",
      "Successfully exported team_history to iwdm_team_history.csv\n",
      "Number of records: 62\n",
      "Successfully exported current_teams to iwdm_current_teams.csv\n",
      "Number of records: 32\n",
      "Successfully exported stadiums to iwdm_stadiums.csv\n",
      "Number of records: 120\n",
      "Successfully exported weather_stations to iwdm_weather_stations.csv\n",
      "Number of records: 29\n"
     ]
    }
   ],
   "source": [
    "# # Create csvs of finals\n",
    "# tables = ['customers', 'bets', 'games', 'team_history', 'current_teams', 'stadiums', 'weather_stations']\n",
    "# for table in tables:\n",
    "#     query = f\"SELECT * FROM {table};\"\n",
    "#     df = pd.read_sql(query, conn)\n",
    "\n",
    "#     filename = f'iwdm_{table}.csv'\n",
    "#     df.to_csv(filename, index=False)\n",
    "#     print(f\"Successfully exported {table} to {filename}\")\n",
    "#     print(f\"Number of records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72365cf2-5df5-4b66-b274-d5d9600bddb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Queries\n",
    "\n",
    "# 1\n",
    "tables = ['customers', 'placed_bets', 'games', 'team_history', 'current_teams', 'stadiums', 'weather_stations']\n",
    "for table in tables:\n",
    "    query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(f\"\\nFirst 5 rows from {table}:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d3c53-9633-4aa0-9192-f89465cf2ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2a\n",
    "query = \"\"\"\n",
    "WITH commission_totals AS (\n",
    "    SELECT \n",
    "        c.customer_id, \n",
    "        SUM(commission_amount) as total_commission\n",
    "    FROM customers c\n",
    "    JOIN placed_bets b ON c.customer_id = b.customer_id\n",
    "    GROUP BY c.customer_id\n",
    "    HAVING SUM(commission_amount) > 20000\n",
    ")\n",
    "SELECT \n",
    "    COUNT(*) as customers_over_20k,\n",
    "    (SELECT COUNT(*) FROM customers) as total_customers,\n",
    "    ROUND(CAST(COUNT(*) AS DECIMAL) / (SELECT COUNT(*) FROM customers) * 100, 2) as percentage\n",
    "FROM commission_totals;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Summary of high-commission customers:\\n\", df)\n",
    "\n",
    "# 2b\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    c.first_name,\n",
    "    c.last_name,\n",
    "    ROUND(CAST(SUM(commission_amount) AS DECIMAL), 2) as total_commission\n",
    "FROM customers c\n",
    "JOIN placed_bets b ON c.customer_id = b.customer_id\n",
    "GROUP BY c.customer_id, first_name, last_name\n",
    "HAVING SUM(commission_amount) > 20000\n",
    "ORDER BY total_commission DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"\\nTop 20 commission payers:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bb6b2-2d33-4125-8e0b-da764595dc37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "query = \"\"\"\n",
    "WITH bet_stats AS (\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        COUNT(*) as total_bets,\n",
    "        COUNT(CASE WHEN b.result = 'win' THEN 1 END) as wins,\n",
    "        SUM(CASE \n",
    "            WHEN b.result = 'win' THEN b.bet_amount\n",
    "            WHEN b.result = 'loss' THEN -b.bet_amount\n",
    "            ELSE 0 END) as total_winnings\n",
    "    FROM customers c\n",
    "    JOIN placed_bets b ON c.customer_id = b.customer_id\n",
    "    GROUP BY c.customer_id, c.first_name, c.last_name\n",
    "    HAVING COUNT(*) >= 6\n",
    ")\n",
    "SELECT \n",
    "    first_name,\n",
    "    last_name,\n",
    "    total_bets,\n",
    "    wins,\n",
    "    ROUND((CAST(wins AS DECIMAL) / total_bets * 100), 2) as win_percentage,\n",
    "    total_winnings\n",
    "FROM bet_stats\n",
    "ORDER BY win_percentage DESC, total_winnings DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Top 10 luckiest bettors:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ea3a7-3c56-4f0f-86d7-d717988fc35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    first_name,\n",
    "    last_name,\n",
    "    COUNT(*) as total_bets,\n",
    "    COUNT(CASE WHEN result = 'win' THEN 1 END) as wins,\n",
    "    SUM(CASE \n",
    "        WHEN result = 'win' THEN -(bet_amount + bet_amount)\n",
    "        WHEN result = 'loss' THEN bet_amount + commission_amount\n",
    "        WHEN result = 'push' THEN commission_amount END) as net_lost_for_company\n",
    "FROM customers c\n",
    "JOIN placed_bets b ON c.customer_id = b.customer_id\n",
    "GROUP BY c.customer_id, first_name, last_name\n",
    "ORDER BY net_lost_for_company\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"20 costliest customers for the sports book:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510e79c-3ffe-42fb-8bd6-154032d43117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5\n",
    "query = \"\"\"\n",
    "WITH weekly_games AS (\n",
    "    SELECT \n",
    "        schedule_week,\n",
    "        COUNT(*) as total_games,\n",
    "        COUNT(CASE WHEN \n",
    "            (winner_line = 'home' AND spread_favorite > 0) OR \n",
    "            (winner_line = 'away' AND spread_favorite < 0) THEN 1 END) as winners,\n",
    "        COUNT(CASE WHEN \n",
    "            (winner_line = 'away' AND spread_favorite > 0) OR\n",
    "            (winner_line = 'home' AND spread_favorite < 0) THEN 1 END) as losers\n",
    "    FROM games\n",
    "    WHERE schedule_season = 2023 AND schedule_playoff = false\n",
    "    GROUP BY schedule_week\n",
    ")\n",
    "SELECT \n",
    "    schedule_week,\n",
    "    total_games,\n",
    "    winners,\n",
    "    losers,\n",
    "    ROUND((CAST(winners AS DECIMAL) / total_games * 100), 2) as winner_percentage,\n",
    "    ROUND((CAST(losers AS DECIMAL) / total_games * 100), 2) as loser_percentage\n",
    "FROM weekly_games\n",
    "ORDER BY schedule_week;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Weekly house performance for 2023 season:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ec73d-782a-497b-b1b4-14c1a43f182d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6\n",
    "query = \"\"\"\n",
    "WITH team_games AS (\n",
    "    SELECT \n",
    "        name as team_name,\n",
    "        game_id,\n",
    "        CASE \n",
    "            WHEN team_id_home = team_id THEN 'home'\n",
    "            ELSE 'away' END as home_or_away,\n",
    "        score_home,\n",
    "        score_away,\n",
    "        winner_line,\n",
    "        spread_favorite,\n",
    "        team_id_favorite\n",
    "    FROM current_teams t\n",
    "    JOIN games g ON t.team_id = g.team_id_home OR t.team_id = g.team_id_away\n",
    "    WHERE schedule_season = 2023\n",
    "),\n",
    "team_records AS (\n",
    "    SELECT \n",
    "        team_name,\n",
    "        COUNT(*) AS games_played,\n",
    "        COUNT(CASE WHEN \n",
    "            (home_or_away = 'home' AND score_home > score_away) OR\n",
    "            (home_or_away = 'away' AND score_away > score_home) THEN 1 END) as wins,\n",
    "        COUNT(CASE WHEN \n",
    "            (home_or_away = 'home' AND score_home < score_away) OR\n",
    "            (home_or_away = 'away' AND score_away < score_home) THEN 1 END) as losses,\n",
    "        COUNT(CASE WHEN home_or_away = winner_line THEN 1 END) as beat_spread\n",
    "    FROM team_games\n",
    "    GROUP BY team_name\n",
    "),\n",
    "betting_counts AS (\n",
    "    SELECT \n",
    "        name AS team_name,\n",
    "        COUNT(CASE WHEN bet_on = ct.name THEN 1 END) AS bets_for,\n",
    "        COUNT(CASE WHEN bet_on != ct.name AND\n",
    "            bet_on NOT IN ('over', 'under') AND\n",
    "            team_id_home = team_id OR\n",
    "            team_id_away = team_id THEN 1 END) as bets_against\n",
    "    FROM current_teams ct\n",
    "    LEFT JOIN games g ON ct.team_id = g.team_id_home OR ct.team_id = g.team_id_away\n",
    "    LEFT JOIN placed_bets b ON g.game_id = b.game_id\n",
    "    WHERE schedule_season = 2023\n",
    "    GROUP BY team_id, name\n",
    ")\n",
    "SELECT \n",
    "    r.team_name,\n",
    "    wins,\n",
    "    losses,\n",
    "    beat_spread,\n",
    "    COALESCE(bets_for, 0) as bets_for,\n",
    "    COALESCE(bets_against, 0) as bets_against\n",
    "FROM team_records r\n",
    "LEFT JOIN betting_counts b ON r.team_name = b.team_name\n",
    "ORDER BY r.team_name;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"Per-team betting analysis for 2023 season:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411348a-c3d9-4f99-b951-2a39be0ffdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Analysis\n",
    "\n",
    "# Query to calculate customer value and create features\n",
    "query = \"\"\"\n",
    "WITH bet_values AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        SUM(bet_amount) AS total_bet,\n",
    "        SUM(commission_amount) as total_commission,\n",
    "        COUNT(*) as num_bets,\n",
    "        COUNT(CASE WHEN result = 'win' THEN 1 END) as num_wins,\n",
    "        SUM(CASE \n",
    "            WHEN result = 'win' THEN -(bet_amount * 2)\n",
    "            WHEN result = 'loss' THEN bet_amount\n",
    "            ELSE 0 END) AS bet_outcomes\n",
    "    FROM placed_bets\n",
    "    GROUP BY customer_id\n",
    ")\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    age,\n",
    "    income,\n",
    "    household_size, \n",
    "    customer_type,\n",
    "    customer_since,\n",
    "    mode_color,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    num_bets,\n",
    "    num_wins,\n",
    "    CASE WHEN customer_type = 'local' THEN 1 ELSE 0 END as type_local,\n",
    "    CASE WHEN customer_type = 'online' THEN 1 ELSE 0 END as type_online,\n",
    "    CASE WHEN customer_type = 'phone' THEN 1 ELSE 0 END as type_phone,\n",
    "    total_commission + bet_outcomes as customer_value\n",
    "FROM customers c\n",
    "LEFT JOIN bet_values bv ON c.customer_id = bv.customer_id;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Feature engineering\n",
    "df['name_length'] = df['first_name'].str.len() + df['last_name'].str.len()\n",
    "df['years_customer'] = 2024 - df['customer_since']\n",
    "df['win_rate'] = df['num_wins'] / df['num_bets']\n",
    "\n",
    "# A: Initial correlation matrix with all variables\n",
    "initial_predictors = ['age', 'income', 'household_size', 'type_local', 'type_online', 'type_phone', 'years_customer', 'name_length', 'win_rate']\n",
    "corr_matrix = df[initial_predictors].corr()\n",
    "print(\"\\nInitial Correlation Matrix:\\n\", corr_matrix)\n",
    "\n",
    "# B: First regression\n",
    "first_predictors = ['age', 'income', 'household_size', 'type_local']\n",
    "X = df[first_predictors]\n",
    "y = df['customer_value']\n",
    "X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X).fit()\n",
    "print(\"\\nFirst Model Results:\")\n",
    "print(model1.summary())\n",
    "\n",
    "# C: Second regression\n",
    "second_predictors = ['win_rate', 'years_customer', 'type_local', 'household_size']\n",
    "X2 = df[second_predictors]\n",
    "y = df['customer_value']\n",
    "X2 = sm.add_constant(X2)\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "print(\"\\nSecond Model Results:\")\n",
    "print(model2.summary())\n",
    "\n",
    "print(f\"\"\"\n",
    "Regression Analysis Summary:\n",
    "--------------------------\n",
    "1. Correlation Analysis:\n",
    "    - High collinearity detected between customer types (type_local, type_online, type_phone)\n",
    "    - No other concerning correlations found among independent variables\n",
    "    - Removed type_online and type_phone due to collinearity with type_local\n",
    "\n",
    "2. First Model:\n",
    "    - Variables: age, income, household_size, type_local\n",
    "    - Adjusted R-squared: {model1.rsquared_adj:.4f}\n",
    "    - Key findings:\n",
    "        * Age not significant (p={model1.pvalues['age']:.4f})\n",
    "        * All other variables significant at p<0.05\n",
    "        * Negative relationship with income and household_size\n",
    "        * Positive relationship with type_local\n",
    "\n",
    "3. Second Model:\n",
    "    - Variables: win_rate, years_customer, type_local, household_size\n",
    "    - Adjusted R-squared: {model2.rsquared_adj:.4f}\n",
    "    - Key findings:\n",
    "        * Win rate and household_size significant at p<0.05\n",
    "        * Years_customer (p=0.229) and type_local (p=0.093) not significant\n",
    "        * Negative relationships with all variables except type_local\n",
    "        * Household size remains consistently significant across models\n",
    "\n",
    "4. Model Comparison:\n",
    "    - First model Adj R-squared: {model1.rsquared_adj:.4f}\n",
    "    - Second model Adj R-squared: {model2.rsquared_adj:.4f}\n",
    "    - First model shows better explanatory power\n",
    "    - Both models identify significant predictors of customer value\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3f46860-7a6c-471a-8073-690cfe5cf1d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# pymssql_cursor.close() \n",
    "# pymssql_conn.close()\n",
    "\n",
    "# Might need to fix teams/team history connection to games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058000c-6380-4ac4-b088-6a4bd6bd7d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Establish connections\n",
    "# conn = psycopg2.connect(\n",
    "#     database=\"iwdm\", \n",
    "#     user='dw_chancewiese',\n",
    "#     password='Spikeball2020',\n",
    "#     host='database-1.czsooswggscz.us-east-2.rds.amazonaws.com',\n",
    "#     port='5432'\n",
    "# )\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # pymssql_conn = pymssql.connect(\n",
    "# #     server='stairwaytoheaven.usu.edu',\n",
    "# #     user='5330user',\n",
    "# #     password='pipelinesnow',\n",
    "# #     database='ironwill'\n",
    "# # )\n",
    "# # pymssql_cursor = pymssql_conn.cursor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
