{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9UFL1BWNWB5roRxU4nSQC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Mini Review Exercise - Homeruns**\n","## *DATA 3300*\n","## Name:\n","\n","In this mini-exercise you've chosen to work on a sports dataset predicting the likelihood of a homerun. This dataset has been cleaned and contains data on 865 plays that were either homeruns or not. Using supervised data mining, answer the posed questions and construct a model to predict positive homerun status given play characteristics (independent variables) including:\n","\n","* **Play_ID** = primary key\n","* **batter_team** = team of batter - BOS, NYC, OAK\n","* **bearing** = center, left, right\n","* **pitch_name** = type of pitch - 4-Seam Fastball, Changeup, Cutter, Curveball\n","* **inning** = game inning, ranging 1-13\n","* **balls** = ranges between 0-3\n","* **pitch_mph** = speed of pitch in mph\n","* **launch_speed** = speed of launch in mph\n","* **is_home_run** = whether or not hit was a homerun"],"metadata":{"id":"Z43Z9FxBYiA7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_fsPPth0ITSe"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.model_selection import train_test_split\n","import statsmodels.api as sm"]},{"cell_type":"code","source":["df = pd.read_csv('/content/home_runs.csv')                      # reads in dataset\n","df.head()                                                       # previews the dataset"],"metadata":{"id":"SIgvQRSkIeOh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Is the relationship between the IVs and the DV linear? Plot one numerical (quantitative) IV against the DV**"],"metadata":{"id":"vn6uUhP0LYnP"}},{"cell_type":"code","source":["plt.scatter(df['Numerical IV'], df['is_home_run'])              # produces a scatterplot of a numerical IV against the DV\n","plt.xlabel(\"Numerical IV Label\")                                # x-axis label\n","plt.ylabel(\"Homerun\")                                           # y-axis label\n","plt.show()"],"metadata":{"id":"VWVKT-I8KaU0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"B5I_cBM0QzJZ"}},{"cell_type":"markdown","source":["**Next, let's set up our x and y objects. The x object should contain all IVs -- let's assume none of them of collinear. The y object should contain the DV**"],"metadata":{"id":"MoSw4bNuUpSj"}},{"cell_type":"code","source":["x = df.drop(['DV', 'primarykey'], axis = 1)                                         # assigns IVs to x object by dropping out non-IVs\n","x = pd.get_dummies(data = x, drop_first= True)                                      # creates dummy variables, dropping out the first as a referent group\n","x.head()"],"metadata":{"id":"A0vm9K9zKBFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = df['DV']                                                                        # assigns DV variable to y\n","y = pd.get_dummies(data = y, drop_first = True)                                     # splits DV into dummy variables, drops out one group"],"metadata":{"id":"-j813x2sLprR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**First let's fit a linear regression and see what happens...**"],"metadata":{"id":"OFbMt8b4L1N7"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=101)  # creates a 80-20 training and test split"],"metadata":{"id":"GdQP7QuPL5yN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LinearRegression()                                                                    # brings in the LinearRegression model\n","\n","OLS = model.fit(x_train, y_train)                                                             # fits a linear regression to the training data\n","\n","y_pred = model.predict(x_test)                                                                # makes predictions onto the test set\n","y_pred[:20]                                                                                   # displays values of first 20 predictions in test set"],"metadata":{"id":"Lg5fd-2hMK8U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What values would you want the model to predict for a binary classification task, what range of values does it appear to be predicting?**"],"metadata":{"id":"NII3zar-Uh3m"}},{"cell_type":"markdown","source":[],"metadata":{"id":"ofIBN3PUUtxa"}},{"cell_type":"code","source":["sns.regplot(x = y_pred, y = y_test)                                                           # produces a regression plot of the actual values of y against the predicted values\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.show()"],"metadata":{"id":"DaVrJaflNUoI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What is the problem with these predictions made using a Linear Regression?**"],"metadata":{"id":"H7LFlN4HNQO7"}},{"cell_type":"markdown","source":[],"metadata":{"id":"rbGs93wAOmg3"}},{"cell_type":"markdown","source":["**What model should we use instead if we want to perform classification of Heart Disease or not Heart Disease?**"],"metadata":{"id":"BxQaBPBfOd9l"}},{"cell_type":"markdown","source":[],"metadata":{"id":"EWHUkFyROlBO"}},{"cell_type":"markdown","source":["**Now let's fit a logistic regression...**"],"metadata":{"id":"JyEXfehDT2uz"}},{"cell_type":"code","source":["x_train_Sm = sm.add_constant(x_train)                                                                     # adds an intercept to x_train\n","log_reg = sm.Logit(y_train, x_train_Sm).fit()                                                             # fits a logistic regression to training data\n","print(log_reg.summary())                                                                                  # produces a summary statistics table"],"metadata":{"id":"nwB8RqbzOrkX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**The units of the regression coefficients above are in terms of?**"],"metadata":{"id":"HVtEMFp28TlM"}},{"cell_type":"markdown","source":[],"metadata":{"id":"CNkVezcn8ZhH"}},{"cell_type":"markdown","source":["**Using your summary table find:**\n","\n","1. **One quantitative (numerical) variable that is statistically significant ($Î± < 0.1$), but interpret its regression coefficient.**\n","\n","2. **One qualitative (categorical) dummy variable that is statistically signficant and interpret its regression coefficient.**"],"metadata":{"id":"cVlTqxvFUACM"}},{"cell_type":"markdown","source":["\n","\n","1.   Quantitative: \n","\n","2.   Qualitative: \n"],"metadata":{"id":"5-ilPBjkUYmi"}},{"cell_type":"markdown","source":["**If you were to begin removing non significant variables, how would you handle Batter Team? Would you leave in both dummy variables, drop both, or leave one or the other in?**"],"metadata":{"id":"FNJqC48amFFT"}},{"cell_type":"markdown","source":[],"metadata":{"id":"0INRMY68mUPb"}},{"cell_type":"markdown","source":["**Why?**"],"metadata":{"id":"yem_MwudmV-9"}},{"cell_type":"markdown","source":[],"metadata":{"id":"hRpSriUHmX6m"}},{"cell_type":"markdown","source":["**What two calculations are necessary to convert the log-odds to probability? Provide the formulas below:**"],"metadata":{"id":"fU6dCUboU5HM"}},{"cell_type":"markdown","source":["* $odds = $\n","* $probability = $"],"metadata":{"id":"lMfEfL5vFgiF"}},{"cell_type":"markdown","source":["**Why convert from log-odds to probability? What basic information can we get from log-odds?**"],"metadata":{"id":"9QzVcpQDXM77"}},{"cell_type":"markdown","source":[],"metadata":{"id":"TUhUwljwXSrk"}},{"cell_type":"markdown","source":["**Compare and Contrast Linear and Logistic Regression, what do they have in common (e.g., common assumptions), how are they different?**"],"metadata":{"id":"94OzN5gKXneT"}},{"cell_type":"markdown","source":["* **Similarities:** \n","\n","* **Differences:** "],"metadata":{"id":"Yp3-QIqgX0Xw"}}]}